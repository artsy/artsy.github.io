<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: javascript | Artsy Engineering]]></title>
  <link href="http://artsy.github.io/blog/categories/javascript/atom.xml" rel="self"/>
  <link href="http://artsy.github.io/"/>
  <updated>2019-05-06T15:21:54+00:00</updated>
  <id>http://artsy.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[What is TypeScript?]]></title>
    <link href="http://artsy.github.io/blog/2019/04/05/omakase-typescript/"/>
    <updated>2019-04-05T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2019/04/05/omakase-typescript</id>
    <content type="html"><![CDATA[<p>TypeScript is a language from Microsoft which builds on JavaScript. This post is a non-technical overview of what
JavaScript is, how TypeScript extends JavaScript and why we choose to adopt TypeScript at Artsy.</p>

<!-- more -->


<a name="What.is.JavaScript."></a>
<h2>What is JavaScript?</h2>

<p>First up, you can't describe TypeScript without talking about JavaScript. To create a website (and a bunch of other
types of things) you work in three languages: HTML, CSS and JavaScript (JS). Broadly speaking: HTML defines the
content that will appear on the page, CSS defines the visual style of the page, and JS defines the interactive
behaviours of the page.</p>

<p>We describe having these sets of skills as being a "front-end" developer. You have to understand those three
languages to present anything inside a web browser like Safari, Firefox or Chrome. So, given how popular the web
is, there is a massive demand for people who are good at using these three languages.</p>

<p>There is also the set of skills for the "back-end" developers, which are to create computer services that
communicate either to a web browser (by passing it HTML/CSS/JS) or to another service (by sending a raw data.) You
don't need to use HTML, CSS or JS to write this type of code, but it's usually an end-product of your work. We
mostly build our back-ends in Ruby or JavaScript at Artsy.</p>

<a name="What.do.Programming.Languages.do."></a>
<h3>What do Programming Languages do?</h3>

<p>Programming languages are an interesting problem to solve. People read code many, many multiples of times more than
they write it - so developers create languages which are good at solving particular problems with a small amount of
code. Here's an example using JavaScript:</p>

<pre><code class="js">var name = "Danger"
console.log("Hello, " + name)
</code></pre>

<p>The first line makes a variable (a kind of box you can keep things in) and then the second line outputs text to the
console (think DOS, or the terminal) <code>"Hello, Danger"</code>. JavaScript is designed to work as a scripting language,
which means the code starts at the top of the file and then goes through line by line. To provide some contrast,
here is the <a href="https://repl.it/repls/VioletredGlisteningInfo">same behavior</a> in Java, which is built with different
language constraints:</p>

<pre><code class="java">class Main {
  public static void main(String[] args) {
    String name = "Danger";
    System.out.println("Hello, " + name);
  }
}
</code></pre>

<blockquote><p>Note: if you find the naming of Java and JavaScript confusing, it is (they are two completely separate
programming languages, no link at all.) JavaScript was <a href="https://medium.com/@benastontweet/lesson-1a-the-history-of-javascript-8c1ce3bffb17">named that way</a> because Java was looking to be
really the next hot language (it did turn out that way for a decade or two, but now JavaScript is usually the
first language people have heard of.)</p></blockquote>

<p>Aside from having a lot more lines, the Java version comes with a lot of words that aren't necessarily about
telling the computer exactly what to do, e.g. <code>class Main {</code>, <code>public static void main(String[] args) {</code>, <code>}</code> and
<code>}</code> again. It also has semi-colons at the end of some lines. Java is aimed at building different things from
JavaScript, and these extra bits of code make sense within the constraints of building a Java app.</p>

<p>To get to my main point though, there is one standout line I'd like us to compare:</p>

<pre><code>// JavaScript
var name = "Danger"
// Java
String name = "Danger";
</code></pre>

<p>Both of these lines declare variables called <code>name</code> which contain the value <code>"Danger"</code>.</p>

<p>In JavaScript you use the abbreviation <code>var</code> to declare a variable. Meanwhile, in Java you need to say <em>what kind
of data</em> the variable contains. In this case the variable contains a <code>String</code>. (A string is a programming term for
a collection of characters. They <code>"look like this"</code>. This <a href="https://www.youtube.com/watch?v=czTWbdwbt7E">5m video</a>
is a good primer if you want to learn more.)</p>

<p>Both of these variables contain a string, but the difference is that in Java the variable can <em>only</em> ever contain a
<em>string</em>, because that's what we said when we created the variable. In JS the variable can change to be <em>anything</em>,
like a number, or a list of dates.</p>

<p>To illustrate:</p>

<pre><code class="js">// Before in JS
var name = "Danger"
// Also OK
var name = 1
var name = false
var name = ["2018-02-03", "2019-01-12"]

// Before in Java
String name = "Danger";
// Not OK, the code wouldn't be accepted by Java
String name = 1;
String name = false
String name = new String[]{"2018-02-03", "2019-01-12"};
</code></pre>

<p>These trade-offs make sense in the context for which these languages were built back in 1995. JavaScript was
originally designed to be a small programming language which handled simple interactions on websites. Java on the
other hand was built specifically to make big apps which could run on any computer. Their needs had different
scales, so the language required programmers write different types of code.</p>

<p>Java required programmers to be more explicit with the values of their variables because the programs they expected
people to build were more complex. While JavaScript opted for ease of reading, and aimed to do less.</p>

<a name="What.is.TypeScript."></a>
<h3>What is TypeScript?</h3>

<p>TypeScript is a programming language - it contains all of JavaScript, and then a bit more. Using our example above,
let's compare the scripts for "Hello, Danger" in JavaScript vs TypeScript:</p>

<pre><code class="js">// JavaScript
var name = "Danger"
console.log("Hello, " + name)

// TypeScript
var name = "Danger"
console.log("Hello, " + name)

// Yep, you're not missing something, there's no difference
</code></pre>

<p>Due to TypeScript's aim to only <em>extend</em> JavaScript, your normal JavaScript code should work fine with TypeScript.
The things TypeScript adds to JavaScript are intended to help you be more explicit about what kinds of data are
used in your code, a bit like Java.</p>

<pre><code class="diff">- var name = "Danger"
+ var name: string = "Danger"
console.log("Hello, " + danger)
</code></pre>

<p>This extra <code>: string</code> allow the reader to be certain that <code>name</code> will only be a string. Annotating your variables
also gives TypeScript the chance to verify this for you. This is <em>very</em> useful because keeping track of changes
like the type of value in a variable seems easy when it's one or two, but once it starts hitting the hundreds,
that's a lot to keep track of. Types help programmers be more confident about their code because types catch
mistakes.</p>

<p>Simply speaking, we call these annotations "Types". Hence the name <i>Type</i>Script. The tag-line for TypeScript
is "JavaScript which scales" which is a statement that these extra type annotations allows you to work on bigger
projects. This is because you can verify up-front how correct your code is. This means you have less need to
understand how every change affects the rest of the program.</p>

<p>In the 90s, and maybe until a 5-10 years ago the trade-off for not having types in your JavaScript application was
fine because the size and complexities of the programs being built were constrained to just the front-end of
websites. Today though, JavaScript is being used everywhere:</p>

<ul>
<li>Apps like Slack, or Spotify for your computer are built in mostly JavaScript</li>
<li>Some iOS apps, including Artsy's are mostly JavaScript</li>
<li>The back-end and front-end of Artsy.net are JavaScript</li>
</ul>


<p>These are all considerably more complicated to build and understand, adding types drastically reduces the
complexity of making improvements to those programs.</p>

<a name="Why.does.Artsy.use.TypeScript."></a>
<h3>Why does Artsy use TypeScript?</h3>

<p>Artsy definitely isn't the size of Microsoft! Artsy is about 30 engineers, and Microsoft are about 60,000. However,
some of our problems are the same. Developers at Artsy build apps which are made up of thousands of files. A change
to one individual file can affect the behaviour of any number of other files, like throwing a pebble into a pond
and causing ripples to spread out to the bank.</p>

<p>Typically, the need to ensure there are no bugs is less of a problem for people building websites. Websites are
easy to make changes to, because if you change the site - everyone gets the update instantly. We also build our iOS
app with JavaScript, but a change to our app requires Apple to review the changes and for users to download the new
version from the App Store.</p>

<p>This means that the iOS team needs to have more checks that everything is OK before shipping the app to the world.
Using TypeScript gives our team the ability to feel good that the changes we have made are only the changes we
want.</p>

<p>TypeScript isn't the only programming language to tackle the problem of making JavaScript code safer, but it's the
one with the biggest community, allows people to re-use their JavaScript knowledge, can be added in small steps,
and has really good tools to help developers work faster.</p>

<p>These qualities made it worth adding an extra tool to our developers' toolbelt, and we're not the only ones because
TypeScript is growing to be <a href="https://www.wired.com/story/typescript-microsoft-javascript-alternative-most-popular">one of the most popular programming languages in the world</a> with almost 6
million downloads a week.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Anatomy of an Editorial Feature]]></title>
    <link href="http://artsy.github.io/blog/2019/03/05/custom-editorial-features/"/>
    <updated>2019-03-05T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2019/03/05/custom-editorial-features</id>
    <content type="html"><![CDATA[<p><img src="http://files.artsy.net/images/2018-visual-culture-screengrab.gif" title="The Year in Visual Culture 2018" alt="The Year in Visual Culture 2018" /></p>

<p>On select occasions since 2015, Artsy Editorial has created a number of custom, one-off articles featuring unique layouts, styles and experiences. After trying a number of implementations, the <a href="https://github.com/artsy/reaction/tree/master/src/Components/Publishing/EditorialFeature"><code>EditorialFeature</code></a> component was introduced to the process during Artsy’s 2018 year-in-review projects.</p>

<p>By moving the implementation of custom articles to Artsy’s component library, we were able to remove some of the friction and time investment necessary for engineers to spin up these articles, and enable bespoke layouts to be housed in Artsy.net’s Article domain rather than a custom Express app. Acting essentially as a wrapper to accept article data, any component can be rendered as a child of the <code>EditorialFeature</code> component, allowing for flexible combinations of new and existing features, and for minimal or maximal interventions.</p>

<!-- more -->


<p>For a light-weight customization, a developer might add props for unique text or background colors. Medium-touch could involve wrapping an existing layout in a styled-component declaring further css interventions to font-size, borders, margins or other layout properties. The space is an open canvas, so the option is available to build every element from scratch, introduce JS interactivity, and to interact with any data saved to the article model in a completely new way. The scale of a project can vary widely, but determined by weighing priorities of editorial intent, proposed designs, engineering capabilities/availability, and budget.</p>

<p>Some examples of articles created with the <code>EditorialFeature</code> component include:</p>

<ul>
<li>The Most Influential Artists of 2018 - <a href="https://github.com/artsy/reaction/tree/master/src/Components/Publishing/EditorialFeature/Components/Eoy2018Artists">Components</a> | <a href="https://www.artsy.net/article/artsy-editorial-influential-artists-2018">Article</a></li>
<li>The Year in Visual Culture 2018 - <a href="https://github.com/artsy/reaction/blob/master/src/Components/Publishing/EditorialFeature/Components/Eoy2018Culture.tsx">Components</a> | <a href="https://www.artsy.net/article/artsy-editorial-people-defined-visual-culture-2018">Article</a></li>
</ul>


<a name="Custom.articles.by.domain:"></a>
<h1>Custom articles by domain:</h1>

<p><strong>1. <a href="https://github.com/artsy/force">In Force (Artsy.net)</a></strong></p>

<ul>
<li>Whether an article requires a custom layout is determined in Force’s <a href="https://github.com/artsy/force/blob/master/src/desktop/apps/article/routes.ts">article routing</a>. This is achieved by passing the prop <code>customEditorial</code>-- a string shorthand for a specific article-- to Reaction’s top-level <code>Article</code> component. The <code>customEditorial</code> prop is pulled from Force’s editorial feature "<a href="https://github.com/artsy/force/blob/master/src/desktop/apps/article/editorial_features.ts">master list</a>", which ties an <code>article._id</code> to a communicative string that will be received by Reaction. In addition to data saved to an article model, the component will also receive all data displayed in the footer including related articles and display ads. Custom articles are rendered as a standalone page, meaning they are excluded from infinite scroll and do not render the main site header.</li>
</ul>


<p><strong>2. <a href="https://github.com/artsy/reaction">In Reaction (Artsy’s component library)</a></strong></p>

<ul>
<li>In Reaction’s top-level <a href="https://github.com/artsy/reaction/blob/master/src/Components/Publishing/Article.tsx"><code>Article</code></a> component, the presence of a <code>customEditoral</code> prop routes an article to the <a href="https://github.com/artsy/reaction/blob/master/src/Components/Publishing/Layouts/ArticleWithFullScreen.tsx"><code>ArticleWithFullScreen</code></a> component. From here, the article is given context for image slideshows and tooltip helpers, and the  <code>EditorialFeature</code> component is rendered rather than the component designated by the article’s specified layout. A <code>FeatureLayout</code> is displayed by default, but any article can be converted into a custom feature, regardless of the <code>article.layout</code> value. Inside the <code>EditorialFeature</code> component, a switch statement is used to associate the string variable for the feature with its affiliated top-level component.</li>
</ul>


<p><strong>3. <a href="https://github.com/artsy/positron">In Writer/Positron (CMS &amp; API for articles)</a></strong></p>

<ul>
<li>Because <code>EditorialFeature</code> accepts an article data-model, it can be edited using the Writer CMS. However it is important to note that a custom layout is rendered by Force only. While editing, what users see is dicated by the <code>article.layout</code> property. Writer's features are exposed based on this property, so a particular custom article’s layout should be determined by the features most suited to the content and design.  For example, if you need a header-image or video, a feature article would be a logical choice because that content can easily be created and edited in Writer. If the article relies heavily on content from related articles, you might choose to customize a series article instead.</li>
</ul>


<a name="Creating.a.custom.feature"></a>
<h1>Creating a custom feature</h1>

<p><img src="http://files.artsy.net/images/2018-influentual-artists-screengrab.gif" title="The Most Influential Artists of 2018" alt="The Most Influential Artists of 2018" /></p>

<p><strong>A custom layout is enabled via three steps:</strong></p>

<ul>
<li>Add a new object to the <code>customEditorialArticles</code> <a href="https://github.com/artsy/force/blob/master/src/desktop/apps/article/editorial_features.ts">master list</a>, indicating the <code>article._id</code> and <code>name</code>. Names are usually a shorthand for the content, and used because they are descriptive (unlike an <code>_id</code>), and will not change over time like a title or slug has potential to do.
<code>javascript
  {
    name: "MY_CUSTOM_FEATURE",
    id: "12345" // mongo _id
  }
</code></li>
<li>Create your custom component in the <code>EditorialFeature/Components</code> directory</li>
<li>Add your <code>customEditorial</code> string to <code>EditorialFeature</code>’s switch statement to enable rendering custom component
<code>javascript
  case "MY_CUSTOM_FEATURE": {
    return &lt;MyCustomFeature {...props} /&gt;
  }
</code></li>
</ul>


<p>Although these features historically receive high traffic via search and other channels, they usually have little internal visibility a few months after they are published. For this reason it is recommended that, in addition to any unit tests, developers create a snapshot of the custom article so that unexpected regressions are flagged in a test failure.</p>

<a name="History..amp..Context"></a>
<h1>History &amp; Context</h1>

<p>Previously we have used multiple strategies to implement these features, using two sometimes overlapping concepts: Curations and SuperArticles.</p>

<p><img src="http://files.artsy.net/images/2017-gender-equality-screengrab.gif" title="Artists for Gender Equality" alt="Artists for Gender Equality" /></p>

<p><strong>Curations:</strong></p>

<p>A <a href="https://github.com/artsy/positron/tree/master/src/api/apps/curations">Curation</a> is a model in Positron’s API that has no schema-- meaning it accepts any data shape. This can be a handy solution for content that does not conform to the existing article model. However, this strategy comes with significant overhead and a few quirks:</p>

<ul>
<li>A <a href="https://github.com/artsy/positron/tree/master/src/client/apps/settings/client/curations">custom edit UI must be created</a> and maintained indefinitely</li>
<li>A custom Express app is required by Force to render the content</li>
<li>Because data is in a unique shape, components often must be fully custom</li>
<li>It is difficult to track visual changes over time</li>
</ul>


<p>Despite these pitfalls, Curations remain useful for special cases, especially those which involve interactive navigation through content.</p>

<p>Published examples of custom articles that use curations are:</p>

<ul>
<li><a href="https://www.artsy.net/gender-equality">Artists for Gender Equality</a></li>
<li><a href="https://www.artsy.net/venice-biennale">Inside the Biennale</a></li>
<li><a href="https://www.artsy.net/2016-year-in-art">The Year in Art 2016</a></li>
</ul>


<p><em>See <a href="http://artsy.github.io/blog/2017/02/01/year-in-art/">previous blog post</a> on creating The Year in Art 2016.</em></p>

<p><strong>SuperArticles:</strong></p>

<p>An article where the <code>is_super_article</code> field is set to true includes the ability to attach related articles and sponsor-related fields to an article. It also exempts an article from the infinite scroll feed, and renders a custom header (in place of the main site navigation) and footer. The SuperArticle <a href="https://github.com/artsy/force/blob/master/src/desktop/components/article/templates/super_article_sticky_header.jade">header</a> and <a href="https://github.com/artsy/force/blob/master/src/desktop/components/article/templates/super_article_footer.jade">footer</a> both include navigation options to view and visit related, aka sub-article, content.</p>

<p>The first SuperArticle was also the <a href="https://www.artsy.net/2015-year-in-art">first custom feature</a>, and its attributes were made available to all articles when launched. However, its weakness lies in a conflation of a series and a sponsor as a single concept. In practice we have seen that they are not mutually exclusive. Additionally, support for this feature was built in Backbone, and hasn’t always behaved as expected when inserted into our React-heavy ecosystem. Since the SuperArticle was created, we have extended the ability for any article to accept either or both sponsor and related article data, and we are currently in the process of deprecating this concept.</p>

<p>Existing SuperArticles include:</p>

<ul>
<li><a href="https://www.artsy.net/2016-year-in-art">The Year in Art 2016</a></li>
<li><a href="https://www.artsy.net/2015-year-in-art">The Year In Art 2015</a></li>
<li><a href="https://www.artsy.net/article/artsy-editorial-the-100-most-expensive-artists">The 100 Most Expensive Artists at Auction</a></li>
</ul>


<a name="Takeaways.for.developers"></a>
<h1>Takeaways for developers</h1>

<ul>
<li>We try to work with our editorial and design teams to ensure new editorial content maps as closely to our existing article data-model and CMS features as possible. That way, we can have an upfront conversation about the constraints our systems might impose on designs.</li>
<li>Relying heavily on existing article and system components ensures that system-wide changes (for example, changes to breakpoints) will be inherited</li>
<li>Always create snapshot tests to monitor how an article changes over time</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Keeping Artsy's dependencies up to date]]></title>
    <link href="http://artsy.github.io/blog/2018/11/26/keeping-dependencies-updated/"/>
    <updated>2018-11-26T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/11/26/keeping-dependencies-updated</id>
    <content type="html"><![CDATA[<p>Hey everyone! I'm Justin, a senior engineer here at Artsy. I've been here for about 6 months and I'm a bit overdue
on my first blog post. This will be one of a series of posts I'm dubbing <em>roads and bridges</em> (<a href="https://www.fordfoundation.org/about/library/reports-and-studies/roads-and-bridges-the-unseen-labor-behind-our-digital-infrastructure/">thanks Orta</a>)
describing infrastructure and tooling work here at Artsy.</p>

<a name="Backstory"></a>
<h3>Backstory</h3>

<p>Here at Artsy we have a lot of internal dependencies. Keeping these dependencies up to date across all of our
projects can be a bit of a headache. For example, there's <a href="https://github.com/artsy/palette">Palette</a> (our <a href="https://www.uxpin.com/studio/blog/design-systems-vs-pattern-libraries-vs-style-guides-whats-difference/">design system</a>)
which is consumed by <a href="https://github.com/artsy/reaction">Reaction</a> (our react component/app library), <a href="https://github.com/artsy/emission">Emission</a> (our React Native
application), <a href="https://github.com/artsy/force">Force</a> (our main site), and <a href="https://github.com/artsy/positron">Positron</a> (our editorial creation tool). That's not
even an exhaustive list. As you can imagine, after making an update to <a href="https://github.com/artsy/palette">Palette</a> we have to make a lot of
Pull Requests to get everything synced up across our many projects. And that's just <em>one</em> dependency.</p>

<!-- more -->


<a name="Evaluating.the.problem"></a>
<h3>Evaluating the problem</h3>

<p>There are a few services out there that connect to GitHub and helps you keep your dependencies up to date. I'd
personally used <a href="https://greenkeeper.io/">Greenkeeper</a> in the past and it seemed to work fairly well for my uses. I'd also
heard about <a href="https://renovatebot.com/">Renovate</a> which is another option that actually supports more package managers than just
yarn/npm. Great! Plenty to evaluate here. Anytime I'm evaluating a new service there are a few questions I ask
myself upfront to help a good decision:</p>

<ol>
<li>What are my exact needs</li>
<li>Can this solution scale to meet future needs</li>
</ol>


<p>The first point is straight-forward, but there's a little twist. We have a <em>lot</em> of dependencies. If we got PRs for
all of them we'd be pretty much unable to do anything. In this case we wanted to specifically limit it to packages
that are published by Artsy (on the <code>@artsy</code> npm namespace).</p>

<p>The second you have to be a bit careful with. Don't try to project too far or you'll end up choosing a solution far
too complex for your current needs. In this case, I wanted something that we could selectively extend in the future
to cover other dependencies. Things like <code>react</code> and <code>react-dom</code> or <code>typescript</code>. Incremental increases without a
ton of noise.</p>

<a name="Picking.a.solution"></a>
<h3>Picking a solution</h3>

<p>First things first... we have to have a solution that can update only Artsy's dependencies. I started digging
through <a href="https://greenkeeper.io/">Greenkeeper</a>'s docs and found a reference to an <a href="https://greenkeeper.io/docs.html#ignoring-dependencies">ignore</a> option.
Essentially any package that you don't want <a href="https://greenkeeper.io/">GreenKeeper</a> to automatically update you can put in this
ignore list. That's not really doable in our usecase because we want to ignore everything but a small subset of
packages.</p>

<p>Checking out <a href="https://renovatebot.com/">Renovate</a>'s docs I found a more promising option:
<a href="https://renovatebot.com/docs/configuration-options/#excludepackagepatterns">excludePackagePatterns</a>. All I really want to do is include Artsy packages, but this sounded
like I could do the inverse by excluding all non-Artsy packages. Being as it had that option, supported more
package managers, and had a more friendly pricing scheme than <a href="https://greenkeeper.io/">Greenkeeper</a> I decided to give
<a href="https://renovatebot.com/">Renovate</a> a shot.</p>

<a name="Making.it.happen"></a>
<h3>Making it happen</h3>

<p>I began by enabling <a href="https://renovatebot.com/">Renovate</a> on <a href="https://github.com/artsy/force">Force</a>. You can see the PR <a href="https://github.com/artsy/force/pull/3086">here</a>.
<a href="https://renovatebot.com/">Renovate</a> has a <em>really</em> excellent on-boarding experience. It first creates a PR that adds its own
configuration. It shows you what packages will be updated based on that configuration. As you update the config,
Renovate will update the PR body to show you the results of your changes. This gives you the opportunity to update
the configuration before it officially activates. If you click the edited dropdown on the PR body you'll see all
the changes Renovate made to the issue while I was trying to figure out the configuration.</p>

<p><img src="/images/2018-11-26-keeping-dependencies-updated/issue-history.png" alt="GitHub PR edit history" /></p>

<p>It took me a while to figure everything out, just take a look at the <a href="https://github.com/artsy/force/pull/3086/commits">commit history</a>. I'm going to
work through the final setup just to give you an idea of our setup.</p>

<p>First, I extended <a href="https://renovatebot.com/">Renovate</a>'s base config.</p>

<pre><code>{
  "extends": [
    "config:base"
  ],
  ...
}
</code></pre>

<p>If you've worked with <a href="https://eslint.org">eslint</a>, <a href="https://babeljs.io/docs/en/options#extends">babel</a>, or other tools in the js ecosystem, you've probably
seen this type of configuration extension. It essentially allows us to use their best practices out of the box.
Check out their <a href="https://github.com/renovatebot/presets/blob/ef6a6e2e6d3e6ba25239d57d808b0e4dc64f32a3/packages/renovate-config-config/package.json#L19-L34">presets repo</a> if you want to know what it adds specifically.</p>

<p>Next, I set the <a href="https://help.github.com/articles/assigning-issues-and-pull-requests-to-other-github-users/">assignees</a>. When <a href="https://renovatebot.com/">Renovate</a> opens a new PR, it'll assign it to these people
so that the PR doesn't get missed.</p>

<p>The actual meat of the change is the <code>packageRules</code> setup.</p>

<pre><code>{
  ...
  "packageRules": [{
    "packagePatterns": ["*"],
    "excludePackagePatterns": ["^@artsy"],
    "enabled": false
  }],
  ...
}
</code></pre>

<p><a href="https://renovatebot.com/">Renovate</a> allows you to set up multiple different <code>packageRules</code> and there's a lot of configuration for
them. I'm not going to go through more than I did, but feel free to read more in their
<a href="https://renovatebot.com/docs/configuration-options/#packagerules">docs</a>. In the <code>packageRule</code> that I setup, I specified <code>packagePatterns</code> with an
asterisk to select all dependencies. Then using <code>excludePackagePatteners</code> I excluded anything that started with
<code>@artsy</code>. Finally (and most importantly), I set <code>enabled</code> to <code>false</code> to disable the dependencies matching those
combinations of rules. That last part took me a while to figure out. When you're building package rules in
<a href="https://renovatebot.com/">Renovate</a>, think of it as building out a list of operations to perform.</p>

<p>The last few pieces of config are a little more straight-forward and you can read about those in the docs. The one
thing that I'll mention is that <a href="https://renovatebot.com/docs/configuration-options/#vulnerabilityalerts">vulnerabilityAlerts</a> <em>ignores</em> <code>packageRules</code> and
triggers update PRs for anything that's reported to have a vulnerability. You'll have to explicitly disable it if
you only want reports on certain packages. Though, having it on probably isn't a bad idea...</p>

<a name="Wrapping.up"></a>
<h3>Wrapping up</h3>

<p>So, that's how we configured <a href="https://renovatebot.com/">Renovate</a> to automatically update npm dependencies in Artsy's namespace.
It's been extremely useful already. I also went ahead and pulled our configuration out into a <a href="https://github.com/artsy/renovate-config">shared
repo</a> so that we didn't have to copy these configurations across all of our projects. That's
a blog post for another day.</p>

<p>Be well friends.</p>

<!-- prettier-ignore -->


<!-- prettier-ignore -->


<!-- prettier-ignore -->

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A History of Artsy's Web Frontend]]></title>
    <link href="http://artsy.github.io/blog/2018/10/04/artsy-frontend-history/"/>
    <updated>2018-10-04T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/10/04/artsy-frontend-history</id>
    <content type="html"><![CDATA[<p>As Artsy Engineering grows in 2018, we have so many newcomers looking for context: they want to understand the
systems they'll be working in day-to-day. Awesome! But it's not enough to understand the systems themselves, it's
often helpful to understand the <em>history</em> of how we ended up where we are.</p>

<p>Frontend web development has changed a <em>lot</em> during Artsy's existence, and it continues to advance at a blistering
pace. It's easy to get caught up in the churn of frameworks and languages and tools, so I want to use this post as
an opportunity to contextualize each transition that Artsy's web presence has made over the past seven years. We've
changed technologies, but we've tried to do so with care and attention. Documenting these decisions is important
(and is ideally done <a href="https://ashfurrow.com/blog/contemporaneous-blogging/">contemporaneously</a>), but even with the best documentation, <a href="https://github.com/artsy/artsy.github.io/pull/489#discussion_r221301472">sometimes our own documentation
is unclear to us</a>.</p>

<p>In an effort to help contextualize our web frontend (which is <a href="https://github.com/artsy/force">open source</a>), this blog post will document
the major transitions that Artsy's web presence has made over the past seven years. Let's begin!</p>

<!-- more -->


<a name="Backbone...CoffeeScript"></a>
<h2>Backbone + CoffeeScript</h2>

<p>Artsy as you know it today began as a standard Rails application. We ran <code>git init</code> in January 2011, which coupled
our backend API to our web frontend, but since our frontend was just a fancy user interface for our API, this
worked for over two years. The web app itself was a kind of simplified MVC – controller logic lived inside the
views and models dealt with backend communication and notifying the view of state changes. For CSS, we used the
SASS CSS preprocessor. The Rails backend served initial pages that were then populated with follow-up API calls
made on the client-side. At a <em>very</em> high level, this isn't <em>that</em> different from what we do today with React.</p>

<p>Our site was built with a framework called <a href="http://backbonejs.org">Backbone</a>, which was really well-suited for our needs at the time.
From their documentation:</p>

<blockquote><p>Philosophically, Backbone is an attempt to discover the minimal set of data-structuring (models and collections)
and user interface (views and URLs) primitives that are generally useful when building web applications with
JavaScript. In an ecosystem where overarching, decides-everything-for-you frameworks are commonplace, and many
libraries require your site to be reorganized to suit their look, feel, and default behavior — Backbone should
continue to be a tool that gives you the <em>freedom</em> to design the full experience of your web application.</p></blockquote>

<p>As an outsider to the web at that time, I can't comment too heavily on Backbone. It seems like the freedom
(emphasis theirs) that they describe is a freedom from tangled jQuery code everywhere. I think our definition of
freedom on the web frontend has evolved since then, but that's just my feeling.</p>

<p>The other key component to our web frontend was <a href="https://coffeescript.org">CoffeeScript</a>. According to its documentation, "CoffeeScript is
a little language that compiles into JavaScript", which was pretty important at the time. JavaScript in 2011 was
very different from JavaScript today. The CoffeeScript docs also state that "JavaScript has always had a gorgeous
heart", which I'm not sure I'd agree with to be honest, but the CoffeeScript project really shows how a handful of
engineers working to improve something they care about can change an entire industry. While I don't think
contemporary JavaScript would have gotten as good as it has without CoffeeScript, it's a bit anachronistic to see
it used today.</p>

<p>Our goal as a (very small!) engineering team at the time was to keep our moving parts to a minimum.
Rails+SASS+CoffeeScript+Backbone helped us achieve that goal, and we couldn't have gotten this far without the help
of those projects.</p>

<a name="Ezel..amp..Friends"></a>
<h2>Ezel &amp; Friends</h2>

<p>In November 2013, we split our web frontend from the API backend. You can read
<a href="2013_review">all the details in this blog post</a>, but the story is summarized nicely as "moving from a single
monolithic application to modular Backbone apps that run in Node and the browser and consume our external API."
This move from monolith to modular systems continues to influence day-to-day work on the Artsy Engineering team.</p>

<p>We had already started moving away from a typical Rails app by moving our API to <a href="https://github.com/ruby-grape/grape">Grape</a> in order to support an
iOS application. The monolith also had some clear drawbacks including severe page load times, maintaining
duplicated backend and frontend UI templates, slow test suites, and poor developer productivity. We took the
project of building our mobile web frontend, m.artsy.net (still known as "martsy" internally) as an opportunity to
address these problems.</p>

<p>We built our new site with <a href="https://github.com/ruby-grape/grape">Node.js</a> since it allowed us to share and consolidate our server/client rendering
code. We split out areas of concern into separate "apps", with their own bundled CSS/JS to help page load times. We
server-side rendered above-the-fold content and used client-side JS to load the rest, which helped SEO and user
experience. We took a <a href="http://getbem.com/introduction/">BEM</a>-like approach to our CSS, which helped developer productivity. Our technical
decisions were driven primarily by our desire to create great user experiences.</p>

<p>And because we are an open source by default organization, we collected these approaches into an open source
project called <a href="https://github.com/artsy/ezel">Ezel</a>. While our main app used this Ezel approach, other new web apps – CMS systems for our
partners, auction-management systems for our admins, etc – were built on new internal tools to share assets and
code across the apps. We experimented a lot; we got pretty good at sharing resources across codebases. Most of our
web projects started on Heroku before moving to heavier-duty deployments as needed. Our frontend mindset at the
time (2015) was focused on getting to a stable, predictable stack. However... we started experimenting with React
around the same time.</p>

<p>CoffeeScript and Backbone were still working for us, and we still use them in production in many systems. However,
the state of the art in web development moved on. When I joined the auctions team and helped maintain one of our
CoffeeScript+Backbone apps, I was <em>very</em> confused about how data flowed from one part of the app to another, across
languages, with a lot of magic happening. I think that's typical in these kinds of apps – "convention over
configuration" is a good mantra <em>if</em> you can expect that incoming engineers are familiar with the conventions.
That's just not the case anymore.</p>

<p>By 2016, we had <a href="http://artsy.github.io/blog/2015/04/08/creating-a-dynamic-single-page-app-for-our-genome-team-using-react/">experimented with React</a> and followed up with <a href="http://artsy.github.io/blog/2016/08/09/the-tech-behind-live-auction-integration/">another app built with the
technology</a>. React (and Redux) were very well-suited for our realtime auction bidding UI, and would later
prove helpful in our <a href="https://github.com/artsy/positron">editorial CMS</a>. These experiences helped prove the technology was ready for
production use <em>and</em> convinced us that React was great at reducing the complexities of building user interfaces
(the realtime nature of our auctions product was particularly well-suited for Redux's state management; it was our
first from-scratch React app).</p>

<p>When the Artsy business require us to make changes to how we build software, like splitting up our monolith, we try
to take full advantage of those changes to improve how we work, which means evaluating new tools. Adopting Node.js
and Ezel wouldn't make sense today, but at the time, they helped us scale up Artsy's business without the same
scaling up of our engineering resources. Ezel helped us do more with less, which is still an important criteria we
use for evaluating new tools.</p>

<a name="React"></a>
<h2>React</h2>

<p>By 2017, the divisions between our mobile frontend and web frontend teams had been totally dissolved (as they
should – the division between mobile and web developers is a false dichotomy). Our <a href="http://artsy.github.io/blog/2017/04/14/artsy-technology-stack-2017/">2017 tech stack
post</a> discusses this in depth, but our goal was really to unify the paradigm that frontend engineers
at Artsy use to build user interfaces, whether that's on mobile or web. React and React Native were our answer to
that challenge.</p>

<p>On the web side of things, however, Artsy had another challenge. Sure, React is great, and sure, it's how we want
to build user interfaces, but how do we get there? We're not fans of large rewriting projects, so we opted for what
we call an "incremental revolution" approach. We built a library called <a href="https://github.com/artsy/stitch">Stitch</a> that would let us mount React
components inside our existing app. Using this approach, we could migrate to React component-by-component. We've
been using Stitch in production for over a year and have been very happy with its approach; you can read more
details of integrating it into our main frontend app <a href="http://artsy.github.io/blog/2017/09/05/Modernizing-Force/">in this blog post</a>.</p>

<p>Today, principal React work takes place in <a href="https://github.com/artsy/reaction">a shared components repo</a>. We share these components across
several of our web apps using Stitch. We have been pretty pleased with the results! But our dive into React is only
just beginning. The community is moving quickly to figure out what best practices make sense in the React paradigm,
and we're a part of that. We are evaluating technologies like <a href="https://www.styled-components.com">styled-components</a> and <a href="https://jxnblk.com/styled-system/">styled-system</a> to create
a universal design system within Artsy. The area is under very active development, so I'll save details for a
future blog post.</p>

<p>I can't go too much further without talking about GraphQL. v1 of our API (REST) is still in use around much of
Artsy and, despite the best efforts of some of our engineers, v2 of our API (<a href="http://stateless.co/hal_specification.html">HAL</a>) hasn't gained significant
internal use yet. Instead, we found ourselves building a <a href="https://graphql.org">GraphQL</a> server to orchestrate API calls to our
existing APIs. This confers many benefits, which I describe from a mobile perspective in some detail <a href="https://ashfurrow.com/blog/the-spirit-of-moya/">here</a>.
The key thing to understand about our GraphQL server, <a href="https://github.com/artsy/metaphysics/">which is open source</a>, is that it is under the
stewardship of our frontend engineers, not our platform engineers. That's not to say that our platform team isn't
involved with its development – in fact, they've been key to scaling it up – but Artsy frontend engineers created
the server to help us build better UIs, and while the technology is still very new, we continue to see it pay
dividends.</p>

<p>Okay so remember earlier when I said that we dissolved our mobile team? Well, I was on that team and it wasn't like
our mobile engineers all learned how Artsy does web – we brought our culture and tools with us and, together with
our web colleagues, have built an integrated engineering team that's greater than the sum of its parts. One thing
that was important to mobile engineers was type safety, so we had to have a conversation about JavaScript.</p>

<p>On its own, JavaScript can't guarantee type safety. We investigated two options: <a href="http://www.typescriptlang.org">TypeScript</a> and <a href="https://flow.org">Flow</a>. <a href="http://artsy.github.io/blog/2017/02/05/Front-end-JavaScript-at-Artsy-2017/">This
blog post</a> goes into detail about our decision, but tl;dr we chose TypeScript. We have been building (and
helping to build) tools <a href="https://github.com/relay-tools/relay-compiler-language-typescript">relay-compiler-language-typescript</a> to take full advantage of interoperability
between TypeScript types and GraphQL types through <a href="https://facebook.github.io/relay/">Relay</a>, as well as using Babel 7 to migrate existing projects
to TypeScript incrementally, which you can read about in more detail <a href="https://artsy.github.io/blog/2017/11/27/Babel-7-and-TypeScript/">here</a>. It's all very exciting – you
can read more on how Relay and GraphQL interoperate <a href="http://artsy.github.io/blog/2018/07/25/Relay-Networking-Deep-Dive/">in this blog post</a>.</p>

<p>We started building software in React not because it was trendy, but because it helped our engineering team deliver
more value to the business. It's been a huge success, but not without its costs. We've tried to mitigate those
costs by using tools like Stitch to migrate apps to React incrementally, and through spreading knowledge of how our
stack through internal knowledge-sharing like <a href="http://artsy.github.io/series/javascriptures/">JavaScriptures</a>. While the transition to React has had its costs,
<em>not</em> moving would also be costly, too.</p>

<hr />

<p>Since I joined Artsy, I've seen us continually investing in tooling that helps us build better software. The
results of this culture-of-continuous-improvement speak for themselves: with fewer than 30 engineers total, we
support a growing company with a suite of software built for many canvasses <em>and</em> we have an outsized impact on the
software industry relative to our size. Our frontend web stack is just one facet of our evolving technology –
there's lots of exciting stuff on the backend, too (<a href="https://github.com/artsy/hokusai">for example...</a>). Through my research for this blog
post, I learned a lot about what drives technological decisions on our team. From humble beginnings as a Rails app,
to CoffeeScript and Bootstrap, to React and GraphQL, Artsy Engineering has evolved our frontend software to achieve
a quality worthy of art – both from the user's perspective and from the developer's. I'm very excited about what's
coming next, and I can't wait to share it with you. Have a great day!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Relay Network Deep Dive]]></title>
    <link href="http://artsy.github.io/blog/2018/07/25/Relay-Networking-Deep-Dive/"/>
    <updated>2018-07-25T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/07/25/Relay-Networking-Deep-Dive</id>
    <content type="html"><![CDATA[<blockquote><p>Hey all, we have another guest post, this one comes from <a href="https://github.com/sibelius">Sibelius Seraphini</a> - a very active contributor to
Relay and its eco-system. When we spotted he had wrote an amazing article on how the networking aspects of Relay
comes together, we wanted to expand his reach and inform more people on how Relay comes together.</p>

<p>-- Orta</p></blockquote>

<p>Data fetching is a hard problem for apps. You need to ask yourself a lot of questions: How do you ask for data from
a server? How do you handle authentication? When is the right time to request data? How can you ensure you have all
the necessary data to render your views? How can you make sure you're not over-fetching? Can you do lazy loading?
When should you trigger lazy loading of data? What about pre-fetching data?</p>

<p><a href="https://facebook.github.io/relay/">Relay</a> is a framework for building data-driven applications which handles data fetching for you. For an
introduction to Relay, read <a href="https://facebook.github.io/relay/">their docs</a>, and also check out my Relay talk at <a href="https://speakerdeck.com/sibelius/reactconfbr-is-relay-modern-the-future">React Conf BR</a>.</p>

<blockquote><p>You don’t deep dive if you don’t know how to swim</p></blockquote>

<a name="TL.DR.Relay.Modern.Network"></a>
<h2>TL;DR Relay Modern Network</h2>

<p>Relay will aggregate the data requirements (fragments) for your components, then create a request to fulfill it.
The API to do this is via the <a href="https://facebook.github.io/relay/docs/en/relay-environment.html">Relay Environment</a>:</p>

<blockquote><p>The Relay "Environment" bundles together the configuration, cache storage, and network-handling that Relay needs
in order to operate.</p></blockquote>

<p>This post focuses on the "network-handling" part, the <a href="https://facebook.github.io/relay/docs/en/network-layer.html">Network Layer</a>. The network layer's responsibility
is to make a request to a server (or a local graphql) and return the response data to Relay. Your implementation
should conform to either <a href="https://github.com/facebook/relay/blob/v1.6.0/packages/relay-runtime/network/RelayNetworkTypes.js#L79-L90">FetchFunction</a> for a Promise-like API, or <a href="https://github.com/facebook/relay/blob/v1.6.0/packages/relay-runtime/network/RelayNetworkTypes.js#L92-L107">SubscribeFunction</a> for an
Observable-like API.</p>

<p>This article will provide 5 implementations of a Relay Network Interface, each of one providing more capabilities
than the other one, eventually enabling GraphQL Live Queries and Deferrable Queries.</p>

<p>You can see the code for these 5 network layers on GitHub here, open source under MIT license:
<a href="https://github.com/sibelius/relay-modern-network-deep-dive">https://github.com/sibelius/relay-modern-network-deep-dive</a>.</p>

<!-- more -->


<a name="Simplest.Network.Layer"></a>
<h3>Simplest Network Layer</h3>

<p>The simplest network layer would; get the request, send it to a GraphQL server to resolve and return the data to
Relay environment.</p>

<pre><code class="js">const fetchFunction = async (
  request: RequestNode,
  variables: Variables,
  cacheConfig: CacheConfig,
  uploadables: ?UploadableMap
) =&gt; {
  // Most GraphQL APIs expect a POST with a JSON
  // string containing the query and associated variables
  const body = JSON.stringify({
    query: request.text, // GraphQL text from input
    variables
  })

  const headers = {
    Accept: "application/json",
    "Content-type": "application/json",
    authorization: getToken()
  }

  const response = await fetchWithRetries(ENV.GRAPHQL_URL, {
    method: "POST",
    headers,
    body,
    fetchTimeout: 20000,
    retryDelays: [1000, 3000, 5000, 10000]
  })

  const data = await response.json()

  // Mutations should throw when they have errors, making it easier
  // for client code to react
  if (isMutation(request) &amp;&amp; data.errors) {
    throw data
  }

  // We return the GraphQL response to update the Relay Environment
  // which updates internal store where relay keeps its data
  return data
}
</code></pre>

<a name="Network.that.Handle.Uploadables"></a>
<h3>Network that Handle Uploadables</h3>

<p>The GraphQL spec does not handle form data, and so if you need to send along files to upload to your server with a
mutation, you'll want to use the uploadables API in Relay when you commit the mutation.</p>

<p>Adding uploadables in a mutation will inevitably get passed to your network interface, where you'll need to change
your request body to use FormData instead of the JSON string above:</p>

<pre><code class="js">function getRequestBodyWithUploadables(request, variables, uploadables) {
  let formData = new FormData()
  formData.append("query", request.text)
  formData.append("variables", JSON.stringify(variables))

  Object.keys(uploadables).forEach(key =&gt; {
    if (Object.prototype.hasOwnProperty.call(uploadables, key)) {
      formData.append(key, uploadables[key])
    }
  })

  return formData
}
</code></pre>

<a name="Network.that.Caches.Requests"></a>
<h3>Network that Caches Requests</h3>

<p>This builds on top of the other 2 implementations, we use
<a href="https://github.com/facebook/relay/blob/v1.6.0/packages/relay-runtime/network/RelayQueryResponseCache.js#L24-L29">RelayQueryResponseCache</a>
to query GraphQL requests based on query and variables.</p>

<p>Every time a mutation happens, we should invalidate our cache as we are not sure how a change can affect all cached
query responses.</p>

<pre><code class="js">// Create our own in-memory cache
const relayResponseCache = new RelayQueryResponseCache({ size: 250, ttl: oneMinute })

const cacheHandler = async (
  request: RequestNode,
  variables: Variables,
  cacheConfig: CacheConfig,
  uploadables: UploadableMap
) =&gt; {
  const queryID = request.text

  // If it's a mutation, clear all cache, then call the implementation above
  if (isMutation(request)) {
    relayResponseCache.clear()
    return fetchFunction(request, variables, cacheConfig, uploadables)
  }

  // Try grab the request from the cache first
  const fromCache = relayResponseCache.get(queryID, variables)
  // Did it hit? Or did we suppress the cache for this request
  if (isQuery(request) &amp;&amp; fromCache !== null &amp;&amp; !forceFetch(cacheConfig)) {
    return fromCache
  }

  // Make the request, and cache it if we get a response
  const fromServer = await fetchFunction(request, variables, cacheConfig, uploadables)
  if (fromServer) {
    relayResponseCache.set(queryID, variables, fromServer)
  }

  return fromServer
}
</code></pre>

<a name="Network.using.Observable"></a>
<h3>Network using Observable</h3>

<p>Relay provides a limited implementation of the upcoming <a href="https://github.com/tc39/proposal-observable">ESObservables</a> spec. I recommend reading <a href="https://kriskowal.gitbooks.io/gtor/content/">A General
Theory of Reactivity</a> to understand why Observables are a great solution instead of promises in some
situations. Notably; a promise is one value in a time space, an observable is a stream of values in a time space.</p>

<!-- [TODO: Why Sink and not the Relay Observable? Observable is exported but has one more function (complete)] -->


<p>To work with this API, we're going to use a private interface for the observable object called Sink:</p>

<pre><code class="js">/**
 * A Sink is an object of methods provided by Observable during construction.
 * The methods are to be called to trigger each event. It also contains a closed
 * field to see if the resulting subscription has closed.
 */
export type Sink&lt;-T&gt; = {|
  +next: T =&gt; void,
  +error: (Error, isUncaughtThrownError?: boolean) =&gt; void,
  +complete: () =&gt; void,
  +closed: boolean
|}
</code></pre>

<p>Which is the shape of the Observable object we pass back to Relay:</p>

<pre><code class="js">const fetchFunction = async (
  request: RequestNode,
  variables: Variables,
  cacheConfig: CacheConfig,
  uploadables: ?UploadableMap,
  sink: Sink&lt;any&gt;
) =&gt; {
  const body = getRequestBody(request, variables, uploadables)

  const headers = {
    ...getHeaders(uploadables),
    authorization: getToken()
  }

  const response = await fetchWithRetries(ENV.GRAPHQL_URL, {
    method: "POST",
    headers,
    body,
    fetchTimeout: 20000,
    retryDelays: [1000, 3000, 5000, 10000]
  })

  const data = await handleData(response)

  if (isMutation(request) &amp;&amp; data.errors) {
    sink.error(data)
    sink.complete()

    return
  }

  sink.next(data)
  sink.complete()
}

// Instead of returning a Promise that will resolve a single GraphQL response.
// We return an Observable that could fulfill many responses before it finishes.

const executeFunction = (
  request: RequestNode,
  variables: Variables,
  cacheConfig: CacheConfig,
  uploadables: ?UploadableMap
) =&gt; {
  return Observable.create(sink =&gt; {
    fetchFunction(request, variables, cacheConfig, uploadables, sink)
  })
}
</code></pre>

<p>This is an implementation you would need when working with <a href="https://github.com/facebook/relay/issues/2174">GraphQL Live Queries</a> (based on polling), as you
are going to resolve the same query more than once.</p>

<a name="Deferrable.Queries.Network"></a>
<h3>Deferrable Queries Network</h3>

<p>A common case for deferrable queries is to lazy load fragments. This lets you get request content above the page
fold first, and then request additional data after. A good example is loading a Post's content first and then
subsequently loading all comments of this post after the post has finished.</p>

<p>Without deferrable queries you could simulate this using the <a href="https://facebook.github.io/relay/docs/en/graphql-in-relay.html#directives">@include</a> directive in your Relay fragment
and a <a href="https://facebook.github.io/relay/docs/en/refetch-container.html">refetch container</a>. When the component mounts the refetch container changes the variable used on
the <code>@include</code> to true and it will request the rest of the data.</p>

<p>The problem with above approach is that you need to wait for the component to mount before you can start the next
request. This becomes a bigger problem as React does more work asynchronously.</p>

<!-- TODO: There are no docs for relay deferrable -->


<p>An ideal deferrable query will start as soon as the previous query has finished, rather than depending on your
React components render cycles. Relay provides a <a href="https://github.com/facebook/relay/issues/2194#issuecomment-383466255">directive</a> for this: <code>@relay(deferrable: true)</code>:</p>

<pre><code class="js">const PostFragment = createFragmentContainer(Post, {
  post: graphql`
    fragment Post_post on Post {
      title
      commentsCount
      ...CommentsList_post @relay(deferrable: true)
    }
  `
})
</code></pre>

<p>In the fragment above, Relay will first get the <code>title</code> and <code>commentsCount</code> from the Post, then afterwards Relay
will get the data for <code>CommentsList_post</code> fragment. Sending both through the observable.</p>

<p>Here is the implementation of an execute function to handle a batched request:</p>

<pre><code class="js">const executeFunction = (
  request: RequestNode,
  variables: Variables,
  cacheConfig: CacheConfig,
  uploadables: ?UploadableMap
) =&gt; {
  return Observable.create(sink =&gt; {
    if (request.kind === "Request") {
      cacheHandler(request, variables, cacheConfig, uploadables, sink, true)
    }

    if (request.kind === "BatchRequest") {
      batchRequestQuery(request, variables, cacheConfig, uploadables, sink)
    }
  })
}
</code></pre>

<p>This execute function now can handle 2 types of requests:</p>

<ul>
<li>a single GraphQL query <code>Request</code></li>
<li>or a <code>BatchRequest</code> that could have be many queries with inter-related data</li>
</ul>


<p>So, what does the <code>batchRequestQuery</code> function look like?</p>

<!-- TODO: Annotate ths code, I'm not 100% what it's doing myself -->


<pre><code class="js">// Get variables from the results that have already been sent
const getDeferrableVariables = (requests, request, variables: Variables) =&gt; {
  const { argumentDependencies } = request

  if (argumentDependencies.length === 0) {
    return variables
  }

  return argumentDependencies.reduce((acc, ad) =&gt; {
    const { response } = requests[ad.fromRequestName]

    const variable = get(response.data, ad.fromRequestPath)

    // TODO - handle ifList, ifNull
    // See: https://github.com/facebook/relay/issues/2194
    return {
      ...acc,
      [ad.name]: variable
    }
  }, {})
}

// Execute each of the requests, and call `sink.next()` as soon as it has the GraphQL
/// server response data.
//
// It will only close the Observable stream when all requests has been fulfilled.
const batchRequestQuery = async (
  request: RequestNode,
  variables: Variables,
  cacheConfig: CacheConfig,
  uploadables: ?UploadableMap,
  sink: Sink&lt;ExecutePayload&gt;
) =&gt; {
  const requests = {}

  for (const r of request.requests) {
    const v = getDeferrableVariables(requests, r, variables)

    const response = await cacheHandler(r, v, cacheConfig, uploadables, sink, false)

    requests[r.name] = response
  }

  sink.complete()
}
</code></pre>

<a name="Relay.Modern.is.very.flexible"></a>
<h2>Relay Modern is very flexible</h2>

<p>Depending on your application needs, you can scale from a simpler Promise-based API for your custom network layer
to one that uses Observables to always resolves from cache data first and then resolves from the server.</p>

<p>Here are some production examples:</p>

<ul>
<li><p><a href="https://github.com/artsy/emission/blob/master/src/lib/relay/fetchQuery.ts">Artsy Emission</a>: Uses the Promise API, caches the results locally, and shares logic with native code in
an iOS app so that queries can be pre-cached before the JavaScript runtime has started.</p></li>
<li><p><a href="https://github.com/relay-tools/react-relay-network-modern">ReactRelayNetworkModern</a>: A network layer that uses the middleware pattern to separate responsibilities like
retrying, logging, caching and auth.</p></li>
<li><p><a href="https://github.com/facebook/relay/issues/2174#issuecomment-375274003">timobetina's example</a>: The simplest Observable network layer you can start with.</p></li>
</ul>


<!-- TODO: More, @sibelius do you have some good examples? -->


<a name="More.Resources"></a>
<h2>More Resources</h2>

<p>If you want to expand your understanding of GraphQL and Relay Modern, I have two great related resources:</p>

<ul>
<li><p>A boilerplate that uses dataloader to batch and cache requests to your database in a GraphQL API:
<a href="https://github.com/entria/graphql-dataloader-boilerplate">https://github.com/entria/graphql-dataloader-boilerplate</a></p></li>
<li><p>A simple boilerplate for working with Relay Modern and React Navigation:
<a href="https://github.com/entria/ReactNavigationRelayModern">https://github.com/entria/ReactNavigationRelayModern</a></p></li>
</ul>


<p>If you have questions about this or anything send me a DM on twitter
<a href="https://twitter.com/sseraphini">https://twitter.com/sseraphini</a></p>
]]></content>
  </entry>
  
</feed>
