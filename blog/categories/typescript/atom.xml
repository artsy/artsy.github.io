<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: typescript | Artsy Engineering]]></title>
  <link href="http://artsy.github.io/blog/categories/typescript/atom.xml" rel="self"/>
  <link href="http://artsy.github.io/"/>
  <updated>2018-06-01T16:50:00+00:00</updated>
  <id>http://artsy.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[JavaScriptures 2 - TypeScript]]></title>
    <link href="http://artsy.github.io/blog/2018/05/02/JavaScriptures-2-TypeScript/"/>
    <updated>2018-05-02T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/05/02/JavaScriptures-2-TypeScript</id>
    <content type="html"><![CDATA[<p>The second in our JavaScriptures series on the Artsy <a href="http://artsy.github.io/blog/2017/02/05/Front-end-JavaScript-at-Artsy-2017/">omakase</a>. This one is a deep dive in TypeScript with
a minor-focus on working with React. We run through a series of excercises you can run <a href="https://github.com/artsy/javascriptures/tree/master/2_intro-to-typescript">through yourself
here</a>.</p>

<p>It's ran by <a href="https://twitter.com/alloy">@alloy</a> and <a href="https://github.com/sarahscott">Sarah Scott</a> and covers compilation, errors, default types, interfaces,
inference, generics and how they all come together in your tools.</p>

<!-- more -->




<center>
<iframe width='100%' height='400' src='https://www.youtube.com/embed/KXPZvjCUlAA' frameborder='0' allowfullscreen></iframe>
</center>




<p style='text-align:right;'><a href="https://speakerdeck.com/artsyopensource/javascriptures-2-typescript">
Slides on Speakerdeck
</a></p>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apogee Technical Retrospective]]></title>
    <link href="http://artsy.github.io/blog/2018/02/06/apogee-technical-retrospective/"/>
    <updated>2018-02-06T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/02/06/apogee-technical-retrospective</id>
    <content type="html"><![CDATA[<p>We've previously covered <a href="/blog/2018/02/02/artsy-apogee/">what Apogee is</a> and <a href="/blog/2018/01/24/kubernetes-and-hokusai/">how it's deployed</a>, so all that's left to cover is the technology used to build it. As a refresher: Apogee is a Google Sheets Add-on we built to help our Auctions Ops team transform the data given to us by our partners into a format that our CMS can understand. This process, done manually up until now, takes a long time and is a perfect candidate for automation.</p>

<p>Apogee had some really interesting technical challenges that I enjoyed solving, and I'm excited to share some lessons I learned. So let's dive in!</p>

<!-- more -->


<p>We built a prototype as a "pure" Add-on, written only inside Google's sandbox, but that approach wouldn't work for us in production: the Add-on environment was just too difficult to work with. Google expects you to write Add-ons in their in-browser <a href="http://script.google.com">Script Editor</a> and ‚Äì while whether or not that editor is <em>good</em> is a matter of preference ‚Äì the environment isn't suited for collaborating or unit testing. Additionally, we could not get Add-on deploys automated, so we'd like to minimize how often we <em>have</em> to deploy.</p>

<p>So we split things up. Instead of building all Apogee's logic into an Add-on, we decided to build two pieces: a very thin Add-on and a Rails server with all the real logic.</p>

<p>(Because Apogee necessarily includes information about how our partners format their data, we decided not to open source it. Data formats are <em>probably</em> not sensitive, but that's a judgement best left up to our partners.)</p>

<a name="Apogee.Add-on"></a>
<h2>Apogee Add-on</h2>

<p>The Add-on we built is very simple, by design. Our goal was to make an Add-on that was flexible enough such that we would need to deploy it less frequently than adding new parsers.</p>

<p>Add-on responsibilities include:</p>

<ul>
<li>fetching the available parsers from the server.</li>
<li>setting up an Add-on user interface (a menu of partners, each with available parsers).</li>
<li>responding to invocations from that interface.</li>
</ul>


<p>Based on the parser selected by the user, Apogee gathers the required data from the current spreadsheet, sends it to the server for processing, and appends the results to the sheet. Pretty straightforward, you'd think.</p>

<p>Unfortunately, Google Add-ons are a bit... strange. The Add-on itself is executed in Google's datacentres (not the user's browser) and is written in <a href="https://developers.google.com/apps-script/guides/services/#basic_javascript_features">JavaScript 1.6-ish</a>. Specifically, it runs with JavaScript 1.6, plus some features from 1.7, plus some other features from 1.8, and also <a href="https://developers.google.com/apps-script/guides/services/advanced">"Google Advanced Services"</a>. The execution environment also lacks an event loop, which makes sense from Google's perspective (their servers need to know if a script execution has completed) but is still a bit unusual.</p>

<p>Rather than deal with a weird version of JavaScript, we decided to write the Add-on in <a href="https://www.typescriptlang.org">TypeScript</a> and compile down to something Google can execute. We also found <a href="https://www.npmjs.com/package/@types/google-apps-script">open source typings</a> for the Google APIs, which helped a lot. Google also provides access to certain whitelisted libraries, including <a href="https://lodash.com">Lodash</a>, which is handy.</p>

<p>Add-ons also have a somewhat complex permissions and authentication model. The <a href="https://developers.google.com/apps-script/add-ons/lifecycle">documentation</a> provided is a great illustration of why <em>complete</em> documentation is not necessarily <em>effective</em> documentation. If you already understand what you're doing, the docs are a good reference, but I found them difficult to learn from. I really like <a href="https://twitter.com/kosamari/status/852319140060823553">this explanation</a> of how to structure documentation like unit tests.</p>

<p>Permissions vary wildly depending on the execution context. For example, the <code>onOpen</code> callback is able to make network requests when the script is run as an attachment to a spreadsheet, but not when deployed. This makes it difficult to populate our menu UI, which is based off an API response. I learned to not have confidence everything was working until I saw it work end-to-end.</p>

<p>One other peculiarity of Google's API is how UI callbacks work. You could create a menu for your Add-on with the following code:</p>

<pre><code class="js">SpreadsheetApp.getUi()
  .createAddonMenu()
  .addItem('Do something', 'doSomething')
  .addToUi()

function doSomething() {
}
</code></pre>

<p>You'll notice that the callback function is specified by a <em>string</em> representing a function name (and not as a function itself, which would be more idiomatic). So, for every menu item, there must exist a corresponding function in the global scope with a corresponding name. Sadly, no parameters are passed to these callbacks, so it's impossible for a function to determine which menu item it was invoked by. Therefore, every menu item <em>must</em> have exactly <em>one</em> corresponding function. That presents a problem for an Add-on with a dynamic menu.</p>

<p>The Add-on isn't executed in a browser; we're running on Google's datacentres so let's just brute-force this. Our menu is a list of partner names, which is itself a submenu of parsers specific to that partner. That means that each menu item (and corresponding callback) can be indexed by two integers: a partner index and a operation index. So now we have a way to map from our user interface to a specific operation to perform inside <em>one</em> common menu handler.</p>

<p>Let's take a look at the actual code.</p>

<pre><code class="ts">interface Operation {
  name: string
  columns: string[]
  token: string
}

interface Partner {
  name: string
  operations: Operation[]
}

// Sets up the Add-on menu and submenus.
function setupAddon(ui: Partner[]) {
  // Reduce the ui to a list of submenus.
  const addOnMenu = ui.reduce((menu, partner, partnerIndex) =&gt; {
    // Reduce the operations list to a list of menu items.
    return menu.addSubMenu(partner.operations.reduce((memo, operation, operationIndex) =&gt; {
      return memo.addItem(operation.name, `partner${partnerIndex}Operation${operationIndex}`)
    }, SpreadsheetApp.getUi().createMenu(partner.name)))
  }, SpreadsheetApp.getUi().createAddonMenu())
  // Add the generated menu to the Add-on UI.
  addOnMenu.addToUi()
}
</code></pre>

<p>Each menu has a callback function named something like <code>partnerXOperationY</code>. Then we just generated a few thousand functions that match that format and call a shared handler <em>with</em> <code>X</code> and <code>Y</code> as parameters. The generated code looks like this:</p>

<pre><code class="js">function partner0Operation0() {
    sharedHandler(0, 0);
}
function partner0Operation1() {
    sharedHandler(0, 1);
}
function partner0Operation2() {
    sharedHandler(0, 2);
}

function sharedHandler(partnerIndex, operationIndex) {
    // TODO: Look up the appropriate parser to use.
}
</code></pre>

<p>It's not elegant, but it works. Actually, I think it does have a certain elegance, given the constraints it has to operate within.</p>

<p>So that's it! The rest of the challenges were just weird permissions issues or config problems, but the Add-on was pretty easy to build. The file generated by the TypeScript compiler is only 166 lines long, and the file with all our menu callbacks is "only" 8000 lines long. Next, let's talk about the server.</p>

<a name="Apogee.Server"></a>
<h2>Apogee Server</h2>

<p>So, Rails' philosophy is "<a href="https://en.wikipedia.org/wiki/Convention_over_configuration">convention over configuration</a>", which is pretty great as long as you know the conventions. I'd never run <code>rails new</code> before. Also, that philosophy works best when you're building <em>conventional</em> apps. Because Apogee is a bit unconventional, I was going to write Apogee in Sinatra before my colleague suggested I use Rails in <a href="http://guides.rubyonrails.org/api_app.html">API-only mode</a> instead. It seemed a bit overkill, but I also didn't want to pass up the chance to finally learn Rails.</p>

<p>The server has two endpoints:</p>

<ul>
<li><code>/ui</code> provides a list of partners and their respective parsers.</li>
<li><code>/columns</code> accepts spreadsheet columns and returns processed data (cell contents and a background colour to indicate our confidence in parsed results).</li>
</ul>


<p>We needed a way for the server to specify all its operations in a way that they could be invoked through the second endpoint. We decided to use a token-based approach: each parser has a token that can be used to invoke the parser later on. This dovetails with how I structured the parsers, too.</p>

<p>Each partner is defined by a submodule within the <code>Apogee::Parser</code> module, and each parser is defined by a class within that partner module. Let's take a look at some code.</p>

<pre><code class="rb">module Apogee
  module Parser
    module Skinner
      extend Apogee::BaseParser

      class DimensionsParser
        # Name to show in Add-on UI.
        def self.menu_name
          "Parse dimensions from Description column"
        end

        # Columns required by the `/columns` endpoint.
        def self.column_names
          %w[Description]
        end

        # Parse the columns, called from the `/columns` endpoint.
        def self.parse(columns)
          # TODO: parse the columns.
        end
      end
    end
  end
end
</code></pre>

<p>Each class within a partner is expected to have those three class methods.</p>

<p>So now that we have a defined structure for our parsers, we can use Ruby reflection to collect a list of partner modules:</p>

<pre><code class="rb">Parser.constants
  .select { |c| Parser.const_get(c).is_a? Module }
  .map do |c|
    {
      name: c,
      operations: Parser.const_get(c).public_parsers
    }
end
</code></pre>

<p>Each module also has a <code>public_parsers</code> function (inherited from <code>Apogee::BaseParser</code>) which also uses reflection:</p>

<pre><code class="rb">def public_parsers
  constants
    .select { |c| const_get(c).is_a? Class }
    .map { |c| const_get(c) }
    .map do |klass|
      {
        klass: klass.to_s,
        name: klass.menu_name,
        columns: klass.column_names,
        token: Digest::SHA256.base64digest(klass.to_s)
      }
    end
end
</code></pre>

<p>This code collects all the Ruby classes inside a module into a data structure that can be consumed by the Apogee Add-on through the <code>/ui</code> endpoint. As a bonus, the tokens are generated from the SHA256 hash of the fully-qualified parser class names. And we also avoid having to maintain a separate list of parsers that I would inevitably forget to update. Win-win.</p>

<p>All that's left to do is to lookup a parser class from a token. This is as easy as finding the class with the matching token and calling its <code>parse</code> function.</p>

<pre><code class="rb">parser = partners
  .map { |p| p[:operations] }
  .flatten
  .find { |op| op[:token] == token }
Object.const_get(parser[:klass]).parse(columns)
</code></pre>

<p>Neat!</p>

<p>This approach is <em>good</em>, but strikes me as overly object-oriented. <em>Most</em> of the parsers we're going to write are going to do the same thing: they have the same three methods and the <code>parse</code> method is basically just matching each spreadsheet cell against a regular expression. We can make a better abstraction.</p>

<p>Since the parsers are defined by the presence of a class within a partner module, we can use metaprogramming to abstract away all the common pieces and add classes to the module programmatically. The implementation is too in-depth to explain in detail here, but our partner module above could be rewritten to look like the following:</p>

<pre><code class="rb">module Apogee
  module Parser
    module Skinner
      extend Apogee::BaseParser

      add_single_column_parser(
        class_name: 'DimensionsParser',
        menu_name: 'Parse dimensions from Description column',
        column_name: 'Description',
        regex: %r{REGEX GOES HERE},
        new_columns: %w[Height Width Depth Unit]
      ) do |match|
        # TODO: Process each cell.
      end
    end
  end
end
</code></pre>

<p>I created two such methods: one that uses a single regex, and another that uses multiple regexes (for more complex needs). I also wrote a handy <code>add_all_parser</code> method which adds a sort of meta-parser, which collates the results from calling <code>parse</code> on all the <em>other</em> parsers in that module. Our Ops team just needs to click "Parse everything" and the entire spreadsheet is processed with all the parsers in seconds.</p>

<p>And of course, since all our parsers are just Ruby classes, they were easy to unit test.</p>

<p>I've done metaprogramming in other languages, and it was a lot of fun to use it in Ruby. I ran the code by my colleagues who are more experienced in Ruby than I am, and documented everything thoroughly. It's a real shame the codebase isn't open source, because I'm really proud of the approach and would love to share it with you.</p>

<a name="Apogee.Authentication"></a>
<h2>Apogee Authentication</h2>

<p>We needed to make sure that only the Add-on itself was invoking the server's endpoints. Not because the server has sensitive data ‚Äì Apogee's server has no database and doesn't access any APIs ‚Äì but just because it's good practice to limit access to services to only who needs them.</p>

<p>We evaluated a bunch of prospective auth strategies, including (but not limited to) the following:</p>

<ul>
<li>Whitelist Google datacentre IP addresses, block all others.</li>
<li>HTTP Basic Auth.</li>
<li>Shared secret.</li>
<li>OAuth with Artsy's API, by the user upon Add-on installation.</li>
<li>Something totally custom, or a combination of any of these.</li>
</ul>


<p>After thoughtful discussion, we decided on a solution that works for us. I'm not going to specify what we used ‚Äì not because I'm that concerned about the security, but because each project and team will have their own needs. If you build a server, think carefully about what kind of authentication makes sense for you and your team.</p>

<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Apogee was a really fun project. It had a defined scope, so it was a good first Rails project for me to tackle. The Add-on helps my colleagues on the Auctions Ops team do their jobs easier, so it was intrinsically rewarding to build. And it turns out that our Gallery Partnerships team also has to import a lot of partner data into Artsy's CMS, so I'm now exploring ways Apogee can help them, too.</p>

<p>As a closing note, I want to discuss something that's been on my mind lately. I've been developing iOS apps <a href="https://ashfurrow.com/blog/5-years-of-ios/">since 2009</a>, and have a <a href="https://ashfurrow.com/books/">very intimate knowledge</a> of Objective-C, Swift, and UIKit. For a long time, I actually avoided learning new languages and frameworks because they intimidated me ‚Äì starting over in a new framework, from scratch, felt like a step backward.</p>

<p>I think this is a common frame of mind, among iOS developers, among all developers. But now I regret avoiding new technology for so long. The languages and tools that I knew had become part of my identity: I was an "iOS Developer." That identity was a source of strength, but was also a limitation.</p>

<p>Developers solve problems. Sometimes those problems are best solved with iOS apps. And sometimes, they're best solved with spreadsheet plugins. After <a href="https://ashfurrow.com/blog/swift-vs-react-native-feels/">realizing</a> last year that I was limiting myself, I'm still coming to terms with how that impacts my identity. But I'll say this: if <em>I</em> can leave the safety blanket of the iOS world and build something completely new, so can you. Don't let your expertise and experience limit what you think you can build.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Babel 7 + TypeScript]]></title>
    <link href="http://artsy.github.io/blog/2017/11/27/Babel-7-and-TypeScript/"/>
    <updated>2017-11-27T14:18:00+00:00</updated>
    <id>http://artsy.github.io/blog/2017/11/27/Babel-7-and-TypeScript</id>
    <content type="html"><![CDATA[<p>At Artsy we &lt;3 <a href="https://www.typescriptlang.org/">TypeScript</a>. We use it with React Native via <a href="https://github.com/artsy/emission">Emission</a> and on the web via <a href="https://github.com/artsy/reaction">Reaction</a>. Until recently, however, projects that required the use of Babel had to implement convoluted tooling pipelines in order to work with the TypeScript compiler, increasing friction in an already complex landscape. (An example of this is Emission's use of Relay, which requires <a href="https://facebook.github.io/relay/docs/babel-plugin-relay.html#setting-up-babel-plugin-relay">babel-plugin-relay</a> to convert <code>graphql</code> literals into require calls.) Thankfully, those days <a href="https://github.com/babel/babel/tree/master/packages/babel-preset-typescript">are over</a>. Read on for an example project, as well as some advice on how to avoid common pitfalls when working with the new beta version of Babel 7.</p>

<!-- more -->


<p>Babel configurations can be complicated. They take time to set up and maintain and can often contain some pretty <a href="https://github.com/kentcdodds/babel-macros">far-out features</a> that make interop with other environments difficult. That's why we were elated when <a href="https://github.com/babel/babylon/pull/523">this PR</a> appeared in the wild from <a href="https://github.com/andy-ms">@andy-ms</a>, a developer on the TypeScript team, announcing a new parser for Babylon. <a href="https://github.com/babel/babel/tree/master/packages/babel-preset-typescript">@babel/preset-typescript</a> arrived soon after and we felt it was finally time to give it a try. There was a catch, however: TypeScript support only works with Babel 7+!</p>

<p><strong>TLDR; <a href="https://github.com/damassi/babel-7-typescript-example" target="_blank">Check out the project on GitHub ></a></strong></p>

<p>Here's list of setup issues we faced in no specific order:</p>

<a name="L1..New..babel.Namespace"></a>
<h2>1) New @babel Namespace</h2>

<p>One of the first things Babel 7 users will notice is the package ecosystem now exists as a <a href="https://github.com/babel/babel/tree/master/packages">monorepo</a> and all NPM modules are namespaced behind the <code>@babel</code> org address. Packages that used to be installed via</p>

<pre><code class="sh">yarn add -D \
  babel-core \
  babel-preset-react \
  babel-preset-stage-3
  ...
</code></pre>

<p>are now installed via
<code>sh
yarn add -D \
  @babel/core \
  @babel/preset-react \
  @babel/preset-stage-3
  ...
</code>
which immediately creates upgrade conflicts between libraries that use Babel 6 and Babel 7. For example, <code>babel-jest</code> internally points to <code>babel-core</code> which supports a <a href="https://github.com/facebook/jest/blob/master/packages/babel-jest/package.json#L19">version range between 6 and 7</a> -- but! -- <code>babel-core</code> is now <code>@babel/core</code> so this breaks.</p>

<p>This wasn't immediately apparent at the time, and so we would often find errors like</p>

<pre><code class="sh">Error: Could not find preset "@babel/env" relative to directory
</code></pre>

<p>These errors appeared ambiguous because the folder structure was correct and commands like <code>yarn list @babel/preset-env</code> yielded expected results:</p>

<pre><code class="sh">‚îî‚îÄ @babel/preset-env@7.0.0-beta.32
‚ú®  Done in 0.58s.
</code></pre>

<p>Why was the package not found? Digging deeper, it seemed like Babel 6 was still being used somewhere. Running <code>yarn list babel-core</code> revealed the culprit:</p>

<pre><code class="sh">‚îî‚îÄ babel-core@6.25.0
‚ú®  Done in 0.58s.
</code></pre>

<p>Thankfully, <a href="https://github.com/babel/babel-bridge">babel-bridge</a> exists to "bridge" the gap, but one can see how complications can and will arise. Further, not all packages have implemented this fix and so we had to rely on <code>yarn</code>'s new <a href="https://yarnpkg.com/lang/en/docs/selective-version-resolutions/">selective dependency resolution</a> feature which overrides child dependency versions with a fixed number set directly in <code>package.json</code>:</p>

<pre><code class="json">"resolutions": {
  "babel-core": "^7.0.0-bridge.0"
},
</code></pre>

<p>With this in place many of our errors disappeared and packages like <code>jest</code> now worked like a charm.</p>

<a name="L2..Missing.ES2015.Features"></a>
<h2>2) Missing ES2015 Features</h2>

<p>Another error we faced early on surrounded language features that worked with Babel <em>or</em> TypeScript, but not with Babel <em>and</em> TypeScript. For example, take an existing Babel project that points to <code>index.js</code> as an entrypoint, configure it to support TypeScript via Babel 7, and then run it:</p>

<pre><code class="json">"scripts": {
  "start": "babel-node index.js"
}
</code></pre>

<pre><code class="js">// index.js
require('@babel/register', {
  extensions: ['.js', '.jsx', '.ts', '.tsx']
})
require('app/server.ts')
</code></pre>

<pre><code class="javascript">// app/server.ts
console.log('hi!')
</code></pre>

<p>Running</p>

<pre><code class="sh">yarn start
$ babel-node index.js

hi!
‚ú®  Done in 1.88s.
</code></pre>

<p>Everything seems to be working; our <code>.js</code> entrypoint is configured to support <code>.ts</code> extensions and we kick off the boot process.</p>

<p>Let's now try to import a file from within <code>app/server.ts</code>:</p>

<pre><code class="javascript">import path from 'path'
console.log(`Hello ${path.resolve(process.cwd())}!`)
</code></pre>

<pre><code class="sh">yarn start
$ yarn run v1.3.2
$ babel-node index.js
sites/src/index.tsx:1
(function (exports, require, module, __filename, __dirname) { import path from 'path'
                                                              ^^^^^^

SyntaxError: Unexpected token import
</code></pre>

<p>Maybe my <code>tsconfig.json</code> file is misconfigured?</p>

<pre><code class="json">{
  "compilerOptions": {
    "module": "es2015"
  }
}
</code></pre>

<p>Nope, all good. How about my <code>.babelrc</code>?</p>

<pre><code class="json">{
  "presets": [
    ["@babel/env", {
      "targets": {
        "browsers": ["last 2 versions"]
      }
    }],
    "@babel/stage-3",
    "@babel/react",
    "@babel/typescript"
  ]
}
</code></pre>

<p>We're using <a href="https://github.com/babel/babel/tree/master/packages/babel-preset-env"><code>@babel/preset-env</code></a> which handles selecting the JS features we need, so thats not it. And anyways, doesn't TypeScript support <code>ES2015</code> modules right out of the box?</p>

<p>Continuing, how about specifying the extension list directly in <code>package.json</code>:</p>

<pre><code class="json">"start": "babel-node --extensions '.ts,.tsx' index.js"
</code></pre>

<p>Still no go üôÅ</p>

<p>Last try: Create a new entrypoint file that uses a <code>.ts</code> extension and then use <em>that</em> to boot the rest of the app:</p>

<pre><code class="json">"start": "babel-node --extensions '.ts,.tsx' index.ts"
</code></pre>

<pre><code class="javascript">// index.ts
import './app/server'
</code></pre>

<pre><code class="sh">yarn start
$ yarn run v1.3.2
$ babel-node index.js
Hello /sites!
</code></pre>

<p>Once this change was in place, we could ditch <code>@babel/register</code> and instead rely on the <code>--extensions</code> configuration from <code>package.json</code>, just like the <a href="https://github.com/babel/babel/tree/master/packages/babel-preset-typescript">README</a> suggests (doh! ü§¶).</p>

<p><strong>NOTE:</strong> If you're using <a href="https://github.com/tleunen/babel-plugin-module-resolver"><code>babel-plugin-module-resolver</code></a> to support absolute path imports make sure to update the <code>extensions</code> <a href="https://github.com/tleunen/babel-plugin-module-resolver#options">option</a> with <code>.ts</code> and <code>.tsx</code>.</p>

<a name="L3..Type-Checking"></a>
<h2>3) Type-Checking</h2>

<p>Lastly, since Babel 7 is now responsible for compiling our TypeScript files we no longer need to rely on TypeScript's own <code>tsc</code> compiler to output JavaScript and instead just use it to type-check our code. Again, in <code>package.json</code>:</p>

<pre><code>"type-check": "tsc"
</code></pre>

<p>This reads in settings located in <code>tsconfig.json</code>:
<code>json
{
  "compilerOptions": {
    "noEmit": true,
    "pretty": true
    ...
  }
}
</code></p>

<p>Notice the <code>noEmit</code> flag? That tells <code>tsc</code> not to output any JS and instead only check for correctness. The "pretty" flag gives us nicer type-checker output.</p>

<p>While this seemed to be all that was needed, running <code>yarn type-check</code> would throw an error:</p>

<pre><code>$ yarn type-check
yarn run v1.3.2
$ tsc

node_modules/@types/jest/index.d.ts(1053,34): error TS2304: Cannot find name 'Set'.

1053         onRunComplete?(contexts: Set&lt;Context&gt;, results: AggregatedResult): Maybe&lt;Promise&lt;void&gt;&gt;;
                                      ~~~

error Command failed with exit code 1.
</code></pre>

<p>Why is it TypeChecking my <code>node_modules</code> folder when <code>rootDirs</code> is set to <code>src</code>? It looks like we missed a TypeScript setting:</p>

<pre><code class="json">{
  "compilerOptions": {
    "skipLibCheck": true
  }
}
</code></pre>

<p>With that last missing piece everything now works:</p>

<pre><code class="sh">yarn type-check -w
yarn run v1.3.2
$ tsc -w

src/index.tsx(5,7): error TS2451: Cannot redeclare block-scoped variable 'test'.

5 const test = (foo: string) =&gt; foo
        ~~~~

src/index.tsx(6,6): error TS2345: Argument of type '2' is not assignable to parameter of type 'string'.

6 test(2)
       ~
</code></pre>

<p>Proper type-checking, but compilation handled by Babel üòé.</p>

<a name="L4..TypeScript.and.Flow"></a>
<h2>4) TypeScript and Flow</h2>

<p>Unfortunately, the TypeScript and Flow plugins for Babel cannot be loaded at the same time, as there could be ambiguity about how to parse some code.</p>

<p>This is usually ok, because the general advice is to compile your library code to vanilla JS before publishing (and thus strip type annotations), but there are packages that could still enable the Flow plugin.</p>

<p>For example, <a href="https://github.com/babel/babel/pull/6118">the React Babel preset</a> in the past would enable the Flow plugin without really needing it for its own source, but just as a default for consumers of React.</p>

<p>This issue cannot really be worked around without patching the code that loads the plugin. Ideally this patch would be sent upstream so that the issue goes away for everybody.</p>

<p>This issue can be worked around by either eliminating the dependency on the preset that loads the plugin, for instance by depending on the individual plugins directly, or if that‚Äôs not possible by patching the code. Ideally that patch should go upstream, of course, but if you need something immediate then we highly recommend <a href="https://github.com/ds300/patch-package">patch-package</a>, as can be seen used in <a href="https://github.com/artsy/emission/pull/780/files#diff-29cf179661e0495e62e9cd67dd0307dd">this example</a>.</p>

<p>There‚Äôs even projects that publish their Flow annotated code <em>without</em> compiling/stripping type annotations, the one we know of and use is <a href="https://github.com/facebook/react-native/issues/7850#issuecomment-225415645">React Native</a>. There‚Äôs no way around this other than patching the code. You may think that you could use a plugin like <a href="https://babeljs.io/docs/plugins/transform-flow-strip-types/">babel-plugin-transform-flow-strip-types</a>, but in reality that transform needs the Flow plugin to be able to do its work and thus is a no-go.</p>

<p>The way we‚Äôve worked around that is by <a href="https://github.com/artsy/emission/pull/780/files#diff-b9cfc7f2cdf78a7f4b91a753d10865a2R36">stripping Flow type annotations from <em>all</em> dependencies</a> at <a href="https://github.com/artsy/emission/pull/780/files#diff-b9cfc7f2cdf78a7f4b91a753d10865a2R39">dependency install time</a> using the <a href="https://github.com/flowtype/flow-remove-types"><code>flow-remove-types</code> tool</a>. It can get a little slow on many files which is why we do a bunch of filtering to only process files that have <code>@flow</code> directives, the downside is that some files don‚Äôt have directives like they should and so <a href="https://github.com/artsy/emission/pull/780/files#diff-d6d30dd9bd4cdb1ac0d1268937508814R65">we patch those to add them</a> using the aforementioned <a href="https://github.com/ds300/patch-package">patch-package</a>.</p>

<a name="L5..Limitations.in.TypeScript.support"></a>
<h2>5) Limitations in TypeScript support</h2>

<p>It is important to note that you <em>may</em> run into a few cases that TypeScript‚Äôs Babel plugin does/can not support. From <a href="https://github.com/babel/babel/blob/master/packages/babel-plugin-transform-typescript/README.md#babelplugin-transform-typescript">the plugin‚Äôs README</a>:</p>

<blockquote><p>Does not support <code>namespace</code>s or <code>const enum</code>s because those require type information to transpile.
Also does not support <code>export =</code> and <code>import =</code>, because those cannot be transpiled to ES.next.</p></blockquote>

<p>The lack of namespace support hasn‚Äôt been a problem for us, we‚Äôre only using it in one place which could easily be changed to use regular ES6 modules as namespace. This is also why for instance the ‚Äòrecommended‚Äô list of TSLint checks includes <a href="https://palantir.github.io/tslint/rules/no-namespace/">the <code>no-namespace</code> rule</a>.</p>

<p>The <code>const enum</code> feature is a runtime optimization that will cause the compiler to inline code. We don‚Äôt have a need for this at the moment, but <a href="https://github.com/babel/babel/issues/6476">some discussion</a> is happening to possibly still being able to make use of this feature when compiling production builds with the TypeScript compiler instead.</p>

<p>The <code>export =</code> and <code>import =</code> syntax is meant to <a href="https://github.com/Microsoft/TypeScript-Handbook/blob/master/pages/Modules.md#export--and-import--require">work with CommonJS and AMD modules</a>; however, we strictly use ES6 modules.</p>

<p><strong>References:</strong></p>

<ul>
<li><a href="https://github.com/damassi/babel-7-typescript-example">babel-7-typescript-example</a></li>
<li><a href="https://github.com/babel/babel/tree/master/packages/babel-preset-typescript">babel-preset-typescript</a></li>
<li><a href="https://github.com/artsy/emission">emission</a></li>
<li><a href="https://github.com/artsy/reaction">reaction</a></li>
<li><a href="https://github.com/ds300/patch-package">patch-package</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Modernizing Force]]></title>
    <link href="http://artsy.github.io/blog/2017/09/05/Modernizing-Force/"/>
    <updated>2017-09-05T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2017/09/05/Modernizing-Force</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/artsy/force">Force</a> is Artsy's main website, <a href="https://www.artsy.net">artsy.net</a>. In the three years since it was <a href="http://artsy.github.io/blog/2014/09/05/we-open-sourced-our-isomorphic-javascript-website/">open-sourced</a>, it has provided a solid foundation to build features on top of without a lot of the costs associated with growth. It is an early example of Isomorphic ("universal") JavaScript, built on top of Express, Backbone, CoffeeScript, Stylus and Jade. It is also highly modular, adopting patterns laid down by its parent project,  <a href="https://github.com/artsy/ezel">Ezel</a>.</p>

<p>When first developed these technologies made a lot of sense; CoffeeScript fixed many of the problems with JavaScript pre-ES6, and Jade / Stylus made working with HTML / CSS much more elegant. As time progressed and new technologies became a thing these solutions starting feeling more burdensome to continue building features with and many of our developers longed to start using next-generation tools like React.</p>

<!-- more -->


<p>Looking at output from <code>cloc</code>, the question is "But how?"</p>

<pre><code class="js">[artsy/force] $ cloc desktop mobile

--------------------------------------------------------
Language                     files                  code
--------------------------------------------------------
CoffeeScript                  1828                 81569
CSS                              9                 76632
Stylus                         577                 32324
JavaScript                     274                 18310
JSON                            30                  6145
Markdown                        41                  1097
HTML                             3                    25
XML                              3                    24
--------------------------------------------------------
SUM:                          2765                216126
--------------------------------------------------------
</code></pre>

<p>216k+ LOC, spread across multiple languages and formats. Given finite resources and a small team rebuilds can be difficult to execute, and so we had to figure out a way to marry the old with the new while also maintaining backwards compatibility / interoperability. Out of this exercise came a few patterns, libraries and projects that I would like to describe in an effort to help those caught in similar situations.</p>

<a name="Step.1:.Get.Your.House..aka.Compiler..in.Order"></a>
<h2>Step 1: Get Your House (aka Compiler) in Order</h2>

<p><a href="https://babeljs.io/">Babel</a> has been around for a while, but lately their team has been putting effort into making it as easy as possible to use. By dropping a <a href="https://github.com/artsy/force/blob/master/.babelrc">.babelrc</a> file into the root of your project, server and client-side JavaScript can share the same configuration, including <a href="https://github.com/tleunen/babel-plugin-module-resolver">module resolution</a> (aka, no more <code>../../../</code>).</p>

<p>A simplified example:</p>

<pre><code class="json">// .babelrc

{
  "presets": ["es2015", "react", "stage-3"],
  "plugins": [
    ["module-resolver", {
      "root": ["./"]
    }]
  ]
}
</code></pre>

<pre><code class="js">// index.js

require('coffee-script/register')
require('babel-core/register')

// Start the app
require('./boot')
</code></pre>

<p>On the client, we use <a href="http://browserify.org/">Browserify</a> with <a href="https://github.com/substack/coffeeify">Coffeeify</a> and <a href="https://github.com/babel/babelify">Babelify</a>:</p>

<pre><code class="json">// package.json

{
  "scripts": {
    "assets": "browserify -t babelify -t coffeeify -o bundle.js",
    "start": "yarn assets &amp;&amp; node index.js"
  }
}
</code></pre>

<p>And then boot it up:
<code>sh
$ yarn start
</code></p>

<p>By adding just a few lines, our existing CoffeeScript pipeline was augmented to support modern JavaScript on both the server and the client, with code that can be shared between.</p>

<a name="Step.2:.Tune-up.Iteration.Time"></a>
<h2>Step 2: Tune-up Iteration Time</h2>

<p><a name="iteration-time"></a></p>

<p>A question that every developer should ask of their stack is:</p>

<blockquote><p>"How long does it take for me to make a change and see that change reflected in a running process?"</p></blockquote>

<p>Does your code take one second to compile, or ten? When writing a back-end service, does your server <a href="https://github.com/remy/nodemon">automatically restart</a> after you make a change, or do you need to <code>ctrl+c</code> (stop it) and then restart manually?</p>

<p>For those of us working in Force, the bottleneck typically involved making changes to back-end code. Due to how we organize our sub-apps, client-side code compilation -- after the server heats up -- is pretty much instant, but that heat-up time can often take a while depending on which app we're working on. So even with a "restart on code change" setup that listens for updates it still felt terribly slow, and this iteration time would often discourage developers from touching certain areas of the codebase. We needed something better!</p>

<p>Enter Webpack and React, which helped popularize the concept of HMR, or "Hot Module Replacement".</p>

<p>From the Webpack docs:</p>

<blockquote><p>"Hot Module Replacement (HMR) exchanges, adds, or removes modules while an application is running, without a full reload."</p></blockquote>

<p>That's more like it! But is there anything similar for the server given we don't use Webpack? This was the question <a href="https://github.com/alloy">@alloy</a>, one of our Engineering Leads, asked himself while researching various setups that ultimately led to <a href="https://github.com/artsy/reaction">Reaction</a>, and for which he found an answer to in Glen Mailer's excellent <a href="https://github.com/glenjamin/ultimate-hot-reloading-example">ultimate-hot-reloading-example</a>. Digging into the code, <a href="https://github.com/glenjamin/ultimate-hot-reloading-example/blob/master/server.js#L38-L45">this little snippet</a> jumped out:</p>

<pre><code class="js">watcher.on('ready', function() {
  watcher.on('all', function() {
    console.log("Clearing /server/ module cache from server");
    Object.keys(require.cache).forEach(function(id) {
      if (/[\/\\]server[\/\\]/.test(id)) delete require.cache[id];
    });
  });
});
</code></pre>

<p>The code seemed simple enough -- on change, iterate through Node.js's internal require cache, look for the changed module, and clear it out. When the module is <code>require</code>'d at a later point it will be like it was required for the first time, effectively hot-swapping out the code.</p>

<p>With this knowledge we wrapped a modified version of this snippet into <a href="https://github.com/artsy/express-reloadable">@artsy/express-reloadable</a>, a small utility package meant to be used with Express.</p>

<p>Here's a full example:</p>

<pre><code class="js">import express from 'express'
import { createReloadable, isDevelopment } from '@artsy/express-reloadable'

const app = express()

if (isDevelopment) {

  // Pass in app and current `require` context
  const reloadAndMount = createReloadable(app, require)

  // Note that if you need to mount an app at a particular root (`/api`), pass
  // in `mountPoint` as an option.
  app.use('/api', reloadAndMount(path.resolve(__dirname, 'api'), {
    mountPoint: '/api'
  }))

  // Otherwise, just pass in the path to the express app and everything is taken care of
  reloadAndMount(path.resolve(__dirname, 'client'))
} else {
  app.use('/api', require('./api')
  app.use(require('./client')
}

app.listen(3000, () =&gt; {
  console.log(`Listening on port 3000`)
})
</code></pre>

<p>In Force, we mounted this library <a href="https://github.com/artsy/force/blob/master/lib/setup.js#L205">at the root</a>, allowing us to make changes anywhere within our numerous sub-apps and with a fresh page reload instantly see those changes reflected without a restart. This approach also works great with API servers, as this implementation from Artsy's <a href="https://github.com/artsy/positron/blob/master/boot.js#L34">editorial app Positron</a> shows. Like magic, it "just works". Why isn't this trick more widely used and known?</p>

<a name="Step.3:.The.View.Layer..or:.How.I.Stopped.Worrying.and.Learned.to.Love.Legacy.UI"></a>
<h2>Step 3: The View Layer, or: How I Stopped Worrying and Learned to Love Legacy UI</h2>

<p>This one was a bit tricky to solve, but ultimately ended up being fairly straightforward and conceptually simple. In Force, we've got dozens of apps built on top of hundreds of components supported by thousands of tests stretched across desktop and mobile. From the perspective of sheer code volume these things aren't going anywhere any time soon. On top of that, our view templates are built using Jade (now known as <a href="https://pugjs.org">Pug</a>), which supports an interesting form of inheritance known as <a href="https://pugjs.org/language/inheritance.html">blocks</a>. What this means in practice is our UI has been extended in a variety of complex ways making alternative view engines difficult on the surface to interpolate.</p>

<p>What to do? It's 2017 and the era of handlebars templates bound to Backbone MVC views is over. We want <a href="https://facebook.github.io/react/">React</a>! We want <a href="https://www.styled-components.com/">Styled Components</a>! And when those tools are surpassed by the Next Big Thing we want that too! But we also want our existing CoffeeScript and Jade and old-school <code>Backbone.View</code>s as well.</p>

<p>Thinking through this problem, <a href="https://github.com/artsy/stitch">@artsy/stitch</a> was born.</p>

<p>Stitch helps your Template and Component dependencies peacefully co-exist. You feed it a layout and some data and out pops a string of compiled html that can be passed down to the client. "Blocks" can be added that represent portions of UI, injected by key. It aims for maximum flexibility: templating engines supported by <a href="https://github.com/tj/consolidate.js">consolidate</a> can be installed and custom rendering engines <a href="https://github.com/artsy/stitch#custom-renderers">can be swapped out or extended</a>. With very little setup it unlocks UI configurations that have been lost to time.</p>

<p>A basic example:</p>

<p>
```html</p>

<div>
  {{title}}
</div>


<pre><code>
</code></pre>

<p>const html = await renderLayout({
  layout: 'templates/layout.handlebars',
  data: {
    title: 'Hello!'
  }
})</p>

<p>console.log(html)</p>

<p>// => Outputs:
/*</p>

<div>
  Hello!
</div>


<p>*/
```</p>

<p>By adding "blocks" you can begin assembling (or adapting to) more complex layouts. Blocks represent either a path to a template or a component (with "component" meaning a React or <a href="https://preactjs.com">React-like</a> function / class component):</p>

<p>
```html
// templates/layout.handlebars</p>

<p><html>
  <head>
    <title>
      {{title}}
    </title>
  </head>
  <body
    {{{body}}}
  </body>
</html>
```
</p>

<pre><code class="js">// index.js

const html = await renderLayout({
  layout: 'templates/layout.handlebars',
  data: {
    title: 'Hello World!',
  },
  blocks: {
    body: (props) =&gt; {
      return (
        &lt;h1&gt;
          {props.title}
        &lt;/h1&gt;
      )
    }
  }
})

console.log(html)

// =&gt; Outputs:
/*
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Hello World!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;
      Hello World!
    &lt;/h1&gt;
  &lt;/body&gt;
&lt;/html&gt;
*/
</code></pre>

<p>In Force, we're using this pattern to incrementally migrate portions of our app over to React, by taking existing block-based Jade layouts and injecting <code>ReactDOM.renderToString</code> output into them, and then rendering the layout into an HTML string that is passed down from the server and rehydrated on the client, isomorphically.</p>

<p>Our existing Backbone views take advantage of the <code>templates</code> key:</p>

<pre><code class="js">// server.js

import LoginApp from 'apps/login/LoginApp'
import { Provider } from 'react-redux'
import { StaticRouter } from 'react-router'

const html = await renderLayout({
  layout: 'templates/layout.handlebars',
  data: {
    title: 'Login / Sign-up',
  },
  templates: {
    login: 'templates/login.jade'
  },
  blocks: {
    app: (props) =&gt; (
      &lt;Provider store={store}&gt;
        &lt;StaticRouter&gt;
          &lt;LoginApp {...props} /&gt;
        &lt;/StaticRouter&gt;
      &lt;/Provider&gt;
    )
  }
})

res.send(html)
</code></pre>

<p>Similar to blocks, templates located in this object are pre-compiled and available to your components as <code>props.templates</code>.</p>

<p>Once the html has been sent over the wire, we mount it like so:</p>

<pre><code class="js">// client.js

import LoginApp from 'apps/login/LoginApp'

React.render(
  &lt;LoginApp {...window.__BOOTSTRAP__} /&gt; // Data passed down from `data` key
)
</code></pre>

<pre><code class="js">// apps/login/LoginApp.js

import React from 'react'
import Login from 'apps/login/Login'

export default function LoginApp (props) {
  const {
    templates: {
      login
    }
  } = props

  return (
    &lt;Login
      template={login}
    /&gt;
  )
}
</code></pre>

<p>During the server-side render phase existing template code will be rendered with the component, and once the component is mounted on the client <code>componentDidMount</code> will fire and the Backbone view instantiated:</p>

<p>
```js
// apps/login/Login.js</p>

<p>import React, { Component } from 'react'
import LoginBackboneView from 'apps/login/views/LoginView'</p>

<p>export default class Login extends Component {
  componentDidMount () {
    this.loginView = new LoginBackboneView()
    this.loginView.render()
  }</p>

<p>  componentWillUnmount () {
    this.loginView.remove()
  }</p>

<p>  render () {
    return (
      <div>
        <div dangerouslySetInnerHtml={{
          __html: this.props.template
        }}>
      </div>
    )
  }
}
```
</p>

<p>All of the possibilities that Stitch provides are too numerous to go over here, but check out the <a href="https://github.com/artsy/stitch#usage">documentation</a> and <a href="https://github.com/artsy/stitch/tree/master/examples">example apps</a> for more complete usage. While new, this pattern has worked quite well for us and has allowed Force to evolve alongside existing code with very little friction.</p>

<a name="Moving.Forward"></a>
<h2>Moving Forward</h2>

<p>A common thread that connects <a href="https://github.com/artsy/force">Force</a> to <a href="https://github.com/artsy/eigen">Eigen</a> (Artsy's mobile app) is an understanding that while grand re-writes will gladly remove technical debt, technical debt is not our issue. A lot of the patterns we've laid down within our apps still work for us, and many of our implementations remain sufficient to the task. What we needed was an environment where <em>incremental revolution</em> was possible, where old ideas could merge with new and evolve. In terms of Eigen, we felt the best way forward was the adoption of <a href="https://facebook.github.io/react-native/">React Native</a> -- and <a href="https://github.com/artsy/emission">Emission</a> was born. Likewise, for our web and web-based mobile apps, <a href="https://github.com/artsy/reaction">Reaction</a> is serving a similar role. Both of these projects are built with <a href="https://www.typescriptlang.org/">TypeScript</a>, and both rely heavily on functionality that our <a href="http://graphql.org/">GraphQL</a> interface <a href="https://github.com/artsy/metaphysics">Metaphysics</a> provides. But crucially, these projects <em>augment</em> our existing infrastructure; they don't replace it. They fit in with existing ideas, tools and processes that have facilitated Artsy's growth, including highly-specific domain knowledge that our engineers have built up over time.</p>

<p>In conclusion, I hope this post has provided a bit of a window into some of our processes here at Artsy for those facing similar challenges. If you want to take a deeper dive, check out the links below:</p>

<ul>
<li><a href="https://github.com/artsy/express-reloadable">express-reloadable</a></li>
<li><a href="https://github.com/artsy/stitch">stitch</a></li>
<li><a href="https://github.com/artsy/reaction">reaction</a></li>
<li><a href="https://github.com/artsy/emission">emission</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introducing Peril to the Artsy Org]]></title>
    <link href="http://artsy.github.io/blog/2017/09/04/Introducing-Peril/"/>
    <updated>2017-09-04T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2017/09/04/Introducing-Peril</id>
    <content type="html"><![CDATA[<p>Once Danger Ruby was stable enough for everyday use in 2015, it became obvious that running Danger on CI was both a
positive and a negative. On the positive side, Danger has access to all artifacts created during testing - and on the negative
side it takes a long time to get feedback. It was obvious that Danger could <a href="https://github.com/danger/danger/issues/42">run on a server</a>, but it was a big unknown what that could look like.</p>

<p>Eventually, <a href="/blog/2017/06/30/danger-one-oh-again/">I came to the conclusion</a> that we would need a JavaScript replacement of Danger - and so I applied
constraints to Danger JS that made a server-side version of Danger a possibility. It was a stroke of luck that around the
time Danger JS became usable for day to day usage, that GitHub introduced <a href="https://developer.github.com/changes/2016-09-14-Integrations-Early-Access/">GitHub Apps</a> - so I started work on Peril. Peril is server-side Danger. The rest of this post talks about how we use it Artsy today, how you can use it yourself and where it's heading.</p>

<!-- more -->


<p>In December 2016, I built out Peril in a sandbox org: <a href="https://github.com/PerilTest">PerilTest</a>, this gave me the chance to get a lot of things wrong safely. My biggest worry around Peril was leaking data though someone abusing the ability to evaluate a Dangerfile.</p>

<p>In May 2017, I introduced Peril into Artsy's org, GitHub apps have the ability to pick and choose which repos to work with.
I scoped the repos to existing open source projects which I was familiar with (<a href="https://github.com/artsy/emission">Emission</a>, <a href="https://github.com/artsy/reaction">Reaction</a> and <a href="https://github.com/artsy/positron">Positron</a>)
which gave a space to ensure stability and handle production edge-cases.</p>

<p>In August 2017, I created a new Peril instance for CocoaPods. I then finally flipped the switch to turn Peril on for all
repos on the Artsy org and formalized the RFC process for changes. This is where we are now.</p>

<a name="Getting.Set.Up"></a>
<h2>Getting Set Up</h2>

<p>For our Artsy org, I followed and improved the guide: <a href="https://github.com/danger/peril/blob/master/docs/setup_for_org.md">Setup for Org</a>. There are three key components:</p>

<ul>
<li>Creating a GitHub app for your Org</li>
<li>Hosting a Peril server</li>
<li>Making up a Peril settings repo</li>
</ul>


<p>The guide covers the initial setup, but I'd like to cover the third part of our setup.</p>

<a name="How.Artsy.s.Peril.works"></a>
<h2>How Artsy's Peril works</h2>

<p>The Artsy Peril settings are all on <a href="https://github.com/artsy/artsy-danger">artsy/artsy-danger</a>. The Artsy Peril heroku instance has the ENV var
<code>"DATABASE_JSON_FILE"</code> set to <code>"artsy/artsy-danger@peril.settings.json"</code>, so Peril will use <a href="https://github.com/artsy/artsy-danger/blob/master/peril.settings.json">that file</a> as the source of truth for all config. Here's what it is today:</p>

<p></article>
<article class='split-desktop-only'></p>

<div style='flex:1; display: block;'>

```json
{
  "settings": {
    "modules": [
      "danger-plugin-spellcheck", 
      "danger-plugin-yarn", 
      "@slack/client"
    ],
    "env_vars": ["SLACK_RFC_WEBHOOK_URL"]
  },
  "rules": {
    "pull_request": "artsy/artsy-danger@org/all-prs.ts"
  },
  "repos" : {
    "artsy/reaction": {
      "pull_request": "danger/pr.ts"
    },
    "artsy/positron": {
      "pull_request": "dangerfile.ts"
    },
    "artsy/artsy-danger": {
      "issues.opened": "artsy/artsy-danger@danger/new_rfc.ts"
    }
  }
}
```

</div>


<div style='flex:1; display: block; padding:0 20px;'>

<p><code>"settings":</code> These settings which conform to today's <a href='https://github.com/danger/peril/blob/752afeb37e3c1fdec512eb91687747d9a8a29337/source/db/index.ts#L26-L31'>GitHubInstallationSettings</a>, here's the <a href='https://github.com/danger/peril/blob/master/source/db/index.ts'>current version</a>. These are org-wide settings
that require a new deploy of the server to re-create.</p>

<p><code>"rules":</code> These are rules which are applied to every repo that Peril has access to. So in this case, every Pull Request in the org will make Peril run the Dangerfile at <code>"artsy/artsy-danger@org/all-prs.ts"</code>.</p>

<p><code>"repos":</code> These are repo-specific overrides, so a Pull Request to artsy/reaction would trigger both the org-wide Dangerfile, and one on the reaction repo.</p>

</div>


<p></article>
<article class='post'></p>

<a name="Events"></a>
<h2>Events</h2>

<p>A Dangerfile evaluation occurs once a GitHub webhook is sent. In the above examples there are two events that Danger supports:
<code>"pull_request"</code> and <code>"issues.opened"</code>. These are qualifiers that GitHub provide as a <a href="https://developer.github.com/v3/activity/events/types/events">Webhook EventTypes</a>.</p>

<p>There's a lot of them: <code>commit_comment</code>, <code>create</code>, <code>delete</code>, <code>deployment</code>, <code>deployment_status</code>, <code>fork</code>, <code>gollum</code>, <code>installation</code>, <code>installation_repositories</code>, <code>issue_comment</code>, <code>issues</code>, <code>label</code>, <code>marketplace_purchase</code>, <code>member</code>, <code>membership</code>, <code>milestone</code>, <code>organization</code>, <code>org_block</code>, <code>page_build</code>, <code>project_card</code>, <code>project_column</code>, <code>project</code>, <code>public</code>, <code>pull_request</code>, <code>pull_request_review</code>, <code>pull_request_review_comment</code>, <code>push</code>, <code>release</code>, <code>repository</code>, <code>status</code>, <code>team</code>, <code>team_add</code>, <code>watch</code>.</p>

<p>Some of these events also have unique sub-actions too:</p>

<ul>
<li><p>For an <code>issue</code> event there is: <code>assigned</code>, <code>unassigned</code>, <code>labeled</code>, <code>unlabeled</code>, <code>opened</code>, <code>edited</code>,  <code>milestoned</code>, <code>demilestoned</code>, <code>closed</code>, or <code>reopened</code></p></li>
<li><p>For a <code>pull_request</code> event there is: <code>assigned</code>, <code>unassigned</code>, <code>review_requested</code>, <code>review_request_removed</code>, <code>labeled</code>, <code>unlabeled</code>, <code>opened</code>, <code>edited</code>, <code>closed</code>, or <code>reopened</code></p></li>
</ul>


<p>The way that you define rules in Peril gives you the ability to either focus on one action for an event type: <code>"issues.opened"</code> or all actions
on an event: <code>"pull_request"</code>. Once you get your head around this, you start to get a sense of the scope of Peril. At Artsy, we've barely scratched the surface.</p>

<a name="Growth"></a>
<h3>Growth</h3>

<p>I've always advocated that Danger, and Peril should be <a href="http://danger.systems/js/usage/culture.html">applied incrementally</a>. This applies even more when you're
making org changes that affect every developer - at least with Danger you can see the Pull Request that changes
the Dangerfile. With Peril you get none of that.</p>

<p>So, we introduced <a href="https://github.com/artsy/artsy-danger/#rfcs">an RFC process for Peril changes</a>. There's not much to it, if you want to add a rule that
affects everyone then you need to make an issue following a template and then wait a week. If you make a new issue that
includes the title <code>RFC:</code> then Peril sends a slack message to our developer Channel</p>

<p><img src="/images/peril/peril-rfc.png" alt="/images/peril/peril-rfc.png" /></p>

<p>This was simple to build via Peril, I first added the npm module: <code>"@slack/client"</code> to the <code>"modules"</code> array, making it available to a Dangerfile. Then I added an environment variable to Peril for a newly minted Slack Incoming Webhook URL, and exposed it to Dangerfiles via: <code>"env_vars": ["SLACK_RFC_WEBHOOK_URL"]</code>.</p>

<p>Then I added a per-repo rule:</p>

<pre><code class="json">    "artsy/artsy-danger": {
      "issues.opened": "artsy/artsy-danger@danger/new_rfc.ts"
    }
</code></pre>

<p>This means the Dangerfile is only ran on <code>"issues"</code> with an <code>"opened"</code> action. I didn't want the discussion around a rule spamming our slack with webhooks from the other actions. The file <code>danger/new_rfc.ts</code> looks like this:</p>

<pre><code class="ts">import { schedule, danger } from "danger"
import { IncomingWebhook } from "@slack/client"
import { Issues } from "github-webhook-event-types"

declare const peril: any // danger/danger#351

const gh = danger.github as any as Issues
const issue = gh.issue

if (issue.title.includes("RFC:")) {
  var url = peril.env.SLACK_RFC_WEBHOOK_URL || "";
  var webhook = new IncomingWebhook(url)
  schedule( async () =&gt; {
   await webhook.send({
      unfurl_links: false,
      attachments: [{
        pretext: "üéâ A new Peril RFC has been published.",
        color: "good",
        title: issue.title,
        title_link: issue.html_url,
        author_name: issue.user.login,
        author_icon: issue.user.avatar_url
      }]
    })
  })
}
</code></pre>

<p>For events that are not a <code>"pull_request"</code> the <code>danger.github</code> object is the JSON for the event.  You can get TypeScript types available for every GitHub event via the NPM module <a href="https://www.npmjs.com/package/github-webhook-event-types">github-webhook-event-types</a> which makes it much easier to work with.</p>

<a name="Where.to.go.from.here."></a>
<h2>Where to go from here?</h2>

<p>Right now we have <a href="https://github.com/artsy/artsy-danger/issues?utf8=%E2%9C%93&amp;q=is%3Aissue%20RFC">a few RFCs</a>, and I don't spend all day making Peril rules, I've gotta <a href="https://github.com/artsy/emission/pulls?utf8=%E2%9C%93&amp;q=consignments%20">do work y'know</a>. We're going to slowly build out our Peril infrastructure.</p>

<p>I'm interested in exploring two ideas big for peril at the moment:</p>

<ul>
<li><p>What a Peril plugin system looks like: You can include modules which can listen to events and react themselves. An org-wide spellcheck on markdown files could be as easy as including <code>"modules": ["peril-plugin-spellcheck"]</code>.</p></li>
<li><p>What <a href="https://github.com/danger/peril/issues/138">scheduled jobs</a> could look like for Peril: We have a bunch of checks I'd like to make on a a regular occasion, and then passing back feedback via slack or making an issue on the repo.</p></li>
</ul>


<p> For example if a repo has an owner who isn't in Artsy anymore, we should highlight that it needs a new owner.</p>

<p>If you're interested in using Peril in large OSS projects, take a look at how Peril is used in CocoaPods via <a href="https://github.com/CocoaPods/peril-settings">CocoaPods/peril-settings</a>.</p>

<p>If you're interested in using Peril in your org, run through the <a href="https://github.com/danger/peril/blob/master/docs/setup_for_org.md">Setup for Org</a> guide and help improve it when you inevitably have some weird issues.</p>
]]></content>
  </entry>
  
</feed>
