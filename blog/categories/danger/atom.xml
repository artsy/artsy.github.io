<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: danger | Artsy Engineering]]></title>
  <link href="http://artsy.github.io/blog/categories/danger/atom.xml" rel="self"/>
  <link href="http://artsy.github.io/"/>
  <updated>2018-12-16T10:16:31+00:00</updated>
  <id>http://artsy.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Context Switching]]></title>
    <link href="http://artsy.github.io/blog/2018/08/10/On-Context-Switching/"/>
    <updated>2018-08-10T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/08/10/On-Context-Switching</id>
    <content type="html"><![CDATA[<p>Programming generally requires getting into a good <a href="https://en.wikipedia.org/wiki/Flow_(psychology)">flow state</a> and working on a tricky problem for some time.
In the last 2 years, most of my work at Artsy (and in the OSS world) has been less about longer-term building of
hard things, but working on many smaller tasks across a lot of different areas.</p>

<p>Somehow, during this period I managed to end up in the top of "most active" <a href="https://gist.github.com/paulmillr/2657075">GitHub members</a>, I feel like a
lot of this is due to doing <a href="http://artsy.github.io/series/open-source-by-default/">Open Source by Default</a> at Artsy and second to being good at context switching. I
want to try and talk though some of my techniques for handling context switching, as well as a bit of philosophy
around adopting and owning your tools.</p>

<!-- more -->


<a name="Shallow.and.Wide.Work"></a>
<h2>Shallow and Wide Work</h2>

<p>I want to encourage as many people as possible to work on fun, deep-flow projects at Artsy. One of the most
successful ways of achieving this, that I've found, is to spend most of my time working on shallower tasks. An
example from my last few weeks is hiring. The communication aspects require dozens of emails and internal updates
that can't be scheduled into safe blocks. <em>(<a href="https://www.artsy.net/jobs#engineering">Totally related BTW, we're hiring</a>.)</em></p>

<p>For programming work I have a few techniques for trying to accomplish a lot of shallow tasks across many repos.</p>

<p>Start off by making yourself accountable to someone. For my OSS, this tends to either be <a href="https://github.com/orta/cocoapods-fix-react-native#contributing-back">setting expectations</a>
in README or using <a href="https://github.com/danger/danger-js/blob/master/VISION.md#danger-for-js">a VISION</a> file. For Artsy work we have product managers and engineers who own the
projects I'm contributing to. For this blog post, it's my <a href="http://artsy.github.io/author/chris/">buddy Chris</a>.</p>

<p>I would then strive to get <em>anything</em> out, this could be a work-in-progress PR or via declaratively via
<a href="https://tom.preston-werner.com/2010/08/23/readme-driven-development.html">README-driven-development</a>. Part of this is because you might end up being dragged off into something else,
and another is that you're less likely to grok the domain better than your reviewers. Whilst not every change is an
improvement, every improvement adds up - even in small increments.</p>

<p>One way to instantly get rich domain knowledge is by pairing with someone who is more involved. This is a perfect
way to understand how decisions were made and provides great insight into how someone works on a project. While
pairing, you might also find additional ways to improve the daily workflow for someone else too!</p>

<p>Trying to have a shallow and wide understanding of many systems means accepting that you can't know the finer
details about how everything works. You want to know when really big interesting things are happening, but most work
should be iterative and less relevant to external folk like you.</p>

<p>With this in mind you can change your perspective to aim for having overviews on many things, but not get bogged
down in the useful discussion.</p>

<p>Techniques for this are:</p>

<ul>
<li><p>Making a custom stream of updates and not being too concerned about reading every single one of them. For Artsy,
with many contributors and contexts - I create slack channels like: <code>#front-end-ios-notifs</code>,
<code>#front-end-web-notifs</code>, <code>#orta-misc-notifs</code> and business specific ones like <code>#consignments-notifs</code> that contain
PR or Issue information creation from GitHub but nothing with more details. I do the same but smaller for Danger
and CocoaPods.</p></li>
<li><p>I set <a href="https://get.slack.help/hc/en-us/articles/201398467-Set-up-keyword-notifications">Slack keywords</a> to key GitHub repo names, or internal facing app names that I care about. This
means I don't have to monitor every channel.</p></li>
<li><p>I don't read my email. All 13,489 of them right now. I read the subjects and decide if it's worth reading. Every
few months I declare inbox zero so others are less distracted by the number.</p></li>
</ul>


<p>The tricky thing with this sort of work is trying not to be a blocker for someone else. A lot of this is about being
cautious about what you strive to help with, and about finding ways to boost others asynchronously. Am I good at
this? Sometimes. It's easier in OSS thanks to the the limited liability clauses, but in work-work that can be hard.</p>

<p>When my contributions are larger and I know the domain well, for example in a front-end JavaScript project, I am
willing to take longer than I'd like to ensure that it is reference level quality. A recent example came up in a
retrospective last month when an engineering team at Artsy said that one of <a href="https://github.com/artsy/emission/tree/master/src/lib/Components/Consignments">my projects</a> was a key
reference for testing and React Native form handling for them. Pulling off this can definitely take longer than
expected, but if you're not going to be the one maintaining it then holding yourself to a higher standard is worth
it.</p>

<a name="Deep.Automation"></a>
<h2>Deep Automation</h2>

<p>Remove as much ambiguity as possible for discussion. Project tools like <a href="https://prettier.io">prettier</a> really help focus code review
away from the petty formatting issues. Linters like <a href="https://github.com/palantir/tslint">tslint</a>, <a href="https://eslint.org">eslint</a> and <a href="https://www.github.com/bbatsov/rubocop">rubocop</a> remove another series of
discussion points. When you find yourself surprised by a cultural rule for a codebase, add <a href="https://danger.systems">a danger</a> rule
so you and others have it codified. Use tools like <a href="https://github.com/typicode/husky">husky</a> and <a href="https://github.com/okonet/lint-staged">lint-staged</a> to get that feedback when you're
still in a development context. Danger can even run as a <a href="http://danger.systems/js/tutorials/fast-feedback.html">git-hook/husky task</a> too, so that feedback
can be <em>blazing</em> too.</p>

<p>You can automate via tools, sure, but you can also encourage independent work via documentation.(TO DO: saves your
time, but isn't "automation") If something is confusing enough that, as an outsider, you don't get it without
asking, you should start adding documentation. I can't tell you what that looks like because it's different
per-project, but at least try to make it so the next person doesn't need to ask.</p>

<p>I strive to use my time on a project to encourage more consolidation, in the case of front-end that's moving closer
to <a href="https://www.youtube.com/watch?v=1Z3loALSVQM">the Artsy omakase</a>. In the case of servers that could be encouraging new APIs to use GraphQL, or to adopt
some of our newer ideas about schema management.</p>

<a name="Impact.per.Keystroke"></a>
<h2>Impact per Keystroke</h2>

<p>I'm a firm believer in customising your environment. Does that suck for pair programming? Yes. Can we deal with it?
Yes. I'm gong to assume you're on a Mac. An out of the box Mac comes with some solid developer tools, and Apple are
good at <a href="http://artsy.github.io/blog/2017/02/05/Retrospective-Swift-at-Artsy/#Developer.Experience">taking</a> some of the communities good ideas and giving it to everyone.</p>

<p>However, there's definitely space for independent apps. Here's a list of apps broken into genres. You should be
running at least one from each genre, and have it's features deeply committed to memory. The ones in bold are what I
use.</p>

<ul>
<li>Window Management: <a href="https://manytricks.com/moom/"><strong>Moom</strong></a>, <a href="http://magnet.crowdcafe.com">Magnet</a>,
<a href="https://www.spectacleapp.com">Spectacles</a>, <a href="http://mizage.com/divvy/">Divvy</a></li>
<li>Effective Keyboard Shortcuts: <a href="https://shortcatapp.com"><strong>Shortcat</strong></a>, <a href="https://keytty.com">Keytty</a>,
<a href="https://vimium.github.io">Vimium</a>/<a href="https://github.com/guyht/vimari"><strong>Vimari</strong></a></li>
<li>Clipboard Manager: <a href="https://www.alfredapp.com"><strong>Alfred</strong></a>, <a href="https://tapbots.com/pastebot/">Pastebot</a>,
<a href="http://www.keyboardmaestro.com/main/">Keyboard Meastro</a></li>
<li>Recently changed files: <a href="http://www.ironicsoftware.com/fresh/"><strong>Fresh</strong></a>,
<a href="http://www.ironicsoftware.com/fresh/"><strong>Alfred</strong></a></li>
<li>Text Snippets: <a href="https://www.alfredapp.com"><strong>Alfred</strong></a>, <a href="https://textexpander.com/">TextExpander</a>, macOS System
Settings</li>
<li>Terminal: <a href="https://iterm2.com"><strong>iTerm 2</strong></a>, <a href="https://hyper.is">Hyper</a></li>
<li>Learning Keyboard Shortcuts: <a href="https://www.mediaatelier.com/CheatSheet/"><strong>CheatSheet</strong></a></li>
<li>Shell: <a href="https://github.com/robbyrussell/oh-my-zsh">Oh my ZSH</a>, <strong><a href="http://fishshell.com">Fish</a> +
<a href="https://fisherman.github.io">Fisherman</a></strong></li>
<li><em>Simple</em> Note Taking: <a href="http://brettterpstra.com/projects/nvalt/"><strong>nvalt</strong></a>,
<a href="https://culturedcode.com/things/"><strong>Things</strong></a>, Notes.app, <a href="https://evernote.com">Evernote</a></li>
</ul>


<p>Use native apps by default, they are better for your time. Native apps will usually conform to the <a href="https://developer.apple.com/design/human-interface-guidelines/macos/overview/themes/">Human Interface
Guidelines</a>, which means logical shortcuts and great accessibility support. This is good because tools like
<a href="https://shortcatapp.com">Shortcat</a> rely on that.</p>

<p>Electron-y apps made the most sense when there is a big
<a href="https://unix.stackexchange.com/questions/137820/whats-the-difference-of-the-userland-vs-the-kernel">user-land</a>
customization scene. So, basically if there's a community around extending the app (<a href="https://hyper.is">Hyper</a> is a
reasonable example, <a href="https://code.visualstudio.com">Visual Studio Code</a> and <a href="https://atom.io">Atom</a> are the best
example) then Electron apps make sense.</p>

<p>Some highlights for non-native apps are <a href="https://mailplaneapp.com">Mailplane</a> and
<a href="https://code.visualstudio.com">Visual Studio Code</a>.</p>

<p>Every second you're at a computer you should be feeling like it's 1-2-3 hotkeys away from whatever you want to do
next. For example:</p>

<ul>
<li>Your terminal should be a <a href="https://www.youtube.com/watch?v=ETskRNFeuGM">single keypress away</a></li>
<li><a href="https://github.com/orta/keyboard_shortcuts#using-a-mac">Learn the keys for OS X</a> so you can jump/delete words</li>
<li><a href="https://www.youtube.com/watch?v=4CRbJwOctMo">Resize/move windows with modal commands</a></li>
<li><a href="https://www.neat.io/bee/">Making a new Jira ticket with a hotkey</a></li>
<li><a href="/images/context-switching/sketch.mov">Open any recent file per-app</a></li>
<li><a href="https://krausefx.com/blog/use-custom-shortcuts-for-every-application">Use a shortcut for every Mac app you use regularly</a></li>
</ul>


<p>App-wise there's always more all of us can do, but constant improvement is key to getting there.</p>

<p>I think it's worth stressing here that I believe in paying for my tools. I want to support independent devs, and my
time is worth orders of magnitude more than the cost of entry for this software. There may be similar versions of
what I noted above for free, they could be open source too - but I'd rather have more people working on our tools
full-time than people doing it in their spare-time.</p>

<a name="Terminal.Context.Switching"></a>
<h2>Terminal Context Switching</h2>

<p>macOS's UNIX underpinnings mean that a lot of common GUI activities have a CLI counter-part. To handle regular
context switching in the terminal you'll need to customise the shell to give you information as you arrive in a new
context. Things that I find useful in a shell are:</p>

<ul>
<li>What folder am I in?</li>
<li>Is it a git repo?</li>
<li>What branch am I on, or are there existing changes?</li>
<li>Did the last command fail?</li>
<li>Sometimes, what version of node/ruby is setup for this project?</li>
</ul>


<p>I think it's also really useful to be able to jump between many development folders, you can use
<a href="https://github.com/rupa/z"><strong>z</strong></a>, <a href="https://github.com/wting/autojump">j</a> or
<a href="https://github.com/iridakos/goto">goto</a> for this. Or set up some custom
<a href="https://shapeshed.com/unix-alias/">aliases</a> for the most common folders.</p>

<p>As you'll be spending a good chunk of time, it's worth feeling comfortable that you know a few of the flags for
<code>cd</code>, <code>ls</code>, <code>mkdir</code>, <code>rm</code>, <code>cat</code>, <code>touch</code> and <code>grep</code>. Ideally, you have tab completion set up, and
<a href="https://stackoverflow.com/questions/6205157/iterm-2-how-to-set-keyboard-shortcuts-to-jump-to-beginning-end-of-line#10485061">natural keybindings</a>
set up in your terminal input.</p>

<a name="Regular.Re-tooling"></a>
<h2>Regular Re-tooling</h2>

<p>Take the time every few years to re-think your previous decisions, I try to start from scratch every 2-3 years, I'm
writing this on a MacBook that's a week old and I've still not installed something from all of the above categories.
It's a good time to re-evaluate your software priorities as your personal/professional aims/responsibilities change.</p>

<p>A pattern I aim to strive for with tools is:</p>

<ul>
<li>Start with overkill to learn what you need.</li>
<li>Migrate to smaller and simpler once you know what you want.</li>
</ul>


<a name="Small.and.Often"></a>
<h2>Small and Often</h2>

<p>It's not a very traditional way to work as a programmer, but it fits my personality type and can really rack up the
commits and contributions across the board. Being able to quickly jump contexts makes a lot more sense in the node
ecosystem - where the boundaries between projects can be as small as per-function.</p>

<p>Working this way can make it really hard to monitor what you've done on a regular basis, a technique I've used to
stay on top of is <a href="https://github.com/kamranahmedse/git-standup">git-standup</a> and a dev folder structure that corresponds to <a href="https://twitter.com/orta/status/1028764128310185984">areas of work</a>. For
example, here's what a week roughly looks like on a slow week for Danger/Peril for me:</p>

<pre><code class="sh">~/dev/projects/danger
‚ùØ git standup -m 7 -d 7
/Users/orta/dev/projects/danger/hazmat/peril
c1d6893 - Update danger (2 days ago) &lt;Orta Therox&gt;
/Users/orta/dev/projects/danger/danger-js
a90d74c - Version bump, and peril fix (2 days ago) &lt;Orta Therox&gt;
f4836a1 - Version bump (2 days ago) &lt;Orta Therox&gt;
fbbcc1c - Adds a create/update label function to the github utils func (2 days ago) &lt;Orta Therox&gt;
702e51d - More dep updates (4 days ago) &lt;Orta Therox&gt;
</code></pre>

<p>Working this way requires trust from others that you're doing things that are valuable, which can be tricky when
your responses to "what did you get up to yesterday" end up being a bit ephemeral. Tools like <code>git-standup</code> help on
the code front, and <a href="https://www.rescuetime.com">RescueTime</a> can help you understand how much time you've spent in greenhouse.</p>

<p>It's your time, you should use it fastly.</p>

<p>Do you have any useful ideas for speeding up context switching? I'm open to improvements.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On the obsessive statelessness of Peril]]></title>
    <link href="http://artsy.github.io/blog/2018/06/18/On-Obsessive-Statelessness/"/>
    <updated>2018-06-18T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/06/18/On-Obsessive-Statelessness</id>
    <content type="html"><![CDATA[<p>We're at 9 months of serious usage <a href="/blog/2017/09/04/Introducing-Peril/">of Peril in Artsy</a>. However, I've been worried.</p>

<p>To get you up to speed on Peril, Peril is a tool that takes GitHub webhooks, and makes it easy to build one-off
actions. It does this by having a per-account settings JSON, that connects JavaScript files to events from webhooks.
So, for example, you can write a rule which runs when closing an issue in GitHub that looks for associated Jira
tickets and resolves them. Peril provides no implicit actions like that, it instead offers a JavaScript runtime
environment optimised to this domain so you can make actions to fit your needs. Like a collection of single-file
<a href="https://probot.github.io">probots</a>.</p>

<p>Three months ago I started building out a "true" staging environment for Peril, one that allows any user or org on
GitHub to click a button and have Peril running on their account. Pulling this off has two real interesting
problems. Problem number one, security. Problem number two, my wallet.</p>

<p>Both of these issues stem from one simple problem: I need to run other people's code on my machines and I think they
should be able to store data. Which to be quite frank, is horrifying for a side-project. So, this post explores one
of main aspects which I've architected Peril to make this problem tractable. Avoiding storing state in the form of
data.</p>

<!-- more -->


<a name="Evaluation.Context"></a>
<h2>Evaluation Context</h2>

<p>Let's start with grounding how Peril works. The GitHub term for when someone adds Peril to their account is that it
creates an "Installation" of the
<a href="https://blog.github.com/2016-09-14-a-whole-new-github-universe-announcing-new-tools-forums-and-features/#integrate-seamlessly-with-github">GitHub App</a>.
When a webhook from GitHub is sent to Peril, Peril grabs the installation metadata (env vars, settings repo
addresses, cached config etc) out of a mongo database (yeah, I know, <a href="https://www.infoworld.com/article/2990184/database/nosql-simply-isnt-hip-anymore.html">how early-2010s</a>) and pulls out a
set of rules. These rules are a map of Webhook events and actions to files. For example:</p>

<pre><code class="json">{
  "rules": {
    "issues.opened": "artsy/peril-settings@danger/new-rfc.ts",
    "issue_comment": "artsy/peril-settings@org/markAsMergeOnGreen.ts",
    "pull_request.closed": "artsy/peril-settings@org/closed-prs.ts"
  }
}
</code></pre>

<p>This <a href="https://github.com/danger/peril/blob/93439da3a088e9a7824192e24d33295ced017239/docs/settings_repo_info.md">custom JSON DSL</a> maps opening an <code>issue</code> on GitHub to the evaluation of
<a href="https://github.com/artsy/peril-settings/blob/6ec744e552df0828b3de2c5bc72e97accc6f562f/danger/new-rfc.ts"><code>artsy/peril-settings@danger/new-rfc.ts</code></a>. Peril runs the code which is declared as the <code>default export</code> with
the JSON contents of the webhook. Then the file can execute with the DSL provided in both <a href="http://danger.systems/js/">danger-js</a> and
<a href="http://danger.systems/js/reference.html#PerilDSL">peril</a>'s extensions. Peril's runtime is a reasonably normal nodejs environment, so it supports working with
<code>node_modules</code> to get stuff done. Here's what <a href="https://github.com/artsy/peril-settings/blob/6ec744e552df0828b3de2c5bc72e97accc6f562f/danger/new-rfc.ts"><code>artsy/peril-settings@danger/new-rfc.ts</code></a> looks like:</p>

<pre><code class="js">import { danger, peril } from "danger"
import { Issues } from "github-webhook-event-types"

export default async (issues: Issues) =&gt; {
  const issue = issues.issue

  const slackify = (text: string) =&gt; ({
    unfurl_links: false,
    attachments: [
      {
        pretext: text,
        color: "good",
        title: issue.title,
        title_link: issue.html_url,
        author_name: issue.user.login,
        author_icon: issue.user.avatar_url
      }
    ]
  })

  if (issue.title.includes("RFC:") || issue.title.includes("[RFC]")) {
    console.log("Triggering slack notifications")

    await peril.runTask("slack-dev-channel", "in 5 minutes", slackify("üéâ: A new RFC has been published."))
    await peril.runTask("slack-dev-channel", "in 3 days", slackify("üï∞: A new RFC was published 3 days ago."))
    await peril.runTask("slack-dev-channel", "in 7 days", slackify("üï∞: A new RFC is ready to be resolved."))

    console.log("Triggered slack notifications")
  }
}
</code></pre>

<p>Implementation-wise, there is a single Peril API which recieves webhooks from GitHub. This triggers a "Runner" which
is a hosted docker container (think, like, serverless) which hosts the runtime. The runner will then run the
Dangerfile, triggering things like comments on PRs or any other interesting side-effect.</p>

<p><img src="/images/peril-state/peril-stack.png"></p>

<p>This is where things get tricky, I first explored running code inside a tightened <a href="https://github.com/patriksimek/vm2">virtual machine for node</a>
but eventually found enough holes that it was definitely not going to work against malicious user-code in the same
process as Peril. I lucked out to a potential answer to this when building out documentation for <a href="http://danger.systems/js/">danger-js</a>,
which could <a href="https://celebrateurbanbirds.org/learn/gardening/providing-water-for-birds/">feed many birds with one bowl</a>. I could separate out the execution context (think: the runtime
DSL, the webhook JSON, and a bunch of installation specific config) as JSON and then pass that servers/processes
then turn that back into a useful runtime again in a separate client which runs the Dangerfile (the name for a
<code>js</code>/<code>ts</code> file running in the Peril JavaScript Environment. )</p>

<p>This idea was so compelling that I first used it to create a version of Danger that runs
<a href="https://github.com/danger/danger-swift">native to swift</a> to figure out the kinks of what actually needs to be
transmitted. For Peril, this meant I could explore having the evaluation of user-code inside a completely different
server. I initially explored <a href="https://github.com/danger/peril/issues/159">using AWS Lambda</a> to run user-code, it's cheap, fast and mature. However, it's
possible for lambda instances to communicate with each other, as each run is not <a href="https://aws.amazon.com/blogs/compute/container-reuse-in-lambda/">a fresh process</a>.
Making it not a secure platform for un-trusted code.</p>

<p>Not deterred, I explored the world of docker hosting as a service - first exploring running my own cluster <a href="https://aws.amazon.com/ecs/">on AWS
ECS</a> and then settling <a href="https://hyper.sh">on Hyper</a> which offered sandboxed runs that booted in a few seconds. This is
where my first real dive into obsessive statelessness comes in. The docker container, and the hyper environment
contains no config by default. There is no Peril information available inside that runtime environment.</p>

<p>The information about a Peril run comes exclusively from Peril. In my head, I call this dependency injection for the
runtime environment. You can get a sense for what the full JSON looks like in this
<a href="https://github.com/danger/peril/blob/master/source/github/events/handlers/_tests/fixtures/PerilRunnerEventBootStrapExample.json">fixtured file generated by tests</a>.
It contains everything from (temporary) GitHub access tokens (only for your installation), to environment variables
for your run and the webhook JSON. The runtime environment only knows that information for the duration of the
process then all access tokens expires after 30 seconds of it starting regardless.</p>

<a name="User.Sessions.are.ephemeral"></a>
<h2>User Sessions are ephemeral</h2>

<p>With the runtime security figured out, and reasonably stable, I could start thinking about how people can understand
what's happening on their installations inside peril.</p>

<p><img src="/images/peril-state/peril-dashboard.png"></p>

<p>I know, a beauty right? Taking ideas from Ashkan's <a href="https://artsy.github.io/blog/2016/10/26/jwt-artsy-journey/">post on JWT's</a> I explored using JWTs to fix a few user-y,
database-y related problems.</p>

<p>A JWT is a string made of three components, a header which says how it is signed, a base64 chunk of JSON data and a
signature verifying the data. You can always read the data inside a JWT, but you need to know the public key used to
sign the token to verify that it's not been tampered with or created from another source.</p>

<p>This brings us to my first problem when building out multi-account Peril: User accounts. For Peril the root element
of the domain model is a GitHub Installation. A first-glance perspective on building a web service like this would
have me creating a user model which can keep track of permission to installations and unique user settings. With
<a href="https://www.wired.co.uk/article/what-is-gdpr-uk-eu-legislation-compliance-summary-fines-2018">GDPR so freshly baked</a> I really didn't see any actual value in keeping this kind of data. Instead I added
enough metadata to a JWT to replace a user model completely.</p>

<p>I opted to rely on GitHub's Oauth API to verify what orgs a user has access to. This means GitHub hosts both the
user model, and the permission relationships. This is always set up outside of Peril, and so there's no need for
duplication of the objects and connections inside this service.</p>

<a name="Here.s.an.example.JWT"></a>
<h4>Here's an example JWT</h4>

<script src="https://gist.github.com/orta/0265c143e2c4f473d4dff5cc6980d1a4.js"></script>


<p>You could throw it into <a href="https://jwt.io">jwt.io</a> to look at what's inside it, but I'll do that for you:</p>

<a name="When.decrypted"></a>
<h4>When decrypted</h4>

<pre><code class="json">{
  "iat": 1529198097,
  "iss": ["123", "321"],
  "data": {
    "user": {
      "name": "Orta",
      "avatar_url": "https://avatars2.githubusercontent.com/u/49038?v=4"
    }
  },
  "exp": 1529201697
}
</code></pre>

<p>So far, I think that's enough information for the dashboard. You can let people know what account they're logged
into, and a show an avatar in a UI. The JWT is generated when you log in to Peril via GitHub OAuth, and Peril looks
up what installations you have access to via the GitHub API. The connected installations IDs are stamped into the
JWT in the <code>iss</code> section. This JWT is stored in the user's browser via cookies, and the server never stores it.</p>

<p>In every API call from the front-end, the server validates that the JWT was signed by Peril, and has not expired. If
it's OK - the server trusts the data inside the JWT and you have access to administrate the installations. No stored
sessions, no stored users.</p>

<p>There's downsides to using a JWT like this. For example, what happens if the user is removed from the org? Until
that JWT has expired (1 month), the user will continue have access to the installation. This is a trade-off which
I'm OK to take right now. I think <a href="http://cryto.net/~joepie91/blog/2016/06/13/stop-using-jwt-for-sessions/">this post</a> covers a lot of the downsides of this stateless JWT
technique well. In the future, as Peril has access to org members being added or removed, I can build a way to
expire the token at runtime.</p>

<a name="Temporary.Tokens"></a>
<h2>Temporary Tokens</h2>

<p>The user/authentication JWT is not the only JWT in play in Peril.</p>

<p>I needed the ability for the JavaScript Runtime to send messages back to the Peril server. Peril re-uses JWTs for
creating a short-lived (2 min) token. This token only has access to a single installation and is given a
list of mutations it has whitelisted access to in the GraphQL API. This token is a part of the data injected in at
the start of the process. The Peril JavaScript DSL uses this token under the hood when you run particular functions.
This approach, the above post argues, is a perfect use-case for JWTs.</p>

<a name="Temporary.Webhooks"></a>
<h2>Temporary Webhooks</h2>

<p>With an admin user interface set up, you can now get a good overview of what your installation looks like in
Peril.</p>

<p><img src="/images/peril-state/admin.png"></p>

<p>This is a good start, but it's a static representation of a live system. In order to do any development of your
Dangerfiles in Peril, you would need to keep triggering the same event inside the GitHub and seeing how Peril
evaluates your code. Even with the rich type definitions, you're unlikely to get it right first time.</p>

<p>And here's where I made a compromise or two, in favour of a good abstraction. Ash recommended that perhaps storing
webhooks from GitHub and making it feasible to re-send them in Peril would make a great development environment. I
couldn't think of a way to do that statelessly, so I opted to time-box them. Now you can trigger a 5 minute window
on an installation where any event sent to Peril will be stored in mongo for a week. After that they're gone.</p>

<p>This is a great trade-off on data storage vs value of a feature. It's been the best idea so far on how to handle
building a development mode into Peril, so I wouldn't want to compromise the feature in favour of something that
won't store any data.</p>

<a name="Real-time.logging"></a>
<h2>Real-time logging</h2>

<p>On the flip side, I spent a long time thinking about how I can get logs from a Peril run to a user without having to
store those.</p>

<p>I came up with what feels like such an obvious answer in retrospect. When you open up the admin dashboard, it
connects to Peril via a websocket. This websocket is used to send real-time updates about when an event is
triggering a Dangerfile evaluation and its changing status. When the evaluation is finished, then the logs are
collected and sent through the websocket to any users connected to the associated installation. The feature is
particularly elegant because storing the logs for every Dangerfile run on something like S3 will not scale with my
wallet. Plus, I don't want to have access to your logs ideally.</p>

<p><img src="/images/peril-state/websocket.png"></p>

<p>Again, an interesting trade-off. You can only get logs when you're looking for them, as opposed to when a problem
may actually have occurred. There's things I can do to work around this if and when it becomes a pressing need, for
example keeping an installation's logs around for a day in Peril. Alternatives to this could be that Peril allows
installations to define a webhook to receive the logs, or for Peril to pass them directly to a installation's
<a href="https://papertrailapp.com">Papertrail</a> (or other hosted log services).</p>

<p>A lot of the obsession comes from a reasonable enough desire to ship something that people can trust, that could
start off small and hard enough that it doesn't consume all my spare time with support and fixing fires. With a lot
of these ideas in tow, I've been able to feel pretty confident in letting others access staging environments and use
my hosted version of Peril. Which means I can move on to the next items in my TODO list, making the dashboard make
sense and to start thinking about what the public facing product pages look like for Peril.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[In the 'Whelp!' of the Great Wave]]></title>
    <link href="http://artsy.github.io/blog/2018/01/24/kubernetes-and-hokusai/"/>
    <updated>2018-01-24T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/01/24/kubernetes-and-hokusai</id>
    <content type="html"><![CDATA[<p>This past week has found me working on a brand new Rails project. Now, if I was building this project for my personal needs, I would without a doubt deploy it to <a href="https://www.heroku.com">Heroku</a> ‚Äì for both the ease of use and the high level of abstraction that <a href="https://www.heroku.com/dynos">Dynos</a> afford. But I'm not building this for myself, I'm building it for my team.</p>

<!-- more -->


<p>While Heroku is easy to get started with, costs scale up quickly. And, as described in our <a href="http://artsy.github.io/blog/2017/04/14/artsy-technology-stack-2017/">2017 tech stack post</a>, our team is moving more and more towards <a href="https://kubernetes.io">Kubernetes</a>. I had almost no experience with Kubernetes before last week, and I was intimidated by the Kubernetes web UI. With some help from my colleague Isac, who wrote the <a href="https://github.com/artsy/hokusai">Hokusai</a> tool, I was able to get a staging environment up and running in under a day.</p>

<p>But let's step back first.</p>

<p>My background is in iOS software development, so spinning up new servers isn't something I do often. When I <em>do</em>, I usually use Heroku. After deploying to it, it feels like Kubernetes is a kind of hosted Heroku: it handles scaling up instances, managing worker/db/other instances, load-balancers, environment variables, promoting from staging to production ‚Äì all that stuff. But Kubernetes' sophistication comes with a sophisticated user interface.</p>

<p>So basically, Hokusai is to Kubernetes what the Heroku command-line tool is to the Heroku platform.</p>

<p>Hokusai provides <a href="https://github.com/artsy/hokusai/blob/master/docs/Command_Reference.md">a bunch of commands</a> for interacting with the Kubernetes cluster. Deploying my new Rails app to Kubernetes involved a few steps, but most of the work was handled automatically by Hokusai.</p>

<p>First, I installed and setup Hokusai locally (with required environment variables for AWS access). I then ran the following command to scaffold out everything.</p>

<pre><code class="sh">hokusai setup --aws-account-id ARTSY_ACCOUNT_ID --project-type ruby-rails
</code></pre>

<p>In addition to staging- and production-specific config files, this command creates a <code>Dockerfile</code>. See, where Heroku uses Dynos as a high level of abstraction, Kubernetes uses <a href="https://www.docker.com">Docker</a> images (as a slightly less high a level of abstraction). Docker is a technology I'm familiar with, and I managed to configure the generated <code>Dockerfile</code> and <code>hokusai/*.yml</code> config files pretty quickly. At this point, I could run <code>hokusai dev start</code> to start a development Docker container, or <code>hokusai test</code> to run RSpec tests. Nothing fancy yet, but that verifies that everything is working so far.</p>

<p>Next up was to use Hokusai in our CI environment. <a href="https://circleci.com/docs/2.0/">Circle CI 2.0</a> is very Docker-oriented, so we set up everything using their <a href="https://circleci.com/docs/2.0/workflows/">Workflows</a>. This is a much higher level of abstraction for CI configuration than I'm used to, but I got the hang of it quickly. I created a job to run RSpec tests through Hokusai, a job to run <a href="http://danger.systems">Danger</a>, a job to build and push a Docker image to our S3 bucket, and a job to deploy that image to the Kubernetes cluster. Finally, I added the workflows to build and deploy automatically after successful builds on the <code>master</code> branch.</p>

<p>Here's a slightly redacted copy of our Circle config:</p>

<pre><code class="yaml">version: 2
jobs:
  test:
    docker:
      - image: artsy/hokusai:0.4.0
    working_directory: ~/REPO_NAME
    steps:
      - add_ssh_keys
      - checkout
      - setup_remote_docker
      - run:
          name: Test
          command: hokusai test
  danger:
    docker:
      - image: circleci/ruby:2.5.0
    working_directory: ~/apogee
    steps:
      - checkout
      - restore_cache:
          keys:
          - v1-dependencies-
          - v1-dependencies-
      - run:
          name: Install Dependencies
          command: bundle install --with=ci --without development test --path vendor/bundle
      - save_cache:
          paths:
            - ./vendor/bundle
          key: v1-dependencies-
      - run:
          name: Danger
          command: bundle exec danger
  push:
    docker:
      - image: artsy/hokusai:0.4.0
    steps:
      - add_ssh_keys
      - checkout
      - setup_remote_docker
      - run:
          name: Push
          command: hokusai registry push --tag $CIRCLE_SHA1 --force --overwrite
  deploy:
    docker:
      - image: artsy/hokusai:0.4.0
    steps:
      - add_ssh_keys
      - checkout
      - run:
          name: Configure
          command: hokusai configure --kubectl-version 1.6.3 --s3-bucket BUCKET_NAME --s3-key k8s/config --platform linux
      - run:
          name: Deploy
          command: hokusai staging deploy $CIRCLE_SHA1
workflows:
  version: 2
  default:
    jobs:
      - test
      - danger:
          filters:
            branches:
              ignore: master
      - push:
          filters:
            branches:
              only: master
          requires:
            - test
      - deploy:
          filters:
            branches:
              only: master
          requires:
            - push
</code></pre>

<p>The initial build on <code>master</code> built and pushed the server image, but the deploy failed. This is an <a href="https://github.com/artsy/hokusai/issues/50">issue</a> that's being tracked in Hokusai ‚Äì I'm sure it'll get addressed on the road to a 1.0. To explain, it's a Catch-22: we can't deploy until we have an image, but we only want to build images on CI, so the first deploy on CI is expected to fail.</p>

<p>Once the initial image was pushed, I ran <code>hokusai staging env create</code> locally to create the staging environment. I was able to set staging environment variables using <code>hokusai staging env set NAME=VALUE</code>, but unlike Heroku, I had to manually restart the server using <code>hokusai staging refresh</code> after adding the environment variables.</p>

<p>At this point, my server was working behind a load balancer, but I still had to add a CNAME record for the <code>really-long-url.elb.amazonaws.com</code> domain name. After some DNS propagation, everything worked fine!</p>

<p>So that's it! I was apprehensive about moving to a totally new (to me) deploy infrastructure. But, it's a direction our engineering team has decided to go in, and there's no better time to migrate to a new deploy infrastructure than before your first deploy. With some encouragement and help from my team, I was able to get the entire thing working in under a day (next time will be a lot faster).</p>

<p>I'm very encouraged by Kubernetes. It offers really slick, enterprise-level scaling features in an open source tool. And I've heard really great things about its community practices. Kubernetes is, however, a very specialized tool and its web interface doesn't make any sense to me. With Hokusai, I got a very programmer-friendly interface for a very DevOps-focused tool.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introducing Peril to the Artsy Org]]></title>
    <link href="http://artsy.github.io/blog/2017/09/04/Introducing-Peril/"/>
    <updated>2017-09-04T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2017/09/04/Introducing-Peril</id>
    <content type="html"><![CDATA[<p>Once Danger Ruby was stable enough for everyday use in 2015, it became obvious that running Danger on CI was both a
positive and a negative. On the positive side, Danger has access to all artifacts created during testing - and on the negative
side it takes a long time to get feedback. It was obvious that Danger could <a href="https://github.com/danger/danger/issues/42">run on a server</a>, but it was a big unknown what that could look like.</p>

<p>Eventually, <a href="/blog/2017/06/30/danger-one-oh-again/">I came to the conclusion</a> that we would need a JavaScript replacement of Danger - and so I applied
constraints to Danger JS that made a server-side version of Danger a possibility. It was a stroke of luck that around the
time Danger JS became usable for day to day usage, that GitHub introduced <a href="https://developer.github.com/changes/2016-09-14-Integrations-Early-Access/">GitHub Apps</a> - so I started work on Peril. Peril is server-side Danger. The rest of this post talks about how we use it Artsy today, how you can use it yourself and where it's heading.</p>

<!-- more -->


<p>In December 2016, I built out Peril in a sandbox org: <a href="https://github.com/PerilTest">PerilTest</a>, this gave me the chance to get a lot of things wrong safely. My biggest worry around Peril was leaking data though someone abusing the ability to evaluate a Dangerfile.</p>

<p>In May 2017, I introduced Peril into Artsy's org, GitHub apps have the ability to pick and choose which repos to work with.
I scoped the repos to existing open source projects which I was familiar with (<a href="https://github.com/artsy/emission">Emission</a>, <a href="https://github.com/artsy/reaction">Reaction</a> and <a href="https://github.com/artsy/positron">Positron</a>)
which gave a space to ensure stability and handle production edge-cases.</p>

<p>In August 2017, I created a new Peril instance for CocoaPods. I then finally flipped the switch to turn Peril on for all
repos on the Artsy org and formalized the RFC process for changes. This is where we are now.</p>

<a name="Getting.Set.Up"></a>
<h2>Getting Set Up</h2>

<p>For our Artsy org, I followed and improved the guide: <a href="https://github.com/danger/peril/blob/master/docs/setup_for_org.md">Setup for Org</a>. There are three key components:</p>

<ul>
<li>Creating a GitHub app for your Org</li>
<li>Hosting a Peril server</li>
<li>Making up a Peril settings repo</li>
</ul>


<p>The guide covers the initial setup, but I'd like to cover the third part of our setup.</p>

<a name="How.Artsy.s.Peril.works"></a>
<h2>How Artsy's Peril works</h2>

<p>The Artsy Peril settings are all on <a href="https://github.com/artsy/artsy-danger">artsy/artsy-danger</a>. The Artsy Peril heroku instance has the ENV var
<code>"DATABASE_JSON_FILE"</code> set to <code>"artsy/artsy-danger@peril.settings.json"</code>, so Peril will use <a href="https://github.com/artsy/artsy-danger/blob/master/peril.settings.json">that file</a> as the source of truth for all config. Here's what it is today:</p>

<p></article>
<article class='split-desktop-only'></p>

<div style='flex:1; display: block;'>

```json
{
  "settings": {
    "modules": [
      "danger-plugin-spellcheck", 
      "danger-plugin-yarn", 
      "@slack/client"
    ],
    "env_vars": ["SLACK_RFC_WEBHOOK_URL"]
  },
  "rules": {
    "pull_request": "artsy/artsy-danger@org/all-prs.ts"
  },
  "repos" : {
    "artsy/reaction": {
      "pull_request": "danger/pr.ts"
    },
    "artsy/positron": {
      "pull_request": "dangerfile.ts"
    },
    "artsy/artsy-danger": {
      "issues.opened": "artsy/artsy-danger@danger/new_rfc.ts"
    }
  }
}
```

</div>


<div style='flex:1; display: block; padding:0 20px;'>

<p><code>"settings":</code> These settings which conform to today's <a href='https://github.com/danger/peril/blob/752afeb37e3c1fdec512eb91687747d9a8a29337/source/db/index.ts#L26-L31'>GitHubInstallationSettings</a>, here's the <a href='https://github.com/danger/peril/blob/master/source/db/index.ts'>current version</a>. These are org-wide settings
that require a new deploy of the server to re-create.</p>

<p><code>"rules":</code> These are rules which are applied to every repo that Peril has access to. So in this case, every Pull Request in the org will make Peril run the Dangerfile at <code>"artsy/artsy-danger@org/all-prs.ts"</code>.</p>

<p><code>"repos":</code> These are repo-specific overrides, so a Pull Request to artsy/reaction would trigger both the org-wide Dangerfile, and one on the reaction repo.</p>

</div>


<p></article>
<article class='post'></p>

<a name="Events"></a>
<h2>Events</h2>

<p>A Dangerfile evaluation occurs once a GitHub webhook is sent. In the above examples there are two events that Danger supports:
<code>"pull_request"</code> and <code>"issues.opened"</code>. These are qualifiers that GitHub provide as a <a href="https://developer.github.com/v3/activity/events/types/events">Webhook EventTypes</a>.</p>

<p>There's a lot of them: <code>commit_comment</code>, <code>create</code>, <code>delete</code>, <code>deployment</code>, <code>deployment_status</code>, <code>fork</code>, <code>gollum</code>, <code>installation</code>, <code>installation_repositories</code>, <code>issue_comment</code>, <code>issues</code>, <code>label</code>, <code>marketplace_purchase</code>, <code>member</code>, <code>membership</code>, <code>milestone</code>, <code>organization</code>, <code>org_block</code>, <code>page_build</code>, <code>project_card</code>, <code>project_column</code>, <code>project</code>, <code>public</code>, <code>pull_request</code>, <code>pull_request_review</code>, <code>pull_request_review_comment</code>, <code>push</code>, <code>release</code>, <code>repository</code>, <code>status</code>, <code>team</code>, <code>team_add</code>, <code>watch</code>.</p>

<p>Some of these events also have unique sub-actions too:</p>

<ul>
<li><p>For an <code>issue</code> event there is: <code>assigned</code>, <code>unassigned</code>, <code>labeled</code>, <code>unlabeled</code>, <code>opened</code>, <code>edited</code>,  <code>milestoned</code>, <code>demilestoned</code>, <code>closed</code>, or <code>reopened</code></p></li>
<li><p>For a <code>pull_request</code> event there is: <code>assigned</code>, <code>unassigned</code>, <code>review_requested</code>, <code>review_request_removed</code>, <code>labeled</code>, <code>unlabeled</code>, <code>opened</code>, <code>edited</code>, <code>closed</code>, or <code>reopened</code></p></li>
</ul>


<p>The way that you define rules in Peril gives you the ability to either focus on one action for an event type: <code>"issues.opened"</code> or all actions
on an event: <code>"pull_request"</code>. Once you get your head around this, you start to get a sense of the scope of Peril. At Artsy, we've barely scratched the surface.</p>

<a name="Growth"></a>
<h3>Growth</h3>

<p>I've always advocated that Danger, and Peril should be <a href="http://danger.systems/js/usage/culture.html">applied incrementally</a>. This applies even more when you're
making org changes that affect every developer - at least with Danger you can see the Pull Request that changes
the Dangerfile. With Peril you get none of that.</p>

<p>So, we introduced <a href="https://github.com/artsy/artsy-danger/#rfcs">an RFC process for Peril changes</a>. There's not much to it, if you want to add a rule that
affects everyone then you need to make an issue following a template and then wait a week. If you make a new issue that
includes the title <code>RFC:</code> then Peril sends a slack message to our developer Channel</p>

<p><img src="/images/peril/peril-rfc.png" alt="/images/peril/peril-rfc.png" /></p>

<p>This was simple to build via Peril, I first added the npm module: <code>"@slack/client"</code> to the <code>"modules"</code> array, making it available to a Dangerfile. Then I added an environment variable to Peril for a newly minted Slack Incoming Webhook URL, and exposed it to Dangerfiles via: <code>"env_vars": ["SLACK_RFC_WEBHOOK_URL"]</code>.</p>

<p>Then I added a per-repo rule:</p>

<pre><code class="json">    "artsy/artsy-danger": {
      "issues.opened": "artsy/artsy-danger@danger/new_rfc.ts"
    }
</code></pre>

<p>This means the Dangerfile is only ran on <code>"issues"</code> with an <code>"opened"</code> action. I didn't want the discussion around a rule spamming our slack with webhooks from the other actions. The file <code>danger/new_rfc.ts</code> looks like this:</p>

<pre><code class="ts">import { schedule, danger } from "danger"
import { IncomingWebhook } from "@slack/client"
import { Issues } from "github-webhook-event-types"

declare const peril: any // danger/danger#351

const gh = danger.github as any as Issues
const issue = gh.issue

if (issue.title.includes("RFC:")) {
  var url = peril.env.SLACK_RFC_WEBHOOK_URL || "";
  var webhook = new IncomingWebhook(url)
  schedule( async () =&gt; {
   await webhook.send({
      unfurl_links: false,
      attachments: [{
        pretext: "üéâ A new Peril RFC has been published.",
        color: "good",
        title: issue.title,
        title_link: issue.html_url,
        author_name: issue.user.login,
        author_icon: issue.user.avatar_url
      }]
    })
  })
}
</code></pre>

<p>For events that are not a <code>"pull_request"</code> the <code>danger.github</code> object is the JSON for the event.  You can get TypeScript types available for every GitHub event via the NPM module <a href="https://www.npmjs.com/package/github-webhook-event-types">github-webhook-event-types</a> which makes it much easier to work with.</p>

<a name="Where.to.go.from.here."></a>
<h2>Where to go from here?</h2>

<p>Right now we have <a href="https://github.com/artsy/artsy-danger/issues?utf8=%E2%9C%93&amp;q=is%3Aissue%20RFC">a few RFCs</a>, and I don't spend all day making Peril rules, I've gotta <a href="https://github.com/artsy/emission/pulls?utf8=%E2%9C%93&amp;q=consignments%20">do work y'know</a>. We're going to slowly build out our Peril infrastructure.</p>

<p>I'm interested in exploring two ideas big for peril at the moment:</p>

<ul>
<li><p>What a Peril plugin system looks like: You can include modules which can listen to events and react themselves. An org-wide spellcheck on markdown files could be as easy as including <code>"modules": ["peril-plugin-spellcheck"]</code>.</p></li>
<li><p>What <a href="https://github.com/danger/peril/issues/138">scheduled jobs</a> could look like for Peril: We have a bunch of checks I'd like to make on a a regular occasion, and then passing back feedback via slack or making an issue on the repo.</p></li>
</ul>


<p> For example if a repo has an owner who isn't in Artsy anymore, we should highlight that it needs a new owner.</p>

<p>If you're interested in using Peril in large OSS projects, take a look at how Peril is used in CocoaPods via <a href="https://github.com/CocoaPods/peril-settings">CocoaPods/peril-settings</a>.</p>

<p>If you're interested in using Peril in your org, run through the <a href="https://github.com/danger/peril/blob/master/docs/setup_for_org.md">Setup for Org</a> guide and help improve it when you inevitably have some weird issues.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Danger]]></title>
    <link href="http://artsy.github.io/blog/2017/06/30/danger-one-oh-again/"/>
    <updated>2017-06-30T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2017/06/30/danger-one-oh-again</id>
    <content type="html"><![CDATA[<p>Danger came out of two needs. One from the needs of a growing dev team working together full-time, and the other from the needs of a completely asymmetric large Open Source project.</p>

<p>A work environment dev team is a complex place. You naturally grow, and to grow safely you add process. Process is a mixed bag, it's a net benefit at the trade-off of individual's time vs team cohesion. You want to grow your team guided by smart applications of process.</p>

<p>On the other hand, working on a large open source project, it's easy to feel overwhelmed at the amount of work that needs to get done on a daily basis. The growth of your OSS team probably doesn't tie to the amount of work that needs to be done. Especially if you're like me, and you don't want to be maintaining OSS as a 2nd full-time job.</p>

<p>So what do you do? Well in a work environment you don't really have a choice, as a team you hold each other to the rules that you set. In OSS, you sacrifice your spare time or you can find time at work, you could stop or you could burn out.</p>

<p>And this is the environment in which the idea of Danger was incubated.</p>

<p>Today mark version 1.0 of the second version of Danger. I'm going to cover what they are, how they continue to grow and what I see their trajectory as.</p>

<!-- more -->


<a name="Why."></a>
<h1>Why?</h1>

<p>Danger came from a need to customise the GitHub workflow for pull requests. In a work context, we wanted to add process like CHANGELOGs and be more thorough about testing. In Open Source, we needed to stop asking the same things to drive-by contributors. Their patches are valuable for sure, but asking for the same changes each time gets tiring. We want to work at a higher level of abstraction.</p>

<p>In both cases you want a way to give instant feedback for things that are "Unit Tests have failed" or "Code could not compile". However, it's hard to give feedback that says "You have not added a CHANGELOG entry in the right format."</p>

<p>Typically CI would only provide a binary: true or false response to the changes for review. We want a more shades of grey.</p>

<a name="What.does.Danger.do."></a>
<h2>What does Danger do?</h2>

<p>Danger acts as a way of creating unit tests at code review level. It gives you the ability to write tests that say: "has this file changed?", "does the contents of new files include this string?", "does the build log include a warning we know is bad news?" then the results of those tests are moved back into the place you're talking about the code.</p>

<p>To do this, you need to be able to create your own rules. Every team has different dynamics, and while it makes sense to offer a set of a set of standard rules that can work across a lot of projects - I'm pretty sure that the needs of the Artsy engineering team is different from the needs of your team.</p>

<p>Danger runs your code, and provides a set of easy to use APIs for you to build these useful culture rules. You write your rules in code, we call these files Dangerfiles. Similar to how a testing framework would give a set of expectations. The general gist is Danger provides access to:</p>

<ul>
<li>Changes from Git</li>
<li>Changes from GitHub/GitLab/BitBucket</li>
<li>Interacting with Danger</li>
</ul>


<p>By making per-project rules with these APIs, you can cover most rote tasks involved in code review. To make it easy for anyone to run Danger on every pull request, Danger was made to run during continuous integration.</p>

<a name="OK..so..2.versions.of.Danger.."></a>
<h1>OK, so "2 versions of Danger"?</h1>

<p>I first implemented Danger in Ruby. Ruby is a great language for building terminal apps, in the iOS community it's the language in which the largest OSS projects are built in. So, as someone used to building apps in that space, it wasn't really a debate what language to work with.</p>

<p>The Ruby build of Danger is now at 5.x with almost 100 releases, it's a solid exploration into code review automation. Ultimately though, I started to feel three main pain-points:</p>

<ul>
<li><p>At Artsy, we moved our mobile team to React Native, and other teams were also consolidating on JavaScript everywhere. It felt weird using a Ruby inside a strictly JS only context.</p></li>
<li><p>Trying to re-create the environment of a PR was tricky from inside the CI. For example most providers are good at about saving on space and bandwidth during a run, and Danger often has to ruin that in order to replicate the PR locally.</p></li>
<li><p>I wanted to explore server-side Dangerfiles. I wouldn't feel comfortable hosting a server that allows anyone to run their own Ruby code. Ruby isn't built with sandboxing in mind.</p></li>
</ul>


<a name="JavaScript"></a>
<h2>JavaScript</h2>

<p>First I explored the idea of having JavaScript based Dangerfiles inside the Ruby version of Danger. I did this by <a href="https://github.com/danger/danger/pull/422">bridging Danger's Ruby objects into a JavaScript context</a> and allowing bi-directional communication between the two. This handled some of the immediate needs, but proved inadequate when working with JavaScript's simple system library and it ignored all other JavaScript tooling.</p>

<p>After enough time, I came to the conclusion that realistically, to use JavaScript properly, you need node modules and npm.</p>

<p>So 10 months ago I decided it was worth starting from scratch and re-created Danger in JavaScript. I had time to consider what I would do differently, and this time I added one key additional restraints on the system: Data can only come from an API.</p>

<p>This constraint negates one of the key problems with running running a Dangerfile on a server - having to have a copy of the code and the PR's environment.</p>

<p>In addition, JavaScript has a much simpler model for evaluating, importing and exporting code and so whitelisting modules and functions can be feasible for a hosted version of Danger.</p>

<center><img src ="/images/danger/danger.png" style="width:50%"></center>


<a name="L1.0.is.my.middle.name"></a>
<h1>1.0 is my middle name</h1>

<p>Any software project used in production should probably be 1.0, but in addition to production use a library needs documentation to be 1.0.</p>

<p>Calling Danger production ready means doing the entire <a href="http://artsy.github.io/blog/2016/07/03/handling-big-projects/">Defensive OSS</a> process: Documentation, Guides, API Reference, Website and Branding.</p>

<p>Once each version of Danger had started to mature to a point that the user-facing aspect stopped changing I started focusing on the documentation engine and website. In both cases, a considerable amount of documentation is generated from the source code of Danger. I'm a big fan of keeping that inside the source code and building documentation sites which import it directly.</p>

<a name="So.what.can.I.do.with.Danger."></a>
<h1>So what can I do with Danger?</h1>

<p>In one way this is a bit like asking, so what can I test with unit tests? Anything, within the scope of: the PR, build artifacts and introspecting the codebase.</p>

<p>I'll cover a quick API overview, then talk about how you can work with these:</p>

<a name="Git"></a>
<h3>Git</h3>

<ul>
<li>What files have been added, removed or changed.</li>
<li>Changes specific to a file.</li>
<li>Looking into Commits.</li>
<li>Exploring the Diff.</li>
</ul>


<a name="GitHub...GitLab...BitBucket"></a>
<h3>GitHub / GitLab / BitBucket</h3>

<ul>
<li>Access to the PR's JSON representation.</li>
<li>Consistent access for PR body, title, author across all platforms.</li>
<li>Util functions for linking to files.</li>
</ul>


<a name="Danger"></a>
<h3>Danger</h3>

<ul>
<li>Handle running other Dangerfiles.</li>
<li>Handles plugin management.</li>
<li>Provides a set of utility functions that would often get used.</li>
</ul>


<a name="Messaging"></a>
<h3>Messaging</h3>

<ul>
<li>Leave warnings, messages and markdown comments.</li>
<li>Leave errors, marking the build as failed.</li>
<li>Post any of the above of the above inside a file.</li>
<li>Create a GitHub review, and use the above messaging.</li>
</ul>


<a name="Plugins"></a>
<h3>Plugins</h3>

<ul>
<li>Infrastructure for shared rules.</li>
<li>Opens up the ability to validate tricky things with an easy API.</li>
</ul>


<p>The API differs between the JS and Ruby version, not drastically - but there are no plugins for Danger JS yet. That's still a bit away.</p>

<a name="OK..got.it."></a>
<h2>OK, got it.</h2>

<p>Let's cover a few examples of the kind of tests can you write.</p>

<a name="Checking.for.changes.to.a.specific.file"></a>
<h4>Checking for changes to a specific file</h4>

<p>Checking for a CHANGELOG. This was the first rule imagined for Danger, I add it to every project.</p>

<p>The first implementation of this rule can just be a check if the file <code>CHANGELOG.md</code> is modified in any PR, that can then be
revised to also check whether there are git changes related to your app. Then documentation, README, tooling updates
don't require an entry. We also check if the PR title says "trivial" and skip the CHANGELOG check.</p>

<p>If you're interested in standardizing on the <a href="http://keepachangelog.com/en/0.3.0/">keepachangelog.com</a> format there is <a href="https://github.com/dblock/danger-changelog">danger-changelog</a>.</p>

<p>Some other examples around this is pinging specific people when a file has changed, or failing if a file that's never meant
to be modified is changed, warning about potential semantic version updates for changes to specific files.</p>

<a name="Checking.the.results.of.command-line.tools"></a>
<h4>Checking the results of command-line tools</h4>

<p>The Artsy developer blog runs both a spell checker, and a prose linter. These report back on files added or
modified during the PR. As someone known for writing loose and quick, having a machine provide some automatic feedback
makes it easy to not waste my reviewers time.</p>

<p>This is done by the <a href="https://github.com/dbgrandi/danger-prose">danger-prose</a> plugin, which wraps both an <a href="https://github.com/lukeapage/node-markdown-spellcheck">npm module</a> and a <a href="https://github.com/amperser/proselint/">python egg</a>.
The plugin handles installing and running the CLI, then converts the output into markdown for github.</p>

<a name="Handling.build.artifacts"></a>
<h4>Handling build artifacts</h4>

<p>If Danger runs after the build process, you can read build logs to provide better feedback. This can range from taking
the results of a test run and posting what has failed (e.g. <a href="https://github.com/orta/danger-junit">danger-junit</a>), to finding specific strings inside
build logs and highlighting them.</p>

<p>In our native iOS app, when a developer accidentally adds code which accesses the network in a test. That is logged out
during the build. Then later, danger will read the logs to find any mentions of this and post it in the comment.</p>

<a name="PR.Metadata"></a>
<h4>PR Metadata</h4>

<p>Every team's workflow is different, but it's pretty common to use a tool other than code review for keeping track of a project's momentum. You can use Danger to warn people that they haven't included a Trello, or JIRA ticket reference on
every PR.</p>

<p>A similar approach could be to warn if someone is sending a PR to a branch other than the preferred branch. This works
well if you use the git-flow model for branches.</p>

<p>We nearly always add a check to see if someone is assigned to a PR, and warn it it's unassigned in front-end projects.</p>

<a name="Using.the.platform.API"></a>
<h4>Using the platform API</h4>

<p>There's no limits here, by using the API from your platform you can perform any sorts of checks. In the Danger repo
we use the GitHub API to note whether someone is in the Danger org, to remind the core team to invite them to the org
after submitting a PR.</p>

<a name="Introducing.Danger"></a>
<h2>Introducing Danger</h2>

<p>OK, maybe that's got you thinking <em>"ah, I know a process I can automate"</em>.</p>

<p>It can be easy to try and jump straight from no Dangerfile to a many-hundred lined complex set of cultural rules. I'd advise against introducing a long list of rules for Danger all at once. In my experience, gradual integration works better. The entire team may have agreed on the changes upfront, but slower adoption has worked better for teams new to working with Danger.</p>

<p>At Artsy we've found that first just integrating Danger with a single simple rule (like checking for a CHANGELOG entry) then starting to introduce them piece-meal from different contributors has made it easier to go from "Ah, we shouldn't do that again" to "Oh, we could make a Danger rule for that" to "Here's the PR".</p>

<a name="Which.Danger.should.I.use."></a>
<h2>Which Danger should I use?</h2>

<p>This definitely depends on the project, there's a longer discussion <a href="http://danger.systems/js/js-vs-ruby.html">on the site</a> too, but here's the main gist:</p>

<ul>
<li><p><strong>Danger Ruby</strong> is more mature, has more features, a solid plugin eco-system and covers more platforms. It's in a great place and is unlikely to have breaking changes from this point onwards.</p></li>
<li><p><strong>Danger JS</strong> has a bigger potential for growth, is "stable enough", you can create plugins and will be able to do things that the Ruby version could not - eventually. Right now it only works with GitHub.</p></li>
</ul>


<a name="Onwards.and.Upwards"></a>
<h2>Onwards and Upwards</h2>

<p>With the JavaScript version of Danger in a great place ready for production, I can start more serious work on <a href="https://github.com/danger/peril#peril">Peril</a>. Peril is a hosted web-service that runs Dangerfiles against GitHub events, see <a href="https://github.com/danger/peril/blob/master/VISION.md">the VISION.md</a>. Those events span from a new user being created, to a new issue on a repo. Peril lets you run your own complex rules across an entire org. This can be a really powerful way to audit and improve entire-company culture.</p>

<p>We started using Peril in Artsy <a href="https://github.com/artsy/reaction-force/pull/184">last week</a>. So it's starting to become a thing internally. It'll be awesome to explore the idea of org-wide rules. I think we're starting with making sure we assign someone on a PR.</p>

<p>So give Danger a shot, and if you're bold. give <a href="https://github.com/danger/peril#peril">Peril</a> a shot.</p>

<hr />

<p>This post uses the CC license image from <a href="https://twitter.com/CloudyConway/status/880426417024114688">this tweet</a> with some changes to make it fit with the design of the blog. Thanks <a href="https://www.patreon.com/vexorian">Vexorian</a>.</p>
]]></content>
  </entry>
  
</feed>
