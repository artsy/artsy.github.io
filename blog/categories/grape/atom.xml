<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Grape | Art.sy Engineering]]></title>
  <link href="http://artsy.github.com/blog/categories/grape/atom.xml" rel="self"/>
  <link href="http://artsy.github.com/"/>
  <updated>2013-01-31T10:54:02-05:00</updated>
  <id>http://artsy.github.com/</id>
  <author>
    <name><![CDATA[Art.sy]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Measuring Performance in Grape APIs with NewRelic RPM]]></title>
    <link href="http://artsy.github.com/blog/2012/11/29/measuring-performance-in-grape-apis-with-new-relic/"/>
    <updated>2012-11-29T21:21:00-05:00</updated>
    <id>http://artsy.github.com/blog/2012/11/29/measuring-performance-in-grape-apis-with-new-relic</id>
    <content type="html"><![CDATA[<p>Knowing how well your API performs in real time is essential to any successful project. That's because you can't fix what you can't measure.</p>

<p>We use and heavily contribute to <a href="http://github.com/intridea/grape">Grape</a>, a Ruby API DSL. Grape is a Rack middleware and we have been reporting API performance data to <a href="http://newrelic.com/">NewRelic</a> with code from <a href="http://code.dblock.org/new-relic-performance-instrumentation-with-grape-api">my older blog post</a>.</p>

<p>It's time to improve the reporting implementation and address performance monitoring in both development and production environments. Here's what a single API request breakdown is going to look like.</p>

<p><img src="http://artsy.github.com/images/2012-11-29-measuring-performance-in-grape-apis-with-new-relic/transaction-detail.png"></p>

<!-- more -->


<h2>NewRelic RPM</h2>

<p>The first step is to add the <code>newrelic_rpm</code> gem to Gemfile, which implements the actual realtime performance reporting to NewRelic. We also use <a href="https://github.com/mongoid/mongoid">Mongoid</a> and the <a href="https://github.com/mongoid/moped">Moped</a> MongoDB Ruby driver, which can be instrumented with <code>newrelic_moped</code>.</p>

<p><code>ruby Gemfile
gem "newrelic_moped", "0.0.3"
gem "newrelic_rpm", "3.3.3"
</code></p>

<p>You will need <code>config/newrelic.yml</code> in your application. Ours can be found in <a href="https://gist.github.com/4170458">this gist</a> and works well both locally and on Heroku.</p>

<h2>Instrumenting Grape</h2>

<p>In the past we used <a href="https://gist.github.com/1233422">NewRelic::Agent::Instrumentation::API</a>, which works for any generic Rack middleware. This would report all API calls to NewRelic, but would treat requests to <em>/api/artist/andy-warhol</em> and <em>/api/artist/wassily-kandinsky</em> as unrelated. That is because the instrumenter is a Rack middleware that wraps Grape requests <em>before</em> they reach Grape. The only information available is the request URL, and not the actual API route that is going to be matched when the request is processed.</p>

<p>We want both requests to <em>/api/artist/andy-warhol</em> and <em>/api/artist/wassily-kandinsky</em> to be treated as <em>/api/artist/:id</em>. Lets insert a middleware inside Grape itself, once the URL has been matched to a route.</p>

<p><code>ruby api.rb
class API &lt;&lt; Grape::API
  use ApiNewRelicInstrumenter
  ...
end
</code></p>

<p>The new instrumenter has access to the current API endpoint via <code>env['api.endpoint']</code> and reports data via NewRelic's <code>ControllerInstrumentation</code>.</p>

<p>``` ruby
class ApiNewRelicInstrumenter &lt; Grape::Middleware::Base
  include NewRelic::Agent::Instrumentation::ControllerInstrumentation</p>

<p>  def call(env)</p>

<pre><code>trace_options = {
  category: :rack,
  path: env['api.endpoint'].routes.first.route_path,
  request: request,
  ...
}

perform_action_with_newrelic_trace(trace_options) do
  yield
end
</code></pre>

<p>  end
end
```</p>

<p>The complete code for <code>ApiNewRelicInstrumenter</code> can be found in <a href="https://gist.github.com/4170469">this gist</a>. It supports enabling and disabling performance reporting by setting <code>NEW_RELIC_ID</code> and works around NewRelic's method name limitations (these cannot contain slashes).</p>

<h2>Development Environment</h2>

<p>You can now see NewRelic performance data in development mode, too. If you mount Grape inside Rails run <code>NEW_RELIC_ID=foo rails s</code>. Navigate to <em>http://localhost:3000/newrelic</em> to see your local traces.</p>

<p><img src="http://artsy.github.com/images/2012-11-29-measuring-performance-in-grape-apis-with-new-relic/developer-mode.png"></p>

<p>Drill into an individual request to find several detailed breakdowns of how time was spent, including specific MongoDB queries (under "SQL", naturally).</p>

<p><img src="http://artsy.github.com/images/2012-11-29-measuring-performance-in-grape-apis-with-new-relic/sql-detail.png"></p>

<p>NewRelic is a commercial product, but you can run development mode for free! Note that enabling this will triple your local Rails boot time: we enable development mode by setting <code>development_mode: &lt;%= !!ENV['NEW_RELIC_ID'] %&gt;</code> in <a href="https://gist.github.com/4170458">newrelic.rpm</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Monitor 503s and Timeout Requests on Heroku]]></title>
    <link href="http://artsy.github.com/blog/2012/11/15/how-to-monitor-503s-and-timeout-on-heroku/"/>
    <updated>2012-11-15T21:21:00-05:00</updated>
    <id>http://artsy.github.com/blog/2012/11/15/how-to-monitor-503s-and-timeout-on-heroku</id>
    <content type="html"><![CDATA[<p>We have recently started hitting an unusually high number of "503: Service Unavailable" errors with one of our applications on Heroku. What are these? How can we monitor their quantity and frequency? What's the fix?</p>

<p><img src="http://artsy.github.com/images/2012-11-15-how-to-monitor-503s-and-timeout-on-heroku/503-error.png"></p>

<!-- more -->


<h2>What does 503 mean?</h2>

<p>A 503 error means "Service Unavailable". Heroku returns a 503 error when an HTTP request times out between the Heroku routing mesh and your application, including when the application failed to boot. This timeout limit is set to 30 seconds, as <a href="https://devcenter.heroku.com/articles/request-timeout">documented by Heroku</a>, and shows up in the logs as follows.</p>

<p><code>
Nov 14 12:10:50 production heroku/router:
 Error H12 (Request timeout) -&gt; GET artsy.net/api/spline
 dyno=web.11 queue= wait= service=30000ms status=503 bytes=0
</code></p>

<p>This usually means that the application could not process the request fast enough, and in very rare cases, that there's an infrastructure problem with Heroku itself. A 504 error which means "Gateway Timeout" would have probably been a more appropriate choice. Either way, the root cause could be something as simple as trying to run a very long database query or do too much work that doesn't fit in a 30 seconds window. It could also involve an external service that didn't respond quickly enough. Your mileage may vary.</p>

<h2>Monitoring 503s</h2>

<p>503 errors don't happen within your application, they are reported by the routing mesh. They will not appear in internal monitoring systems attached to your app, including <a href="http://newrelic.com/">NewRelic</a>.</p>

<p>We get the frequency of 503s by sending our Heroku logs to <a href="https://papertrailapp.com/">Papertrail</a> and using their <a href="http://help.papertrailapp.com/kb/how-it-works/alerts">alerts feature</a> to push the number of 503s to <a href="http://www.geckoboard.com/">Geckoboard</a>. You can send these to <a href="http://graphite.wikidot.com/">Graphite</a> or any other monitoring system in the same manner.</p>

<p>This is what it looks like:</p>

<p><img src="http://artsy.github.com/images/2012-11-15-how-to-monitor-503s-and-timeout-on-heroku/503-geckoboard.png"></p>

<h2>Aborting Requests</h2>

<p>When Heroku reports a 503 status code, it just gives up. Your application continues executing the request though, often to completion, which may take forever. In the meantime, Heroku will send a new request to the dyno that's still busy, and get a new 503. This is known as a "stuck" dyno.</p>

<p>To prevent dynos from being stuck you must abort the request within the 30 second period. This can be accomplished with the <a href="https://github.com/kch/rack-timeout">rack-timeout</a> gem and setting <code>Rack::Timeout.timeout = 29</code> in an initializer (or a smaller value within which you want to guarantee a response). The gem automatically inserts itself into a Rails application, but you will need to manually mount it in other Rack apps, such as those using <a href="https://github.com/intridea/grape">Grape</a>.</p>

<p>``` ruby api.rb
class Api &lt; Grape::API
  use Rack::Timeout</p>

<p>  desc "Returns a reticulated spline."
  get "spline/:id"</p>

<pre><code>Spline.find(params[:id])
</code></pre>

<p>  end
end
```</p>

<p>Because your application is now getting a timeout exception, you can also report it in NewRelic. The following works in Grape.</p>

<p>``` ruby
rescue_from Timeout::Error, :backtrace => true do |e|
  NewRelic::Agent.instance.error_collector.notice_error e,</p>

<pre><code>uri: request.path,
referer: request.referer,
request_params: request.params
</code></pre>

<p>  rack_response({</p>

<pre><code>:type =&gt; "timeout_error",
:message =&gt; "The request timed out."
</code></pre>

<p>  }.to_json, 503)
end
```</p>

<p>Don't forget to write a test!</p>

<p>``` ruby api_spec.rb
require 'spec_helper'</p>

<p>describe Api do
  it "times out after Rack::Timeout.timeout" do</p>

<pre><code>Rack::Timeout.stub(:timeout).and_return(1)
Spline.stub(:find) { sleep 3 }
get "/spline/1"
response.status.should == 503
response.body.should == '{"type":"timeout_error","message":"The request timed out."}'
</code></pre>

<p>  end
end
```</p>

<h2>Fixing Timeouts</h2>

<p>The root causes of timeouts are specific to your application. Our general approach for long running requests is to offload the request processing into a delayed job or background process and "cook" data in a way that makes it readily available to API endpoints. You can read more about this and related aspects of our system architecture in <a href="/blog/2012/10/10/artsy-technology-stack/">this earlier blog post</a>.</p>
]]></content>
  </entry>
  
</feed>
