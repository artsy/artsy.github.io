<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: api | Artsy Engineering]]></title>
  <link href="http://artsy.github.io/blog/categories/api/atom.xml" rel="self"/>
  <link href="http://artsy.github.io/"/>
  <updated>2016-01-28T18:28:33+00:00</updated>
  <id>http://artsy.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Designing the Public Artsy API]]></title>
    <link href="http://artsy.github.io/blog/2014/09/12/designing-the-public-artsy-api/"/>
    <updated>2014-09-12T12:21:00+00:00</updated>
    <id>http://artsy.github.io/blog/2014/09/12/designing-the-public-artsy-api</id>
    <content type="html"><![CDATA[<p>Today we are happy to announce that we're making a new public API generally available, along with over 26,000 artworks from many of our institutional partners.</p>

<p>The Artsy API currently provides access to images of historic artwork and related information on <a href="https://artsy.net">artsy.net</a> for educational and other non-commercial purposes. You can try it for playing, testing, and learning, but not yet for production. The scope of the API will expand in the future as it gains some traction.</p>

<p><a href="https://developers.artsy.net"><img src="/images/2014-09-12-designing-the-public-artsy-api/the-art-world-in-your-app.png" border="0"></a></p>

<p>If you just want to use the API, you can stop reading here and head to the <a href="https://developers.artsy.net/">developers.artsy.net</a> website. (The developers website itself is a classic Rails + Boootstrap example and is also <a href="https://github.com/artsy/doppler">open-source</a>.)</p>

<p>In this post we will step back and describe some of the technical decisions made during the development of the new API.</p>

<!-- more -->


<h2>First, Make All The Mistakes</h2>

<p>Artsy has been developing a homegrown API over the last four years, consisting of almost 400 endpoints and exposing over 100 domain models. It's probably one of the largest <a href="https://github.com/intridea/grape">Ruby Grape</a> implementations and it has been battlefield-tested by the dozens of services that we have built around it, starting with our <a href="https://github.com/artsy/force-public">recently open-sourced artsy.net website</a>. The core API project itself is unfortunately not public.</p>

<p>As with all legacy code with many client dependencies, our API has accumulated a staggering number of architectural faults, which have become impossible to work ourselves out of without a major rewrite. When thinking about a public API we went back to the drawing board with a more pragmatic approach.</p>

<h2>Use Hypermedia</h2>

<p>One of the common problems of being an API client is figuring out which routes an API provides or what data is available. For example, what can I do with this specific artwork? Documentation helps, but it often lacks such context. Furthermore, URLs are long and cumbersome to reference, parse and use. How can we make the API more developer-friendly and discoverable? Our answer was to settle on a well-known Hypermedia format. We chose <a href="http://stateless.co/hal_specification.html">HAL+JSON</a> because it is disciplined and very complete. Let me illustrate by example.</p>

<p>The <a href="https://api.artsy.net/api">API root</a> lists all the API routes within "_links", such as "artists".</p>

<pre><code class="json">{
  _links: {
    artists: {
      href: "https://api.artsy.net/api/artists"
    },
    ...
  }
}
</code></pre>

<p>If you fetch artists from the above URL, they will be returned in the same JSON+HAL format. Each artist will include a number of links, notably to the artist's artworks. This is a perfect example of "context".</p>

<pre><code class="json">{
  _embedded: {
    artists: [
      {
        id: 123,
        _links: {
          artworks: {
            href: "https://api.artsy.net/api/artworks?artist_id=123"
          }
        }
      }
    ]
  }
}
</code></pre>

<p>This is very powerful and makes it possible to write a generic API client that consumes any HAL+JSON API with just a bit of meta-programming. For Ruby, we provide examples using <a href="https://github.com/codegram/hyperclient">hyperclient</a>. Here's a more complete example that retrieves a well-known artist, <a href="https://artsy.net/artist/gustav-klimt">Gustav Klimt</a>, and a few of his works.</p>

<pre><code class="ruby">require 'hyperclient'

api = Hyperclient.new('https://api.artsy.net/api').tap do |api|
  api.headers.update('Accept' =&gt; 'application/vnd.artsy-v2+json')
  api.headers.update('X-Xapp-Token' =&gt; ...)
end

artist = api.links.artist.expand(id: '4d8b92b64eb68a1b2c000414') # Gustav Klimt
puts "#{artist.attributes.name} was born in #{artist.attributes.birthday} in #{artist.attributes.hometown}"

artist.links.artworks.embedded.artworks.each do |artwork|
  puts artwork.attributes.title
end
</code></pre>

<h2>Provide Canonical URLs for Resources</h2>

<p>In the past we returned different JSON payloads for a resource when it appeared within a collection vs. when it was retrieved individually. We have also developed solutions such as <a href="https://github.com/dblock/mongoid-cached-json">mongoid-cached-json</a> to deal with this in a declarative way. However, clients were burdened to merge data. For example, our iOS application had to deal with the fact that different data existed in the local store for the same artwork depending on how a user navigated to it in the app.</p>

<p>With the new API each resource has a canonical, uniquely identifying, "self" link which is used to reference it from other resources. When a client encounters such a link and has already downloaded the resource, it can just swap the data without making an HTTP request. This is only possible because every single URL maps 1:1 with a specific JSON response - there're no two data responses possible for the same URL. The retrieval of such data can be solved by a generic crawler - get a resource, fetch dependent resource links, iterate until you run out of links. Storage is even simpler and doesn't have to know anything about our domain model since it just maps URLs to JSON bodies.</p>

<h2>Partition Data and Perform Access Controls at API Level</h2>

<p>Because we decided not to return two different types of responses for a given model, we needed to partition data at the model level. For example, we introduced publicly available <a href="https://developers.artsy.net/docs/users">Users</a> and private <a href="https://developers.artsy.net/docs/user_details">User Details</a>. Access controls are now done exclusively at the API level.</p>

<p>The API developer must simply answer the question of whether a client is authorized to retrieve a resource or not. The API will return a 403 or 404 otherwise and it's not necessary to customize the response for different types of access.</p>

<h2>Be Disciplined About Data Access and NxM Queries</h2>

<p>The performance of APIs that return collections of objects has been a constant struggle. The initial API design attempted to help clients make the least amount of HTTP requests possible, often requiring many NxM server-side queries. This actually had a profoundly negative impact on overall performance and user experience than we have ever anticipated. Servers had to allocate a lot more memory to parse, render and cache very large JSON payloads, also causing larger garbage collection cycles. Web applications seemed slower because a lot of data had to be retrieved to render anything on initial page load. Mobile clients spend a lot more time parsing huge JSON payloads, requiring a lot of CPU and yielding rarely. This created a very sluggish user experience and much longer delays waiting for background processing to finish. To mitigate this and keep our API response times low on the server we had to leverage complicated caching schemes with <a href="https://github.com/artsy/garner">garner</a> and had to fine-tune Mongoid's eager-loading endpoint by endpoint.</p>

<p>For the new API we decided to never return relational data for a given model and refactor relations at the API model level when necessary. For example, we do not return artist information with a given artwork, but we do return a collection of artist links (an artwork can be created by a group of artists).</p>

<pre><code class="json">_embedded: {
    artist_links: [
      {
        id: "4fe8862daa12fb00010017b9",
        _links: {
          artist: {
            href: "https://api.artsy.net/api/artists/4fe8862daa12fb00010017b9"
          }
        }
      }
    ],
  }
}
</code></pre>

<p>We can still leverage the fact that we do have embedded objects in MongoDB and the fact that HAL supports embedded data. For example, we always return editions embedded within an artwork. Being disciplined about this allows the server to make one database query for one API request.</p>

<p>Furthermore, creating such rigid rules forces us to never optimize for a specific client's scenario. That said, we still want to make life easy for developers that need bulk loading of various resources. We plan to implement a <a href="http://techblog.netflix.com/2012/07/embracing-differences-inside-netflix.html">Netflix API</a>-style middleware, where you can supply a set of URLs and get back a single, full JSON response with many different embedded resources. HAL+JSON's disciplined structure makes mixing data very easy.</p>

<h2>Use Media Types and Accept Headers for Versioning</h2>

<p>Our initial API lives under a versioned URL which includes "v1". For the new API we decided to adopt a different model and use an "Accept" header which currently takes an optional "application/vnd.artsy-v2+json" media type.</p>

<pre><code>$ curl 'http://api.artsy.net/api' -H 'Accept:application/vnd.artsy-v2+json'
</code></pre>

<p>Accept headers in the API context can be used to indicate that the request is specifically limited to an API version. Our API will serve a backward compatible format by default. However, when we decide change the format of a resource we will increment the API version and require a newer value in the header to retrieve it. The new version can become the default only after the old version has been fully deprecated.</p>

<h2>Create a Flat API Structure and Leverage 302 Redirects</h2>

<p>Our old API served all artworks from "/artworks" and artworks belonging to a partner from "/partner/:id/artworks". This was convenient, but made obsolete by a Hypermedia API. API URL structure no longer matters, because you no longer have to build URLs yourself, but follow links instead.</p>

<p>We decided to expose all models at the root and to use query string parameters for filtering. The API uses a plural for all routes, so you can query both "/artworks" and "/artworks/:artwork_id". At the Hypermedia API root level those differences are expressed in a declarative way in the shape of link templates with a singular (an artwork) or a plural (artworks) key, and all possible parameters.</p>

<pre><code class="json">{
  _links: {
    artworks: {
      href: "https://api.artsy.net/api/artworks{?public,artist_id}",
      templated: true
    },
    artwork: {
      href: "https://api.artsy.net/api/artworks/{id}",
      templated: true
    }
  }
}
</code></pre>

<p>We leverage 302 redirects extensively. For example, querying "/current_user" redirects to "/users/:user_id" with a 302 status code (we cannot serve different content per user at the root of the API, as explained in a section above). Another good example is that the current API only provides access to public domain artworks, so if you navigate to "/artworks", you will currently be redirected to "/artworks?public=true", making this scheme future-proof.</p>

<h2>Do Not Paginate with Pages and Offsets</h2>

<p>Our original API accepted "page" or "offset" parameters. This was rather problematic for changing collections. Consider what happens when you are on page 5 and an item is inserted on page 4. Your next set of results for page 6 will include a duplicate that has just moved from page 5 onto page 6. Similarly, if an item was removed from page 4, a request to page 6 will skip an item that now appears on page 5.</p>

<p>Our new API returns subsets of collections with "next" links and optional counts. To fetch a subsequent page, follow the "next" link, which accepts an opaque "cursor" (internally we use the <a href="https://github.com/dblock/mongoid-scroll">mongoid-scroll</a> Ruby gem). The cursor retains position in a collection, including when an item has been deleted.</p>

<pre><code class="json">{
  total_count: 26074,
  _links: {
    self: {
      href: "https://api.artsy.net/api/artworks?public=true"
    },
    next: {
      href: "https://api.artsy.net/api/artworks?cursor=...&amp;public=true"
    }
  }
}
</code></pre>

<p>We also wanted to solve the problem of querying different page sizes as we often wanted to retrieve just a couple of items quickly on an initial page load, then make larger requests for subsequent pages as the user scrolled, or vice-versa. You can now supply "size" to all collection APIs and a cursored approach makes it possible to vary the number on every request.</p>

<p>To get the "total_count", we decided to require clients to append "?total_count=true" to the query string. It's not necessary to do all that counting work on the server side if you're not going to use the data.</p>

<h2>Standardize Error Format</h2>

<p>We use HTTP error codes, however we also use JSON data that comes with those errors for additional, often humanly readable descriptions. We settled on a standard error format that includes a "type" and a "message". For example, a 401 Unauthorized response will also carry the following payload.</p>

<pre><code class="json">{
  type: "auth_error",
  message: "The access token is invalid or has expired."
}
</code></pre>

<h2>Conclusion</h2>

<p>We tried to stay pragmatic with our approach and still have time and room for improvements. We would love to hear from you on our <a href="http://groups.google.com/group/artsy-api-developers/subscribe">API developers mailing list</a> and hope you'll give our new API a try at <a href="https://developers.artsy.net/">developers.artsy.net</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Improving Performance of Mongoid-Cached-Json]]></title>
    <link href="http://artsy.github.io/blog/2013/01/20/improving-performance-of-mongoid-cached-json/"/>
    <updated>2013-01-20T21:21:00+00:00</updated>
    <id>http://artsy.github.io/blog/2013/01/20/improving-performance-of-mongoid-cached-json</id>
    <content type="html"><![CDATA[<p>Last year, we have open-sourced and made extensive use of two Ruby libraries in our API: <a href="https://github.com/dblock/mongoid-cached-json">mongoid-cached-json</a> and <a href="https://github.com/artsy/garner">garner</a>. Both transform the procedural nightmare of caching and JSON generation into a declarative and easily manageable DSL. It was worth the investment, since our service spends half of its time generating JSON and reading from and writing to Memcached.</p>

<p>Today we've released mongoid-cached-json 1.4 with two interesting performance improvements.</p>

<!-- more -->


<h2>Bulk Reference Resolving with a Local Cache</h2>

<p>Consider an array of database model instances, each with numerous references to other objects. It's typical to see such instances reference the same object: for example we have an <code>Artwork</code> that references an <code>Artist</code>. It's common to see multiple artworks reference the same artist in a collection. Retrieving the artist from cache every time it is referenced is clearly inefficient.</p>

<p><code>Mongoid::CachedJson</code> will now collect all JSON references, then resolve them after suppressing duplicates, in-place within the JSON tree. This significantly reduces the number of cache queries.</p>

<p>Note, that while this optimization reduces load on the Memcached servers, there's a cost of doing additional work after collecting the entire JSON in Ruby.</p>

<h2>Fetching Cache Data in Bulk</h2>

<p>Various cache stores, including Memcached, support bulk read operations. The <a href="https://github.com/mperham/dalli">Dalli</a> gem, which we use in production, exposes this via the <code>read_multi</code> method. With the bulk reference optimization above we now have the entire list of keys to query from cache, at once. <code>Mongoid::CachedJson</code> will always invoke <code>read_multi</code> where available, which significantly reduces the number of network roundtrips to the cache servers.</p>

<p>This is a good example of where declarative models and DSLs have tremendous advantages in enabling massive improvements across the board. Imagine making the <code>read_multi</code> optimization in hundreds of API endpoints!</p>

<h2>Benchmarks</h2>

<p>With the above optimizations the library does more work in order to make less roundtrips to Memcached over the network. Since the network is often the slowest part in any large scale system, the overall production performance should be better as long as we can obtain similar throughput in ideal network conditions on localhost. We've added some common case benchmarks in <a href="https://github.com/dblock/mongoid-cached-json/blob/master/spec/benchmark_spec.rb">spec/benchmark_spec.rb</a> and ran them against 1.2.3 and 1.4.0 to obtain <a href="https://gist.github.com/4583039">these results</a>. The overall performance gain averaged 14.6%, which is quite significant. With real world data in a production environment we're seeing 15-50% less time spent in Memcached, depending on the API.</p>

<h2>Links</h2>

<p>The concepts behind these improvements should be attributed to <a href="https://github.com/aaw">@aaw</a> and <a href="https://github.com/macreery">@macreery</a>. If you want to learn more about the above-mentioned libraries, check out the following links:</p>

<ul>
<li><a href="http://confreaks.com/videos/986-goruco2012-from-zero-to-api-cache-w-grape-mongodb-in-10-minutes">From Zero to API-Cache w/ Grape and MongoDB</a>, video recorded at GoRuCo</li>
<li><a href="/blog/2012/02/20/caching-model-json-with-mongoid-cached-json/">Caching Model JSON with Mongoid-Cached-Json</a></li>
<li><a href="/blog/2012/03/23/simplifying-model-level-json-versioning-with-mongoid-cached-json/">Simplifying Model Level Versioning with Mongoid-Cched-Json</a></li>
<li><a href="/blog/2012/05/30/restful-api-caching-with-garner/">RESTful API Caching with Garner</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RESTful API Caching with Garner]]></title>
    <link href="http://artsy.github.io/blog/2012/05/30/restful-api-caching-with-garner/"/>
    <updated>2012-05-30T21:21:00+00:00</updated>
    <id>http://artsy.github.io/blog/2012/05/30/restful-api-caching-with-garner</id>
    <content type="html"><![CDATA[<p>Implementing server-side RESTful API caching is hard. In a straightforward API all the expiry decisions can be made automatically based on the URL, but most real world APIs that add requirements around object relationships or user authorization make caching particularly challenging.</p>

<p>At <a href="http://goruco.com/">GoRuCo</a> we open-sourced <a href="http://github.com/artsy/garner">Garner</a>, a cache implementation of the concepts described in this post. To "garner" means to gather data from various sources and to make it readily available in one place, kind-of like a cache! Garner works today with the <a href="http://github.com/intridea/grape">Grape API framework</a> and the <a href="http://github.com/mongoid/mongoid">Mongoid ODM</a>. We encourage you to fork the project, extend our library to other systems and contribute your code back, if you find it useful.</p>

<p>Garner implements the Artsy API caching cookbook that has been tried by fire in production.</p>

<!-- more -->


<h3>Enabling Caching of Static Data</h3>

<p>Caching static data is fairly easy: set <code>Cache-Control</code> and <code>Expires</code> headers in the HTTP response.</p>

<pre><code class="ruby">expire_in = 60 * 60 * 24 * 365
header "Cache-Control", "private, max-age=#{expire_in}"
header "Expires", CGI.rfc1123_date(Time.now.utc + expire_in)
</code></pre>

<p>This example indicates to a cache in front of your service (CDN, proxy or user's browser) that the data expires in a year and that it's private for this user. When caching truly static data, such as images, use <code>public</code>. Your CDN or proxy, such as <a href="https://www.varnish-cache.org/">Varnish</a> that sits in front of Artsy on <a href="http://www.heroku.com/">Heroku</a>, will cache the data and subsequent requests won't even need to hit your server, even though it could potentially serve different content every time.</p>

<h3>Disabling Caching of Dynamic Data</h3>

<p>Caching dynamic data is slightly more involved. Let's begin with a simple Ruby API that returns a counter.</p>

<pre><code class="ruby">class API &lt; Grape::API
  def count
    { count : 0 }
  end
end
</code></pre>

<p>This kind of dynamic data cannot have a well-defined expiration time. The counter may be incremented at any time via another API call or process, so we must tell the client not to cache it. This is accomplished by setting the value of <code>Cache-Control</code> to <code>private, max-age=0, must-revalidate</code>. The <code>private</code> option instructs the client that it's allowed to store data in a private cache (unnecessary, but is known to work around overzealous cache implementations), <code>max-age</code> that it must check with the server every time it needs this data and <code>must-revalidate</code> prevents gateways from returning a response if your API server is unreachable. An additional <code>Expires</code> header set to a past date (usually January 1st 1990), will make double-sure the entire request expires immediately with old browsers.</p>

<p>Garner provides <a href="https://github.com/dblock/garner/blob/master/lib/garner/middleware/cache/bust.rb">Garner::Middleware::Cache::Bust</a> a Rack middleware that accomplishes just that.</p>

<h3>If-Modified-Since, ETags and If-None-Match</h3>

<p>Given our API example, a client may want to retrieve the value of the counter and, for example, run a job every time the value changes. As it stands, the current API requires an effort on the client's part to remember the previous value and compare it every time it makes an API call. This can be avoided by asking the server for a new counter if the value has changed since last time it was retrieved.</p>

<p>One option for the client is to include an <code>If-Modified-Since</code> header with a timestamp. The server could then choose to respond with <code>304 Not Modified</code> if the counter hasn't changed since the timestamp in <code>If-Modified-Since</code>. While this may be acceptable for certain data, timestamps have a granularity of seconds. A counter may be modified multiple times during the same second, therefore preventing it from retrieving the result of the second modification.</p>

<p>A more robust solution is to generate a unique signature, called ETag, for this data and to use it to find out whether the counter has changed. There exists a generic <a href="https://github.com/rack/rack/blob/master/lib/rack/etag.rb">Rack::ETag</a> middleware that sets ETags on all text bodies. Adding the middleware would produce an ETag for every response from the API. You can now combine <code>Rack::ETag</code> and <code>Rack::Cache</code> - a client makes a request with an <code>If-None-Match: Etag</code> header and the server returns a <code>304 Not Modified</code> if the data hasn't changed, without sending the data.</p>

<h3>Memcached via Dalli and Rails.Cache</h3>

<p>There's an obvious problem with <code>Rack::Cache</code>. In order for it to serve a <code>304 Not Modified</code> response it must compare the ETag from the request with the ETag generated from the body of the current response. So it saves bandwidth, but doesn't save execution time on the server. We'd also like the server to cache the entire response and therefore avoid any heavy processing, such as querying a database.</p>

<p>A typical Ruby cache supports a block syntax. The following example returns a cached copy when available or executes the supplied block and stores the result in the cache. In this context <code>cache</code> could be <code>Rails.cache</code> or an instance of <code>ActiveSupport::Cache::FileStore</code>. We use <code>Rails.cache</code> with <a href="http://memcached.org/">Memcached</a> via the <a href="https://github.com/mperham/dalli">dalli gem</a> in production.</p>

<pre><code class="ruby">cache("count") do
  { count : 0 }
end
</code></pre>

<p>The parameter of the <code>cache</code> call is the cache key that uniquely identifies the cache entry. Hard-coding cache keys is tedious, so we can generate a key from the API version, route and request parameters.</p>

<pre><code class="ruby">def cache_key
  options = { }
  options[:version] = version
  options[:path] = request.path
  options[:params] = request.GET
  Digest::MD5.hexdigest(options.to_json)
end
</code></pre>

<p>This generic approach to key generation is fine to get one started, but is largely insufficient for real-world applications.</p>

<h3>Production-Grade Cache Keys and Model Binding</h3>

<p>Most large scale web properties operate on data with the following requirements.</p>

<ul>
<li>Partition cache in sync with object ownership and permissions. For example, a <code>Widget</code> may have different representations depending on whether <code>current_user</code> owns it or not or may choose to return a <code>401 Access Denied</code> in some of the cases.</li>
<li>Retrieve objects from cache no matter where the calling code appears. The above strategy would generate identical keys from two different locations within the same function.</li>
<li>Invalidate entire cached collections when one of the objects in a collection has changed. For example, invalidate all cached instances of <code>Widget</code> when a new <code>WidgetCategory</code> is created and forces a reorganization of those widgets.</li>
</ul>


<p>Garner will help you introduce such aspects of your domain model into the cache and solve all these.</p>

<p>A cache is a collection of flat name/value pairs. We'll specify object relationships within each key by chaining model names, field values and by using wildcards where appropriate. For example, <code>User/id=12,Widget/id=45,Gadget/*</code> binds the cache value to changes in <code>User</code> with id=12, <code>Widget</code> with id=45 and any instance of <code>Gadget</code>.</p>

<pre><code class="ruby">cache(bind: [[User, { id: current_user.id }], [Widget, { id: params[:widget_id] }], [Gadget] ])
  Widget.where({ id: params[:widget_id], user_id: current_user.id }).first.as_json
end
</code></pre>

<p>Binding to multiple objects or classes can also be reasoned about as a way to partition the cache. Adding structure into the fields lets us reason about the relationships between various instances of data in the cache.</p>

<h3>Role-Based Caching</h3>

<p>Role-Based caching is a subset of the generic problem of binding data to groups of other objects. For example, a <code>Widget</code> may have a different representation for an <code>admin</code> vs. a <code>user</code>. In Garner you can inject something called a "key strategy" into the current key generation pipeline. A strategy is a plain module that must implement two methods: <code>field</code> and <code>apply</code>. The former should define a unique key name and the latter applies the strategy within a context.</p>

<p>The following example introduces the role of the current user into the cache key.</p>

<pre><code class="ruby">module MyApp
  module Garner
    module RoleStrategy
      class &lt;&lt; self
        def field
          :role
        end
        def apply(key, context = {})
          key.merge { :role =&gt; current_user.role }
        end
      end
    end
  end
end
</code></pre>

<p>Garner key strategies can be currently set at application startup time.</p>

<pre><code class="ruby">Garner::Cache::ObjectIdentity::KEY_STRATEGIES = [
  Garner::Strategies::Keys::Caller, # support multiple calls from the same function
  MyApp::Garner::RoleStrategy, # custom strategy for role-based access
  Garner::Strategies::Keys::RequestPath # injects the HTTP request's URL
]
</code></pre>

<h3>Multiple Calls from the Same Function</h3>

<p>Binding to the same set of objects within the same function call will produce the same key. To solve this in a generic way we can examine the call stack, find the caller that's not within the helper module and inject it in the key options.</p>

<pre><code class="ruby">api_caller = caller.detect { |line| !(line =~ /\/#{File.basename(__FILE__)}/) }
api_caller_line = api_caller.match(/(.*\.rb:[0-9]*):/) if api_caller
options[:caller] = api_caller_line[1] if api_caller_line
</code></pre>

<p>Garner implements this as <a href="https://github.com/dblock/garner/blob/master/lib/garner/strategies/keys/caller_strategy.rb">Garner::Strategies::Keys::Caller</a>.</p>

<h3>Cache Invalidation</h3>

<p>Invalidating a cache entry bound to multiple objects requires keeping an additional index along with the actual cache data. In the example above we've bound the resulting Widget to a specific <code>User</code>, the <code>Widget</code> instance itself and all instances of <code>Gadget</code>. Every time a Gadget changes, we'll want to invalidate this cache entry. Garner will handle this either automatically via a mixin (we've provided <a href="https://github.com/dblock/garner/blob/master/lib/garner/mixins/mongoid_document.rb">Garner::Mixins::Mongoid::Document</a> for the Mongoid ODM) or via an explicit <code>invalidate(Gadget)</code> call.</p>

<p>Since we're not able to scan the entire cache during invalidation, we keep a key index in the cache as well. The key for each index entry is derived from the individual elements in the binding.</p>

<h3>Using with Grape</h3>

<p>Garner currently ships with <a href="https://github.com/dblock/garner/blob/master/lib/garner/mixins/grape_cache.rb">Garner::Mixins::Grape::Cache</a>. There're two ways to use it: <code>cache</code> and <code>cache_or_304</code>.</p>

<p>The <code>cache</code> implementation will generate a key from the binding by applying all registered cache key strategies within the current context, look up the entry by that key and either cache hit or miss. In summary, it's an extension to a standard cache, introducing a much more fully featured binding system.</p>

<pre><code class="ruby"># caches, but always returns the widget
get "widget/:id" do
  cache(bind: [Widget, params[:id]]) do
    Widget.find(params[:id])
  end
end
</code></pre>

<p>The <code>cache_or_304({ bind: [ ] })</code> will generate a meta key from the binding by applying all registered cache key strategies within the current context and search the cache index by the meta key. If a value is found, it will be compared to the ETag or the timestamp supplied in the request's <code>If-None-Match</code> or <code>If-Modified-Since</code> and issue a <code>304 Not Modified</code> where appropriate.</p>

<pre><code class="ruby"># caches, returns the widget and supports If-Modified-Since or If-None-Match
get "widget/:id" do
  cache_or_304(bind: [Widget, params[:id]]) do
    Widget.find(params[:id])
  end
end
</code></pre>

<h3>Conclusion</h3>

<p>An effective cache implementation for a web service combines server-side caching with client-side expiration. The latter broadly includes proxies, CDNs and browsers, all active actors in the process of exchanging information. The web is, in a way, an eventually consistent data storage and distribution system.</p>

<h3>Links</h3>

<ul>
<li><a href="https://github.com/artsy/garner">Garner</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Simplifying Model-Level JSON Versioning with Mongoid-Cached-Json]]></title>
    <link href="http://artsy.github.io/blog/2012/03/23/simplifying-model-level-json-versioning-with-mongoid-cached-json/"/>
    <updated>2012-03-23T09:14:00+00:00</updated>
    <id>http://artsy.github.io/blog/2012/03/23/simplifying-model-level-json-versioning-with-mongoid-cached-json</id>
    <content type="html"><![CDATA[<p>Did you know that Netflix has hundreds of API versions, one for each device? Daniel Jacobson's <a href="http://www.slideshare.net/danieljacobson/techniques-for-scaling-the-netflix-api-qcon-sf">Techniques for Scaling the Netflix API</a> at QConSF 2011 explained why they chose this model. And while we don't all build distributed services that supply custom-tailored data to thousands of heterogeneous TVs and set-top boxes, we do have to pay close attention to API versioning from day one.</p>

<p>Versioning is hard. Your data models evolve, but you must maintain backward-compatibility for your public interfaces. While many strategies exist to deal with this problem, we'd like to propose one that requires very little programming effort and that is more declarative in nature.</p>

<p>At Artsy we use <a href="http://github.com/intridea/grape">Grape</a> and implement the "path" versioning strategy from the <a href="http://github.com/intridea/grape/tree/frontier">frontier</a> branch. Our initial v1 API is consumed by our own website and services and lives at <a href="https://artsyapi.com/api/v1">https://artsyapi.com/api/v1</a>. We've also prototyped v2 and by the time v1 is frozen, it should already be in production.</p>

<p>Grape takes care of version-based routing and has a system that lets you split version-based presentation of a model from the model implementation. I find that separation forcefully induced by unnecessary implementation complexity around wanting to return different JSON depending on the API version requested. What if implementing versioning in <code>as_json</code> were super simple?</p>

<p>Consider a Person model returned from a v1 API.</p>

<pre><code class="ruby">class API &lt; Grape::API
  prefix :api
  version :v1
  namespace :person
    get ":id"
      Person.find(params[:id]).as_json
    end
  end
end
</code></pre>

<pre><code class="ruby">class Person
  include Mongoid::Document

  field :name

  def as_json
    {
      name: name
    }
  end

end
</code></pre>

<p>In v2 the model split <code>:name</code> into a <code>:first</code> and <code>:last</code> name and in v3 <code>:name</code> has finally been deprecated. A version v3 Person model would look as follows.</p>

<pre><code class="ruby">class Person
  include Mongoid::Document

  field :first
  field :last

  def as_json
    {
      first: first,
      last: last
    }
  end

end
</code></pre>

<p>How can we combine these two implementations and write <code>Person.find(params[:id]).as_json({ :version =&gt; ? })</code>?</p>

<p>In <a href="http://github.com/dblock/mongoid-cached-json">mongoid-cached-json</a> we've introduced a declarative way of versioning JSON. Here's the code for Person v3.</p>

<pre><code class="ruby">class Person
  include Mongoid::Document
  include Mongoid::CachedJson

  field :first
  field :last

  def name
    [ first, last ].join(" ")
  end

  json_fields \
    name: { :versions =&gt; [ :v1, :v2 ] },
    first: { :versions =&gt; [ :v2, :v3 ] },
    last: { :versions =&gt; [ :v2, :v3 ] }

end
</code></pre>

<p>With the <a href="http://github.com/dblock/mongoid-cached-json">mongoid-cached-json</a> gem you also get caching that respects JSON versioning, for free. Read about it <a href="http://artsy.github.com/blog/2012/02/20/caching-model-json-with-mongoid-cached-json/">here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[10x Rack and Rails Output Compression with Rack::Deflater]]></title>
    <link href="http://artsy.github.io/blog/2012/02/24/10x-rack-and-rails-output-compression-with-rack-deflater/"/>
    <updated>2012-02-24T16:05:00+00:00</updated>
    <id>http://artsy.github.io/blog/2012/02/24/10x-rack-and-rails-output-compression-with-rack-deflater</id>
    <content type="html"><![CDATA[<p>You can quickly reduce the amount of data transferred from your Rack or Rails application with <a href="https://github.com/rack/rack/blob/master/lib/rack/deflater.rb">Rack::Deflater</a>. Anecdotal evidence shows a reduction from a 50Kb JSON response into about 6Kb. It may be a huge deal for your mobile clients.</p>

<p>For a Rails application, modify config/application.rb or config/environment.rb.</p>

<pre><code class="ruby config/application.rb">Acme::Application.configure do
  config.middleware.use Rack::Deflater
end
</code></pre>

<p>For a Rack application, add the middleware in config.ru.</p>

<pre><code class="ruby config.ru">use Rack::Deflater
run Acme::Instance
</code></pre>

<!-- more -->


<p>Note that the order of the middleware is very important. For example, we also use Rack::JSONP that adds automatic JSONP support to our API. It must be invoked before Rack::Deflater or it will attempt to wrap compressed content. Rack middleware is executed in reverse order [<a href="http://verboselogging.com/2010/01/20/proper-rack-middleware-ordering">source</a>].</p>

<pre><code class="ruby config/application.rb">  config.middleware.use Rack::Deflater
  config.middleware.use Rack::JSONP
</code></pre>

<p>A couple of handy RSpec tests to add to your application. You will need to modify this code with a valid API path and expected response.</p>

<pre><code class="ruby spec/api/rack_deflater_spec.rb">require 'spec_helper'

describe Rack::Deflater do
  it "produces an identical eTag whether content is deflated or not" do
    get "/api/acme"
    response.headers["Content-Encoding"].should be_nil
    etag = response.headers["Etag"]
    content_length = response.headers["Content-Length"].to_i
    get "/api/acme", {}, { "HTTP_ACCEPT_ENCODING" =&gt; "gzip" }
    response.headers["Etag"].should == etag
    response.headers["Content-Length"].to_i.should_not == content_length
    response.headers["Content-Encoding"].should == "gzip"
  end
  it "deflates JSONP content" do
    get "/api/acme?callback=parseResponse", {}, { "HTTP_ACCEPT_ENCODING" =&gt; "deflate" }
    response.headers["Content-Encoding"].should == "deflate"
    inflated_response_body = Zlib::Inflate.new(-Zlib::MAX_WBITS).inflate(response.body.to_s)
    inflated_response_body.should == "parseResponse(...)"
  end
end
</code></pre>
]]></content>
  </entry>
  
</feed>
