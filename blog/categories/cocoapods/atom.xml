<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: cocoapods | Artsy Engineering]]></title>
  <link href="http://artsy.github.io/blog/categories/cocoapods/atom.xml" rel="self"/>
  <link href="http://artsy.github.io/"/>
  <updated>2018-12-16T10:16:31+00:00</updated>
  <id>http://artsy.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Why does my team's Podfile.lock Podspec checksums change?]]></title>
    <link href="http://artsy.github.io/blog/2016/05/03/podspec-checksums/"/>
    <updated>2016-05-03T12:09:00+00:00</updated>
    <id>http://artsy.github.io/blog/2016/05/03/podspec-checksums</id>
    <content type="html"><![CDATA[<p>We use CocoaPods, and <a href="https://github.com/artsy/eigen/issues/418">we don't check in our Pods</a> directory for one of our fastest moving apps, <a href="https://github.com/artsy/eigen/">Eigen</a>. This sometimes can cause an <a href="https://github.com/artsy/eigen/pull/1464">interesting data churn</a> inside the <code>Podfile.lock</code> when developers have different sha checksums for their Pods. This is weird, what gives?</p>

<!-- more -->


<a name="What.are.the.Lockfiles."></a>
<h3>What are the Lockfiles?</h3>

<p>First off, to ensure we're talking about the same thing, this is our <a href="https://github.com/artsy/eigen/blob/master/Podfile.lock">Podfile.lock</a>. The lockfile is used on <code>pod install</code> to ensure all the members of your team have the <em>exact same</em> version of the libraries as each other. Otherwise, with a Podfile like:</p>

<pre><code class="ruby">platform :ios, '9.3'
pod 'AFNetworking/Serialization', '~&gt; 3.0'
target 'MyApp'
</code></pre>

<p>A developer running <code>pod install</code> would get the latest <code>3.x</code> version, which could be <code>3.1</code> originally, but then 6 months later they could get <code>3.4</code> - without a lockfile there is no way to keep track of the specific build. This is why it should always be in your code repo. In the case above my lockfile looks like this:</p>

<pre><code class="yaml">PODS:
  - AFNetworking/Serialization (3.1.0)

DEPENDENCIES:
  - AFNetworking/Serialization (~&gt; 3.0)

SPEC CHECKSUMS:
  AFNetworking: 5e0e199f73d8626b11e79750991f5d173d1f8b67

PODFILE CHECKSUM: 876ceaa409f4ade2b3d58d310dbe026393824bcc

COCOAPODS: 1.0.0.beta.8
</code></pre>

<a name="What.do.the.Spec.Checksums.do."></a>
<h3>What do the Spec Checksums do?</h3>

<p>With the CocoaPods Master Specs repo, we do our best <a href="https://github.com/CocoaPods/Specs/pull/12199">to try</a> and ensure a write-once repository of Podspecs for the public. However, there are many times when you cannot guarantee that every you have the same version of a Podspec as everyone else in your team.</p>

<p>So, CocoaPods makes a checksum of the JSON representation of your Podspec and keeps that in the lockfile. You can easily <a href="https://github.com/CocoaPods/CocoaPods/issues/3371">replicate</a> the work to generate a checksum with:</p>

<pre><code class="sh">~/D/MyApp ‚èõ  pod ipc spec ~/.cocoapods/repos/master/Specs/AFNetworking/3.1.0/AFNetworking.podspec.json  | openssl sha1
5e0e199f73d8626b11e79750991f5d173d1f8b67
</code></pre>

<a name="So.why.am.I.seeing.churn."></a>
<h3>So why am I seeing churn?</h3>

<p>A normal git development flow when working with libraries is to:</p>

<ul>
<li>Fork a library, change your Podfile to reflect that change</li>
<li>Make some changes</li>
<li>Commit them back to the main repo</li>
<li>Update the Podspec, then make changes bringing your Podfile back to a real (tagged) release</li>
</ul>


<p>CocoaPods is smart about updating your libraries behind the scenes, but it's not perfect. In order to avoid re-creating your entire Pods folder every time it will check whether your libraries are at the expected version and skip re-creating the whole process.</p>

<p>In the example above, we used the CocoaPods' Specs repo version of the Podspec. In forked repos, e,g,</p>

<pre><code class="ruby">pod 'AFNetworking/Serialization', :git =&gt; "https://github.com/orta/AFNetworking.git", :commit =&gt; "6f31b5c7bcbd59d4dac7e92e215d3c2c22f3400e"
</code></pre>

<p>The Podspec is saved into the <code>Pods</code> directory in JSON format at <code>Pods/Local\ Podspecs/AFNetworking.podspec.json</code>, this is to ensure there's always access within the CocoaPods sandbox for the Podspecs, and speed probably. This is the podspec used for generating the checksum.</p>

<p><strong>So how can this get out of sync?</strong></p>

<ul>
<li>During the development cycle, when working with a library you would have used <code>pod update [library]</code> to update just that library you were working on.  This could happen multiple times as you build your changes.</li>
<li>You continued working against your fork till it was ready for review. At this point you have a working version, you submit a PR for code review on the library.</li>
<li>There are changes that affect the podspec that come up in review, you don't do a <code>pod update [library]</code> but send the code back to review ( maybe you changed some metadata for example, which doesn't warrant another update to pass CI. )</li>
<li>Once all code is reviewed, everything is merged back into master.</li>
<li>You <code>pod install</code> - which continues to use the older version of the Podspec inside the Pods dir, e.g. <code>Pods/Local\ Podspecs/AFNetworking.podspec.json</code>.</li>
<li>You now have the older <code>AFNetworking.podspec.json</code> inside your local Pods folder, when the next person runs <code>pod install</code> with your changes merged, they get a different SHA, as they've got the version with the metadata changes.</li>
</ul>


<a name="Simple.Fix"></a>
<h3>Simple Fix</h3>

<p>The best option is to run <code>pod update [library]</code> on the computer which is causing churn, this will tell CocoaPods specifically to request a new version of the library. If that fails to give the same checksum as the rest of your team, there's the good old fasioned <code>rm -rf Pods &amp;&amp;  pod install</code>.</p>
]]></content>
  </entry>
  
</feed>
