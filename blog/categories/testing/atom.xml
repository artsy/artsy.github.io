<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: testing | Artsy Engineering]]></title>
  <link href="http://artsy.github.io/blog/categories/testing/atom.xml" rel="self"/>
  <link href="http://artsy.github.io/"/>
  <updated>2018-11-26T19:28:22+00:00</updated>
  <id>http://artsy.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How To Debug Jest Tests]]></title>
    <link href="http://artsy.github.io/blog/2018/08/24/How-to-debug-jest-tests/"/>
    <updated>2018-08-24T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/08/24/How-to-debug-jest-tests</id>
    <content type="html"><![CDATA[<p>Hey there! My name is Anson and I work on the Platform team at Artsy. Recently, we faced an issue where a certain <a href="https://github.com/airbnb/enzyme">Enzyme</a> test we wrote using mock tracking was failing, but we couldn't figure out why. Luckily, with some help from <a href="/author/orta">Orta</a> and some clever thinking, we figured out what was going on.</p>

<!-- more -->


<p>We thought it was an issue with the mock testing library we had written. We tried to fix the problem by sprinkling <code>console.log</code> calls throughout the test, but it was still hard to figure out what was going on, especially without knowing how to peek into the properties of certain objects.</p>

<p>Instead, <a href="/author/orta">Orta</a> suggested we used the Chrome Node DevTools. Since the Enzyme test is run via <code>yarn jest</code>, yarn is acting as a frontend for running the Enzyme test with Node. This means that we can use the Chrome Node DevTools as a debugger to run the Enzyme test. This was super useful since the one thing we needed was to be able to peek inside certain objects to see what they looked like and how they were failing. It was a much faster, more methodical way to approach debugging this test. Here are the steps we took:</p>

<ul>
<li>First, insert a new line in your test where you think it might be failing and type <code>debugger</code>. This will serve as a break point for the debugger to stop at.</li>
<li>Open up Chrome and type in the address bar : <code>chrome://inspect</code></li>
<li>Click on "Open dedicated DevTools for Node"</li>
<li>In your terminal, instead of typing <code>yarn jest &lt;path_to_test&gt;</code>, type this:</li>
</ul>


<pre><code class="bash">node --inspect node_modules/.bin/jest --runInBand &lt;path_to_test&gt;
</code></pre>

<p>Or you can add it to your <code>package.json</code> as a script:</p>

<pre><code class="diff">  {
    "scripts" : {
+    "test:debug": "node --inspect node_modules/.bin/jest --runInBand",
    }
  }
</code></pre>

<p>Which you can then run as <code>yarn test:debug &lt;path_to_test&gt;</code>.</p>

<p>Voila! Your test should now be running in the Chrome debugger. And you get your handy console to poke around all sorts of stuff!</p>

<p>You also have the option of using this with Jest's <code>--watch</code> mode in order easily re-run tests, after changes to app or test code.</p>

<pre><code class="bash">node --inspect node_modules/.bin/jest --watch --runInBand &lt;path_to_test&gt;
</code></pre>

<p>Now simply hit Enter in the terminal running your Jest process anytime you want to re-run your currently selected specs. You'll be dropped right back into the Chrome debugger.</p>

<p>You might be wondering how this fixed our tests. Well, turns out that we missed a <code>jest.unmock()</code> call at the top of the test file. <em>Facepalm.</em> To prevent this from biting other developers in the future, <a href="/author/orta">Orta</a> whipped up a <a href="https://github.com/artsy/reaction/pull/1174">pull request</a> to add a rule in our TypeScript linter, check it out!</p>

<p>Either way, in the future, this will probably be my first step in debugging non-obvious issues in tests, if only to eliminate possible sources of the issues. I'm glad I was able to learn with <a href="/author/orta">Orta</a> about a methodical way to debug test failures. Hope this helps, and happy hacking!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Splitting up a large test suite]]></title>
    <link href="http://artsy.github.io/blog/2015/09/24/splitting-up-a-large-test-suite/"/>
    <updated>2015-09-24T22:13:00+00:00</updated>
    <id>http://artsy.github.io/blog/2015/09/24/splitting-up-a-large-test-suite</id>
    <content type="html"><![CDATA[<p>A while back, we wrote about <a href="/blog/2012/10/09/how-to-run-rspec-test-suites-in-parallel-with-jenkins-ci-build-flow/">How to Run RSpec Test Suites in Parallel with Jenkins CI Build Flow</a>. A version of that still handles our largest test suite, but over time the initial division of specs became unbalanced. We ended up with some tasks that took twice as long as others. Even worse, in an attempt to rebalance task times, we ended up with awkward file patterns like <code>'spec/api/**/[a-m]*_spec.rb'</code>.</p>

<p>To keep our parallel spec tasks approximately equal in size and to support arbitrary concurrency, we've added a new <code>spec:sliced</code> task:</p>

<!-- more -->


<pre><code class="ruby">namespace :spec do
  task :set_up_spec_files do
    spec_files = Dir['spec/**/*_spec.rb']
    @spec_file_digests = Hash[spec_files.map { |f| [f, Zlib.crc32(f)] }]
  end

  RSpec::Core::RakeTask.new(:sliced, [:index, :concurrency] =&gt; :set_up_spec_files) do |t, args|
    index = args[:index].to_i
    concurrency = args[:concurrency].to_i
    t.pattern = @spec_file_digests.select { |f, d| d % concurrency == index }.keys
  end
end
</code></pre>

<p>As you can see, the <code>set_up_spec_files</code> helper task builds a hash of spec file paths and corresponding checksums. When we invoke the <code>sliced</code> task with <code>index</code> and <code>concurrency</code> values (e.g., <code>0</code> and <code>5</code>), only the spec files with checksums equal to <code>0</code> when mod-ed by <code>5</code> are run. Thus, the Jenkins build flow would look like:</p>

<pre><code class="java">parallel (
  {build("master-ci-task", tasks: "spec:sliced[0,5]")},
  {build("master-ci-task", tasks: "spec:sliced[1,5]")},
  {build("master-ci-task", tasks: "spec:sliced[2,5]")},
  {build("master-ci-task", tasks: "spec:sliced[3,5]")},
  {build("master-ci-task", tasks: "spec:sliced[4,5]")}
)
build("master-ci-succeeded")
</code></pre>

<p>Now, spec times <em>might</em> continue to be unbalanced despite files being split up approximately evenly. (For a more thorough approach based on recording spec times, see <a href="https://github.com/ArturT/knapsack">knapsack</a>.) However, this little bit of randomness was a big improvement over our previous approach, and promises to scale in a uniform manner.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Releasecop Tracks Stale Releases]]></title>
    <link href="http://artsy.github.io/blog/2015/09/01/releasecop-tracks-stale-releases/"/>
    <updated>2015-09-01T17:30:00+00:00</updated>
    <id>http://artsy.github.io/blog/2015/09/01/releasecop-tracks-stale-releases</id>
    <content type="html"><![CDATA[<p>Artsy practices a sort of <a href="http://en.wikipedia.org/wiki/Continuous_delivery">continuous delivery</a>. We keep release cycles short and the process of reviewing, testing, and deploying our software as reliable, fast, and automated as possible. (This blog has touched on these practices <a href="http://artsy.github.io/blog/categories/testing/">multiple</a> <a href="http://artsy.github.io/blog/categories/continuous-integration">times</a>.)</p>

<p>Usually, commits that have been reviewed and merged are immediately built and tested. Successfully built versions of the codebase are often automatically deployed to a staging environment. On an automated or frequent-but-manual basis, that version is deployed to a production environment. Thus, commits form a pipeline:</p>

<ul>
<li>From developers' working branches</li>
<li>To the master branch</li>
<li>Through a hopefully-successful build</li>
<li>To a staging environment</li>
<li>To production</li>
</ul>


<p>The number of apps and services we deploy has grown to <em>dozens</em> per team, so sometimes things fall through the cracks. We've been using <a href="https://github.com/joeyAghion/releasecop">Releasecop</a> for the last few months to get gentle email reminders when an environment could use a deploy.</p>

<!-- more -->


<pre><code>gem install releasecop
releasecop edit
</code></pre>

<p>This opens a <em>manifest</em> file where you can describe the sequence of git remotes and branches that make up your own release pipeline. For example:</p>

<pre><code>{
  "projects": {
    "charge": [
      { "name": "master", "git": "git@github.com:artsy/charge.git" },
      { "name": "staging", "git": "git@heroku.com:charge-staging.git" },
      { "name": "production", "git": "git@heroku.com:charge-production.git" }
    ],
    "gravity": [
      { "name": "master", "git": "git@github.com:artsy/gravity.git" },
      { "name": "master-succeeded", "git": "git@github.com:artsy/gravity.git", "branch": "master-succeeded" },
      { "name": "staging", "git": "git@github.com:artsy/gravity.git", "branch": "staging" },
      { "name": "production", "git": "git@github.com:artsy/gravity.git", "branch": "production" }
    ]
  }
}
</code></pre>

<p>The <code>charge</code> app is a typical deployment to Heroku. Work progresses from the <code>master</code> branch to a <code>charge-staging</code> app to a <code>charge-production</code> app. The <code>gravity</code> app is a more complicated, non-Heroku deployment. It updates git branches to reflect what has been merged (<code>master</code>), tested (<code>master-succeeded</code>), deployed to staging, and deployed to production.</p>

<p>Run the <code>releasecop check [app]</code> command to report the status of your apps' releases:</p>

<pre><code>$ releasecop check --all
charge...
  staging is up-to-date with master
  production is up-to-date with staging
gravity...
  master-succeeded is up-to-date with master
  staging is up-to-date with master-succeeded
  production is behind staging by:
    06ca969 2015-09-04 [config] Replace Apple Push Notification certificates that expire today. (Eloy Durán)
    171121f 2015-09-03 Admin-only API for cancelling a bid (Matthew Zikherman)
    4c5feea 2015-09-02 install mongodb client in Docker so that import rake tasks can run (Barry Hoggard)
    95347d1 2015-08-31 Update to delayed_job cookbook that works with Chef 11.10 (Joey Aghion)
2 project(s) checked. 1 environment(s) out-of-date.
</code></pre>

<p>A nightly <a href="https://jenkins-ci.org/">Jenkins</a> job emails us the results, but a cron job could work equally well.</p>

<p><a href="https://github.com/joeyAghion/releasecop">Releasecop</a> reminds us to deploy ready commits and close the loop on in-progress work. We hope you find it useful. (Pull requests are welcome!)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How To Write Unit Tests Like a Brood Parasite]]></title>
    <link href="http://artsy.github.io/blog/2015/07/06/how-to-write-unit-tests-like-a-brood-parasite/"/>
    <updated>2015-07-06T13:54:00+00:00</updated>
    <id>http://artsy.github.io/blog/2015/07/06/how-to-write-unit-tests-like-a-brood-parasite</id>
    <content type="html"><![CDATA[<p>To a beginner, <a href="http://ocmock.org/">OCMock</a> looks scary. The syntax is strange, the idea of stubbing seems complicated, and skirting around the need to use it at all times kind of works out for a while.</p>

<pre><code class="objc">[[[mock stub] // three brackets!!

[OCMockObject niceMockForClass:UINavigationItem.class]; // it has to be told to be nice?
</code></pre>

<p>All of this can be overwhelming for someone who just wants to write simple unit tests for a particular view controller.</p>

<p>Once you look into the specifics of OCMock, however, things get less terrifying really quickly. It is helpful to compare OCMock’s approach to stubbing to the <a href="https://vimeo.com/60553870">behaviors of certain bird species</a>. As always, the soothing voice of David Attenborough brings clarity and joy to even the most mundane puzzles of life’s journey.</p>

<!-- more -->


<hr />

<p>For those who hate birds and videos of them, the cuckoo duck is known for leaving its eggs in the nests of other birds precisely as their unsuspecting victims lay their own. The new host parents cannot differentiate their offspring from those of the duck and inadvertently raise the duck chicks to maturity.</p>

<p>In a similar fashion, OCMock can place trick objects in your <del>nest</del> test code with whichever custom configuration suits your needs. The ‘host’ subject under test can’t differentiate these mock objects from the objects they’ve been written to use, and you can decide exactly how you’d like the mock objects to behave in your testing environment. This was especially helpful for a method I created that relies on information from an asynchronous network request. We’ll call it the <code>DataSource</code> of a <code>StatusMonitor</code> class.</p>

<pre><code class="objc">- (BOOL)updatedStatus
{
    [DataSource getNewDataWithNetworkRequest];
    /// some code that relies on this new data
}
</code></pre>

<p>In my view controller, I can use a <code>StatusMonitor</code> to decide whether or not a notification should appear in my view:</p>

<pre><code class="objc">- (void)viewWillAppear
{
    [super viewWillAppear];

/// show or hide a notification based on this status
    BOOL shouldShowNotification = [self.statusMonitor updatedStatus];
}
</code></pre>

<p>When I’m writing tests for this view controller, I don’t care about <code>DataSource</code> - I just want to make sure the view controller knows when to show or hide a notification correctly depending on the new value from its StatusMonitor. I’d really like to avoid making any network requests within these kinds of tests. This is where the bird strategy comes in.</p>

<p>In my tests, I can create a decoy <code>StatusMonitor</code> with its corresponding methods using OCMock.</p>

<pre><code class="objc">StatusMonitor *statusMonitor = [[ARCMSStatusMonitor alloc] init];
id mockMonitor = [OCMockObject partialMockForObject:statusMonitor];

[[[mockMonitor stub] andReturn:@YES] checkStatus];
</code></pre>

<hr />

<p>I can then assign mockMonitor to the <code>statusMonitor</code> property of my view controller under test. In this way, the dependency on a network connection disappears, my view controller is happy, and my test can isolate the functionality I care about. OCMock provides some excellent documentation of what they mean by ‘nice’ and some other interesting things you can do with mock objects <a href="http://ocmock.org/features/">here</a>. For those interested in David Attenborough, birds, or natural history in general, I recommend  <a href="http://www.bbc.co.uk/nature/collections/p0048522">Nature</a>.</p>

<div style="text-align:center;">
<img src = "/images/2015-07-06-how-to-write-unit-tests-like-a-brood-parasite/attenborough.gif">
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using CocoaPods Caching with Travis CI]]></title>
    <link href="http://artsy.github.io/blog/2014/08/08/CocoaPods-Caching/"/>
    <updated>2014-08-08T11:46:00+00:00</updated>
    <id>http://artsy.github.io/blog/2014/08/08/CocoaPods-Caching</id>
    <content type="html"><![CDATA[<p>As <a href="http://artsy.github.io/blog/2014/08/07/taking-a-snapshot-with-second-curtain/">Ash said earlier</a> we like using Continuous Integration. Today I spent a large amount of time migrating us to use the new CocoaPods caching system in Travis CI. To make up for my lost time I'm passing on what I've learned and also showing how we do CI at Artsy with Objective-C apps. If you're interested in how we do it in Swift, you can just check <a href="https://github.com/artsy/eidolon">Eidolon</a>.</p>

<!-- more -->


<p>First and foremost, this only works if you are paying for Travis CI.</p>

<p>Travis CI recently merged in support for <a href="http://docs.travis-ci.com/user/caching/">Caching of CocoaPods</a> - this is great! By using this, we've reduced our build times from an average of about 10 minutes, to about 7 minutes. It works by using your <code>Podfile.lock</code> as a key to cache your <code>Pods</code> directory, if the lock hasn't changed then there's no need to update the Cache and so <code>pod install</code> is not called on your project. This caused me an issue as the <code>[Project].xcworkspace</code> file that CocoaPods generates was not in source control, and the app wouldn't build. Useful note, if you're using <a href="http://guides.cocoapods.org/syntax/podfile.html#pod">development pods</a> in your build you probably shouldn't use this as your Pods directory can get out of sync with the cached version.</p>

<p>We use a <a href="https://github.com/artsy/eidolon/blob/master/Makefile">Makefile</a> to separate the tasks required to build, test and deploy an app. The general structure of our Makefile is:</p>

<table>
<thead>
<tr>
<th> Action        </th>
<th> Reason </th>
</tr>
</thead>
<tbody>
<tr>
<td> Constants </td>
<td> A collection of constants that get resued by different make tasks. </td>
</tr>
<tr>
<td> CI Tasks </td>
<td> Separate commands necessary for running Xcode projects from the terminal. </td>
</tr>
<tr>
<td> Actions </td>
<td> Commands that manipulate your project state, or maintainance commands. </td>
</tr>
<tr>
<td> Deployment </td>
<td> Commands to get your app ready for the App Store, or Hockey. </td>
</tr>
</tbody>
</table>


<p>If you don't know the syntax for Make, essentially if it's on the same line you're either setting constants or calling other make commands. If it's on a separate line then you are running a shell command.</p>

<p>This is the <a href="http://orta.io/#folio-header-unit">Artsy Folio</a> Makefile in full:</p>

<pre><code class="make"># Constants

WORKSPACE = Artsy Folio.xcworkspace
XCPROJECT = Artsy\ Folio.xcodeproj
SCHEME = ArtsyFolio
CONFIGURATION = Beta
APP_PLIST = Info.plist
PLIST_BUDDY = /usr/libexec/PlistBuddy
TARGETED_DEVICE_FAMILY = \"1,2\"

BUNDLE_VERSION = $(shell $(PLIST_BUDDY) -c "Print CFBundleVersion" $(APP_PLIST))
GIT_COMMIT = $(shell git log -n1 --format='%h')
ALPHA_VERSION = $(BUNDLE_VERSION)-$(BUILD_NUMBER)-$(GIT_COMMIT)

GIT_COMMIT_REV = $(shell git log -n1 --format='%h')
GIT_COMMIT_SHA = $(shell git log -n1 --format='%H')
GIT_REMOTE_ORIGIN_URL = $(shell git config --get remote.origin.url)

DATE_MONTH = $(shell date "+%e %h")
DATE_VERSION = $(shell date "+%Y.%m.%d")

CHANGELOG = CHANGELOG.md
CHANGELOG_SHORT = CHANGELOG_SHORT.md

IPA = ArtsyFolio.ipa
DSYM = ArtsyFolio.app.dSYM.zip

# Phony tasks are tasks that could potentially have a file with the same name in the current folder
.PHONY: build clean test ci

# CI Tasks

ci: CONFIGURATION = Debug
ci: pods build

build:
    set -o pipefail &amp;&amp; xcodebuild -workspace "$(WORKSPACE)" -scheme "$(SCHEME)" -sdk iphonesimulator -destination 'name=iPad Retina' build | xcpretty -c

clean:
    xctool -workspace "$(WORKSPACE)" -scheme "$(SCHEME)" -configuration "$(CONFIGURATION)" clean

test:
    set -o pipefail &amp;&amp; xcodebuild -workspace "$(WORKSPACE)" -scheme "$(SCHEME)" -configuration Debug test -sdk iphonesimulator -destination 'name=iPad Retina' | second_curtain | xcpretty -c --test

lint:
    bundle exec fui --path Classes find

    bundle exec obcd --path Classes find HeaderStyle
    bundle exec obcd --path "ArtsyFolio Tests" find HeaderStyle

# Actions

ipa:
    $(PLIST_BUDDY) -c "Set CFBundleDisplayName $(BUNDLE_NAME)" $(APP_PLIST)
    $(PLIST_BUDDY) -c "Set CFBundleVersion $(DATE_VERSION)" $(APP_PLIST)
    ipa build --scheme $(SCHEME) --configuration $(CONFIGURATION) -t

alpha_version:
    $(PLIST_BUDDY) -c "Set CFBundleVersion $(ALPHA_VERSION)" $(APP_PLIST)

change_version_to_date:
    $(PLIST_BUDDY) -c "Set CFBundleVersion $(DATE_VERSION)" $(APP_PLIST)

set_git_properties:
    $(PLIST_BUDDY) -c "Set GITCommitRev $(GIT_COMMIT_REV)" $(APP_PLIST)
    $(PLIST_BUDDY) -c "Set GITCommitSha $(GIT_COMMIT_SHA)" $(APP_PLIST)
    $(PLIST_BUDDY) -c "Set GITRemoteOriginURL $(GIT_REMOTE_ORIGIN_URL)" $(APP_PLIST)

pods: remove_debug_pods
pods:
    rm -rf Pods
    bundle install
    bundle exec pod install

remove_debug_pods:
    perl -pi -w -e "s{pod 'Reveal-iOS-SDK'}{}g" Podfile

update_bundle_version:
    @printf 'What is the new human-readable release version? '; \
        read HUMAN_VERSION; \
        $(PLIST_BUDDY) -c "Set CFBundleShortVersionString $$HUMAN_VERSION" $(APP_PLIST)

mogenerate:
    @printf 'What is the new Core Data version? '; \
        read CORE_DATA_VERSION; \
        mogenerator -m "Resources/CoreData/ArtsyPartner.xcdatamodeld/ArtsyFolio v$$CORE_DATA_VERSION.xcdatamodel/" --base-class ARManagedObject --template-path config/mogenerator/artsy --machine-dir Classes/Models/Generated/ --human-dir /tmp/ --template-var arc=true

# Deployment

deploy: ipa distribute

alpha: BUNDLE_NAME = 'Folio α'
alpha: NOTIFY = 0
alpha: alpha_version deploy

appstore: BUNDLE_NAME = 'Artsy Folio'
appstore: TARGETED_DEVICE_FAMILY = 2
appstore: remove_debug_pods update_bundle_version set_git_properties change_version_to_date

next: TARGETED_DEVICE_FAMILY = \"1,2\"
next: update_bundle_version set_git_properties change_version_to_date

distribute:
  cat $(CHANGELOG) | head -n 50 | awk '{ print } END { print "..." }' &gt; $(CHANGELOG_SHORT)
  curl \
   -F status=2 \
   -F notify=$(NOTIFY) \
   -F "notes=&lt;$(CHANGELOG_SHORT)" \
   -F notes_type=1 \
   -F ipa=@$(IPA) \
   -F dsym=@$(DSYM) \
   -H 'X-HockeyAppToken: $(HOCKEYAPP_TOKEN)' \
   https://rink.hockeyapp.net/api/2/apps/upload \
   | grep -v "errors"
</code></pre>

<p>That gives you a sense of the commands that you can run from the terminal in our projects, next we need to look at the <code>.travis.yml</code> file.</p>

<pre><code class="make">language: objective-c
cache:
  - bundler
  - cocoapods

env:
  - UPLOAD_IOS_SNAPSHOT_BUCKET_NAME=eigen-ci UPLOAD_IOS_SNAPSHOT_BUCKET_PR...

before_install:
  - 'echo ''gem: --no-ri --no-rdoc'' &gt; ~/.gemrc'
  - cp .netrc ~
  - chmod 600 .netrc
  - pod repo add artsy https://github.com/artsy/Specs.git

before_script:
  - gem install second_curtain
  - make ci

script:
  - make test
  - make lint
</code></pre>

<p>This is nice and simple. It was built to use multiple travis build steps. This makes the CI output a lot more readable as an end user. Travis will by default collapse the shell output for different build stages leaving only the <code>script</code> stage defaulting to being exposed. Here is an example of what you see on a failing test:</p>

<center>
<img src="/images/2014-08-08-CocoaPods-Caching/failing_travis_screenshot.png" alt='Travis CI Failure'>
</center>


<p>We use a gem with a binary in <a href="https://github.com/AshFurrow/second_curtain/">second_curtain</a>, and this came with bundler caching issues in Travis. The solution was to ignore bundler and run <code>gem install second_curtain</code> each time. To increase the speed we also ensured that documentation is not being generated. If you are interested in what's going on with the <code>.netrc</code>, read my blog post on <a href="http://artsy.github.io/blog/2014/06/20/artsys-first-closed-source-pod/">Artsy's first Closed Source Pod</a>.</p>

<p>We will continue pushing the state of the art in iOS deployment, in building our own tools and using everything available to increase developer happiness. If you're into this we're always looking to hire people with a good open source track record or street smarts. Here's <a href="https://artsy.net/job/mobile-engineer">the jobs page</a>.</p>
]]></content>
  </entry>
  
</feed>
