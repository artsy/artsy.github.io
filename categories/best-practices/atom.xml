<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: best practices | Artsy Engineering]]></title>
  <link href="http://artsy.net/categories/best-practices/atom.xml" rel="self"/>
  <link href="http://artsy.net/"/>
  <updated>2015-08-24T12:49:03-04:00</updated>
  <id>http://artsy.net/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How to Write Great Outage Post-Mortems]]></title>
    <link href="http://artsy.net/blog/2014/11/19/how-to-write-great-outage-post-mortems/"/>
    <updated>2014-11-19T12:21:00-05:00</updated>
    <id>http://artsy.net/blog/2014/11/19/how-to-write-great-outage-post-mortems</id>
    <content type="html"><![CDATA[<p>The website is finally back up after crashing hard for 4 hours straight.</p>

<p>Recently AWS decided to <a href="http://aws.amazon.com/blogs/aws/ec2-maintenance-update">reboot a few of your servers for a critical update</a>. It didn't seem like it was going to be a big deal, except that the schedule was only accommodating if you were in the Pacific Northwest. The first reboot took out a secondary replica of our MongoDB database. Unfortunately <a href="https://github.com/mongoid/moped/issues/321">the driver handled that poorly</a> and spent the first 400ms of every subsequent HTTP request trying to reconnect to the missing instance. That server came back up, but failed to find its storage volumes because of a human mistake in a past migration and the alerts were mistakenly silenced by someone monitoring the system. A few hours later the primary was being stepped down and rebooted, sending the driver into panic over <a href="https://github.com/mongoid/moped/issues/323">another bug</a>. The site went down.</p>

<p>None of this was obvious while it was happening as the rate of automated alerts grew. Engineers communicated to the team that they are actively focusing on bringing the systems back up. This helped to fend off a large amount of instant messages, e-mails, texts and phone calls from various people on the team that were in the middle of demoing something to a very important prospective customer on the other side of the planet. It was also the middle of the night in New York.</p>

<p>Now that all the systems are back up, lets write a detailed outage post-mortem.</p>

<!-- more -->


<h2>Whose Job is It?</h2>

<p>In a small or medium-sized company, the most senior engineering manager, CTO, VP or Head of Engineering should be writing an outage post-mortem. It's their job and responsibility to acknowledge, understand and explain what happened. Focusing attention away from the individual contributors allows the team to learn from the mistakes and address the root causes in time without the unnecessary stress or pressure during a crisis.</p>

<h2>Recipients</h2>

<p>The post-mortem audience includes customers, direct reports, peers, the company's executive team and often investors. The e-mail may be published on your website, and otherwise goes to the entire team. It's critical to bcc everyone. This is the equivalent of a locked thread, avoiding washing the laundry in public: one of the worst possible things to see is when a senior manager replies back pointing an individual who made a mistake, definitely not an email you want accidentally sent to the entire company.</p>

<p>I usually begin my e-mails with <em>Team (on the bcc), ...</em>.</p>

<p>I also bcc myself and label the e-mail "Outages", to be able to easily find the incident history next time around.</p>

<p><img src="/images/2014-11-19-how-to-write-great-outage-post-mortems/header.png" alt="header" /></p>

<h2>Outage Email Subject</h2>

<p>Post-mortem subjects should include a date and a duration. This gets right to the point and offers a summary of the impact.</p>

<p><img src="/images/2014-11-19-how-to-write-great-outage-post-mortems/subject.png" alt="subject" /></p>

<h2>Outage Summary</h2>

<p>The outage e-mail begins with a summary, a slightly expanded version of the subject line. Many people won't read the details, so include graphs. These should tell the same story as the description of the outage. I use <a href="http://newrelic.com">NewRelic's</a>.</p>

<p><img src="/images/2014-11-19-how-to-write-great-outage-post-mortems/summary.png" alt="summary" /></p>

<h2>What Caused the Outage</h2>

<p>Explain what caused the outage on a timeline. Every incident begins with a specific trigger at a specific time, which often causes some unexpected behavior. For example, our servers were rebooted and we expected them to come back up intact, which didn't happen. Furthermore, every incident has a root cause: the reboot itself was trigger, however a bug in the driver caused the actual outage. Finally, there're consequences to every incident, the most obvious one is that the site goes down.</p>

<p><img src="/images/2014-11-19-how-to-write-great-outage-post-mortems/cause.png" alt="cause" /></p>

<h2>How was the Outage Resolved</h2>

<p>Now that the timeline of the outage is established, we explain what actions took place to resolve it.</p>

<p><img src="/images/2014-11-19-how-to-write-great-outage-post-mortems/resolution.png" alt="resolution" /></p>

<h2>The Post-Mortem</h2>

<p>The post-mortem answers the single most important question of what could have prevented the outage.</p>

<p><img src="/images/2014-11-19-how-to-write-great-outage-post-mortems/post-mortem.png" alt="post-mortem" /></p>

<h2>Outage History</h2>

<p>To most humans that encounter bugs, it may seem like your systems have failures all the time. It's important to educate everyone that an outage is much more than a bug and that it hopefully doesn't happen frequently. Provide a history of outages, referencing the last one.</p>

<p><img src="/images/2014-11-19-how-to-write-great-outage-post-mortems/history.png" alt="history" /></p>

<h2>Don't Bury It</h2>

<p>A few final words. Despite how painful an outage may have been, the worst thing you can do is to bury it and never properly close the incident in a clear and transparent way. Most humans come together in times of crisis and communication around outage post-mortems, in my experience, has always been met with positive energy, understanding comments, constructive suggestions and numerous offers to help.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Launching a Security Bug Bounty Program at Artsy]]></title>
    <link href="http://artsy.net/blog/2014/09/24/launching-a-security-bug-bounty-program-at-artsy/"/>
    <updated>2014-09-24T12:21:00-04:00</updated>
    <id>http://artsy.net/blog/2014/09/24/launching-a-security-bug-bounty-program-at-artsy</id>
    <content type="html"><![CDATA[<p>Many established companies have bug bounty programs, including a recently publicized <a href="http://www.forbes.com/sites/kashmirhill/2014/09/10/bug-bounty-programs">Twitter Bug Bounty</a>. Some use services, such as <a href="https://hackerone.com">HackerOne</a> or <a href="https://bugcrowd.com">BugCrowd</a>. In early September 2014 we quietly launched <a href="https://artsy.net/security">our own Security Bug Bounty</a>. Since then we have fixed 14 issues reported by 15 security researchers and paid $750 in bounty. In the process we have learned a ton and wanted to share some things that would have probably done a little bit differently, knowing what we know now.</p>

<p>In this post I will focus on both technical and non-technical takeaways, and will provide an extensive list of vulnerabilities that should have been dealt with before launching our bug bounty.</p>

<!-- more -->


<h2>Before You Begin</h2>

<p>Our security bug bounty program started with an engineer (myself) creating a <a href="https://artsy.net/security">document</a> on our website, largely inspired from other bug bounty programs. Our staff attorney wanted to review and edit it, something that definitely needed to be done.</p>

<p>A less evident step was to have a conversation with the finance department about whether or not bounty could be paid to individuals living in countries that may have U.S. sanctions imposed on them (see <a href="http://www.treasury.gov/resource-center/faqs/Sanctions/Pages/answer.aspx">What countries do I need to worry about in terms of U.S. sanctions?</a>). We also needed to talk about the terms under which reward payments could be made at all - we now require the individual's full name and postal address. Other bounty programs, including <a href="https://bounty.github.com/">Github's</a>, require a <a href="http://www.irs.gov/pub/irs-pdf/fw9.pdf">W9</a> for U.S. citizens or a <a href="http://www.irs.gov/pub/irs-pdf/fw8ben.pdf">W8_BEN</a> for non-U.S. citizens before any payment can be made (we may start doing this as well).</p>

<p>Another question raised was regarding budget and how much money I expected to pay. With about $50 a bug I estimated that this program would not exceed about $1,000 in the first few months, with an initial spending spike, because with time bugs would be harder to find. This was the wrong way to think about it - hacking is a skill and better hackers are paid more to spend more time on a single issue. We are now receiving only a fraction of bug reports, but new issues typically required much more effort to engineer. Those cost us more money, proportional to potential reputation loss. To sum this up, I recommend budgeting a fixed quarterly amount and using it as a reference to cap the maximum amount of dollars paid for a single issue.</p>

<p>It should be clear that every dollar of the $1,000 spent each month is worth every penny when you consider having exploitable security vulnerabilities in your production systems.</p>

<h2>Security Bug Bounty Services</h2>

<p>I have looked at the many bug bounty services and were quite impressed with their offerings, their ability to automatically recognize duplicates and to report on a security researcher's reputation. However, I didn't want to add yet another service in the plethora of services that we already use and wanted to have some brand control. In all honesty I do not know whether rolling out our own was or wasn't the best decision, but we're getting security bug reports, fixing real issues, and that's what matters.</p>

<h2>Full Time Attention Required</h2>

<p>The early days of the bug bounty program needed full time attention from one engineer who knew the entire system very well. This meant reading every report, triaging it as something new or already known, and opening detailed issues in the internal bug tracking systems. We labeled every issue as "Security Bounty" and created a "Security Bounty" project in Pivotal Tracker for issues that span multiple projects. We also found it useful to keep a Google Docs Spreadsheet to track the individuals reporting issues in a way where you can easily copy-paste all the issues that they have reported into an email to give them an update. <a href="https://docs.google.com/spreadsheets/d/1_Bq0jMImwU_r2-R76d2vqsYPLt9AB02lz2ZowK77yHc/edit?usp=sharing">Here's such a blank spreadsheet</a> with some formulas that can instantly tell you how many issues were opened, fixed, etc.</p>

<h2>Communicating the Program to the Team</h2>

<p>After running the program for a week I sent an email with a bit of statistics and explanations to the entire team. The entire e-mail can be found <a href="https://gist.github.com/dblock/5781f9b4931191de42b4">here</a>, and if there's one thing you retain from this post, that should be it. The e-mail was extremely well received, highlighting both the importance of explaining all-the-things to the rest of the company and being very transparent about such sensitive issues as security.</p>

<h2>Classes of Bugs</h2>

<p>While we were very diligent about large classes of potential vulnerabilities, such as SQL injections, most issues reported by the independent security researchers were also avoidable and should have been fixed before launching the program. Other issues should have been reviewed and acknowledged as a known, but acceptable risk upfront as well.</p>

<h3>SSL, Secure Cookies and HSTS</h3>

<p>If you let users signup and log-in or enter any personal information, your entire site must run under SSL. We were half way through this transition with some services still open for both SSL and non-SSL requests. Also you must enable <a href="https://scotthelme.co.uk/hsts-the-missing-link-in-tls">HSTS</a>, so that browsers that have visited your site before make an SSL request even if the user typed a non-SSL address, avoiding leaking session data over an insecure connection.</p>

<p>In Rails, HSTS is turned on with <code>config.force_ssl = true</code>. In node.js applications we use <a href="https://github.com/artsy/force-public/blob/master/lib/middleware/hsts.coffee">an HSTS middleware</a> combined with <a href="https://github.com/artsy/force-public/blob/master/lib/middleware/ensure_ssl.coffee">a redirect middleware</a>, but you might also want to check out <a href="https://github.com/evilpacket/helmet">helmet</a>.</p>

<p>Redirecting from HTTP to HTTPS is a compromise, it allows existing non-SSL clients and the myriad of existing links out there to keep functioning, however it exposes users to a potential risk of sending data over a non-encrypted connection, first. This is mitigated by using HSTS and by making sure session cookies carry a <code>secure=true</code> option.</p>

<h3>Clickjacking Vulnerabilities</h3>

<p>Make sure your site is not vulnerable to clickjacking. These attacks rely on loading the target page in an <code>iframe</code>. A simple test is to try to embed your site in the <a href="https://gist.github.com/dblock/8a91f805e97ba2325278">code in this gist</a>.</p>

<p>The standard and very simple fix is to deny framing by using the <code>X-Frame-Options</code> header with a <code>SAMEORIGIN</code> or, better, <code>DENY</code> value. There's a rather advanced explanation of this problem and the difference between these two values in an article about <a href="http://webstersprodigy.net/2012/09/13/clickjacking-google">clickjacking Google</a>. This is enabled by default in Rails, and can be turned on in node.js applications with <a href="https://github.com/evilpacket/helmet">helmet</a>.</p>

<h3>Cross-Site Scripting and Content Security Policy</h3>

<p>Spend time looking for Cross-Site Scripting (XSS) vulnerabilities in your code. The majority could have been known by actually attempting to enter JavaScript into the few user inputs that we have and then going to the pages that display that content. Then examine the code for any instances that render raw HTML, usually via <code>!=</code> in Jade templates or HAML. Track down how this data is inputted into the system and check whether these need to really be raw HTML. As a rule of thumb, do not trust the data in your database or data returned from your API, and encode or sanitize HTML when rendering it. We use the <a href="https://github.com/rgrove/sanitize">Sanitize</a> gem in Ruby, as well as a <a href="https://github.com/artsy/force-public/commit/0902c3450a0de60ee2b3e45a08e2dab656b31d86">fix in our open-source front-end</a> for how to deal with this in a node.js app.</p>

<p>Content Security Policy (CSP) also helps prevent cross-site-scripting. You can add a <code>Content-Security-Policy</code> header, or its variations, <code>X-WebKit-CSP</code> and <code>X-Content-Security-Policy</code>.</p>

<h3>Preventing User Abuse</h3>

<p>Log-in as a user, note their session cookie and log the user out. If you can reuse the session cookie in a new browser, your're not actually logging users out. This is particularly problematic on public computers and seems to be an issue often exploited by man-in-the-middle malware. To fix this, you must track sessions server-side.</p>

<p>Another similar problem is that all user sessions must be invalidated when a user resets their password. Imagine that you suspect that your account has been compromised, changing a password should make you safe again and the attacker who logged in as you earlier should be logged out. This is something natively supported by many session management implementations, including Devise, by adding a "salt" stored with the user record into the session cookie and comparing it after a session is deserialized.</p>

<p>Finally, make sure you either lock accounts or throttle after too many login or password reset attempts.</p>

<p>Another related example is when attackers can spam users with legitimate requests, such as password resets. For example, we didn't <a href="https://github.com/artsy/flare/pull/12">restrict how many SMS messages one can send</a> on our iPhone app download landing page. This particular instance had no actual benefit for the attacker, but could have really hurt our reputation. What would you say if a paying customer reported being spammed with anything coming from your company?</p>

<h3>Open Redirect</h3>

<p>Review all HTTP redirects in your applications. A common problem is when you can supply a URI and be redirected to it after, for example, a social login. This, combined with an XSS, would leak your session cookies, so don't ever redirect outside of your application. Furthermore, this can be a source of an XSS by itself with data URLs, something I had never seen before.</p>

<h3>Mixed Content</h3>

<p>Make sure the secure (HTTPS) pages aren't loading insecure (HTTP) javascript. A man-in-the-middle attack would enable injecting JavaScript into, otherwise, secure pages. Don't forget to check your error pages.</p>

<h2>Issues We Won't Fix</h2>

<p>We attempt to fix every reported issue, even very small. A single vulnerability may not be a problem in isolation, but may be exploitable in combination with another unknown issue. Still, we want to be able to disagree with the risk assessment of the security researcher. Such issues require a detailed explanation in a well articulated and prepared response, as well as a mention in a list of issues not eligible for bounty in our program's description. Here're a few examples.</p>

<h3>User Enumeration and Discovery</h3>

<p>Attackers often obtain databases of user e-mails and try to use those on other services with password dictionaries. When users enter the wrong password on login, you're supposed to be returning the same error message whether the account exists or not. While that would prevent user enumeration and make password attacks impractical, it's terribly unhelpful to the person trying to access your website. Many sites choose not to fix this, including Artsy. After-all, we will eventually have all of the 11 billion people on Artsy and the issue will be moot!</p>

<h3>Cross-Site Request Forgery</h3>

<p>CSRF is a class of attacks that attempt to force a user to execute unwanted actions on a web application in which they are currently authenticated, often without their knowledge. This can be mitigated by ensuring that the action was triggered from a legitimately rendered page within a certain period of time. CSRF was disabled on Artsy following some complicated technical issues related to caching, and is something that would cost us a lot of time and effort to bring back. It's a real problem, but not a critical one, so we explicitly list it in our bug bounty rules as ineligible for bounty.</p>

<h3>User Identity</h3>

<p>One of the most frequently reported issues is that we don't require e-mail verification, which is by design on Artsy. We used to have email verification, but too many users found it confusing and would never confirm their e-mail addresses. We treat emails as usernames, without any additional level of trust except for manually verified users, something internal to our systems.</p>

<h3>Sender Policy Framework</h3>

<p>Having a Sender Policy Framework (SPF) record increases the chances people will get emails you send. Without one, your email has a greater chance of being marked as Spam. Adding an SPF may not be as simple, especially if you use multiple thirdparty services for delivering e-mail. Furthermore, it might make forwarded e-mails go to spam.</p>

<h2>Acknowledging Security Researchers</h2>

<p>While most security researchers do an amazing job reporting issues, there's an unfortunately some number of bounty hunters who will dramatize issues or nag you for bounty payment or swag every other day. Many don't understand why it takes two weeks to get paid, why you disagree on their assessment of the problem, or will think that you're lying to them when you say a bug has been reported in the past by another security researcher. These are annoying and often discouraging exceptions.</p>

<p>I believe in the need of acknowledging the hard work done by the security researchers by listing their name on our security page, unless they don't want to. I want to thank each and every one of them.</p>

<p>I also do believe in the need to increase transparency into your process by listing the general category of issues after they have been fixed. I want users to trust us based on real data rather than on us just saying that we care about users' security and privacy. I think everyone understands that software has bugs, and I don't see any good reason to hide the security ones after they have been fixed.</p>

<h2>In Conclusion and a Word About Education</h2>

<p>A security bug bounty helps our systems be more secure and our users to trust us more. But that alone is not enough. Overtime the complexity of every system increases and the development team grows. We can only succeed at earning our users' trust if we actually spend time on security as a team. This includes teaching individual contributors how to avoid similar issues or entire classes of problems. I strongly encourage you to make a lot of extra effort to explain exploit vectors to all developers, using the issues reported by the Security Bug Bounty program as a starting point.</p>
]]></content>
  </entry>
  
</feed>
